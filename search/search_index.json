{"config":{"lang":["en"],"separator":"[\\s\\.]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Welcome! This user guide provides information on accessing and using the University of Chicago Research Computing Center's High-Performance Computing (HPC) resources. </p>"},{"location":"#overview-of-rccs-hpc-systems","title":"Overview of RCC's HPC systems","text":"<p>The University of Chicago Research Computing Center (RCC) is the home of multiple professionally managed high-performance computing clusters. In particular, Midway2, Midway3, Midway3-AMD, MidwaySSD, DaLI, Beagle3, GM4, MidwayR, and Skyway constitute the core of the RCC\u2019s advanced computational infrastructure. </p> <p>Remember, DaLI and Midway2 share a lot of resources. Midway3, Midway3-AMD, and Beagle3 also are closely interconnected. In this user guide, we distinguish between these clusters whenever there are system-specific differences. </p>"},{"location":"#shared-systems","title":"Shared systems","text":"<p>General access systems are accessible to any researcher with an RCC user account. </p>"},{"location":"#midway2-midway3-and-midway3-amd","title":"Midway2, Midway3, and Midway3-AMD","text":"<p>Midway2 was introduced in 2016 as the successor to the RCC's first HPC cluster, Midway. Four years later, in 2021, the Midway3 and Midway3-AMD clusters were brought online. Midway3 and Midway3-AMD are the current RCC's flagship HPC cluster for multi-purpose scientific computing.</p> <p>Note</p> <p>We recommend Midway3 for new users, as it provides the latest hardware and software modules.</p>"},{"location":"#dali","title":"DaLI","text":"<p>The Data Lifecycle Instrument (DaLI) enables the management and sharing of data from instruments and observations, allowing researchers to:</p> <ul> <li>Acquire, transfer, process, and store data from experiments and observations in a unified workflow.</li> <li>Manage data collections over their entire lifecycle.</li> <li>Share and publish data.</li> <li>Enhance outreach and education opportunities.</li> </ul>"},{"location":"#skyway","title":"Skyway","text":"<p>Skyway is an integrated platform developed at the RCC to allow users to burst computing workloads from the on-premise RCC cluster, Midway, to run on remote commercial cloud platforms such as Amazon AWS, Google GCP, and Microsoft Azure. Skyway enables users to run computing tasks in the cloud from Midway seamlessly without needing to learn how to provision cloud resources. Since the user does not need to set up or manage cloud resources, the result is improved productivity with a minimum learning curve. Skyway uses SLURM as a resource manager in the cloud. Resources in the cloud have the same configuration, software modules, and file storage systems as Midway.  </p>"},{"location":"#restricted-systems","title":"Restricted systems","text":"<p>Special permissions are required to access these systems. </p>"},{"location":"#beagle3","title":"Beagle3","text":"<p>Beagle3 is a high-performance computing cluster funded by the NIH grant led by Professor Benoit Roux, the Amgen Professor of Biochemistry and Molecular Biology. The project benefits biomedical research with cutting-edge HPC resources for modeling and large-scale simulations of the molecular building blocks for biological functions. The cluster also serves research projects that employ recent advances in imaging technology, like cryo-electronic microscopy, for producing images of molecules at unprecedented resolution. The enormous amount of data rapidly generated needs commensurate amounts of computing horsepower to analyze. Beagle3 has been in service since February 2022. Beagle3 was preceded by the highly successful Beagle1 and Beagle2 supercomputer clusters and comprises 44 compute nodes, each with a 32-core Intel Xeon Gold 6346 CPU and 4 NVIDIA A100 graphics processing units (GPUs). </p>"},{"location":"#midwayssd","title":"MidwaySSD","text":"<p>MidwaySSD is a high-performance computing cluster within the Midway3 ecosystem dedicated to computationally intensive Social Science Division research and educational excellence. </p>"},{"location":"#gm4","title":"GM4","text":"<p>The GPU-enabled Multiscale Materials Modeling and Machine-learning (GM4) cluster is a high-performance GPU cluster tailored for fast and efficient simulations, including molecular dynamics (MD), hybrid particle-continuum, mesoscale, and continuum simulations. This state-of-the-art research instrument was awarded to the University of Chicago researchers by the National Science Foundation (NSF)  under the Major Research Instrumentation (MRI) program. GM4 provides a unique computational resource that enables new collaborative efforts in algorithm and software development at the interface between molecular engineering, physics, chemistry, biology, computer science, and materials science. </p>"},{"location":"#midwayr","title":"MidwayR","text":"<p>MidwayR is part of the University of Chicago\u2019s Secure Data Enclave. It provides a secure computing environment to support research that has higher security standard requirements. The MidwayR computing and storage environment is similar to the RCC\u2019s Midway but is equipped with tools and software needed to meet the highest levels of secure data protection.</p>"},{"location":"#where-to-start","title":"Where to start?","text":""},{"location":"#the-rccs-workflow","title":"The RCC's workflow","text":"<p>This flowchart illustrates the workflow of a typical researcher using our HPC resources. </p> <p> </p>"},{"location":"#rcc-accounts","title":"RCC accounts","text":"<p>The RCC offers two types of user accounts: </p> <ul> <li>Principal investigator (PI) accounts</li> <li>General user accounts: A PI with an active RCC account must sponsor general users. </li> </ul> <p>More information about creating an account can be found on the accounts and allocations page.</p>"},{"location":"#connecting-to-rcc-clusters","title":"Connecting to RCC clusters","text":"<p>After creating your RCC user account, you can connect to an RCC login node. Depending on your operating system and desired user experience, there are several ways to connect to RCC's cluster login nodes. Login nodes are the \"foyer\" of the RCC's supercomputers. They are connected to the internet and enable you to transfer data to and from the system. </p>"},{"location":"#transfering-data-tofrom-rcc-clusters","title":"Transfering data to/from RCC clusters","text":"<p>Once you successfully connect to login nodes, you can move your research data (data transfer options) to your personal directories. Also, you have access to your group's shared directory (data storage). To request more shared group storage space, check this page. </p>"},{"location":"#running-jobs-on-rcc-clusters","title":"Running jobs on RCC clusters","text":"<p>After transferring your research data, you can perform high-performance computation by running jobs (which call your scripts and programs) on compute nodes (running jobs). Running jobs on servers consumes your group's computing time (Service Units - SUs) To learn more about how to apply for server units (applying for allocations), check this page. </p>"},{"location":"#troubleshooting","title":"Troubleshooting","text":"<p>Solutions to most issues can be found at our FAQ pages.</p> <p>If you need further assistance, please contact our helpdesk. </p> <p>To chat/consult with RCC's computational scientists about your computational needs contact our helpdesk. </p> <p>Know what you're looking for?</p> <p>Check out the search bar in the top right of the page! (e.g., search: GPU) </p>"},{"location":"#improve-this-user-guide","title":"Improve this user guide","text":"<p>If you come across any content that you think should be changed or improved (typo, out-of-date info, etc.), please email us through contact us page. </p>"},{"location":"beagle3-overview/","title":"Beagle3","text":""},{"location":"beagle3-overview/#what-is-beagle3","title":"What is Beagle3?","text":"<p>Beagle3 is a high-performance computing cluster funded by the NIH grant led by Professor Benoit Roux, the Amgen Professor of Biochemistry and Molecular Biology. The project benefits biomedical research with cutting-edge HPC resources for modeling and large-scale simulations of the molecular building blocks for biological functions. The cluster also serves research projects that employ recent advances in imaging technology, like cryo-electronic microscopy, for producing images of molecules at unprecedented resolution. The enormous amount of data rapidly generated need commensurate amounts of computing horsepower to analyze. Beagle3 has been in service since February 2022.</p> <p>Beagle3 consists of 44 computing nodes, each with an 32-core Intel Xeon Gold 6346 CPUs and 4 NVIDIA A100 graphics processing units (GPUs).</p>"},{"location":"beagle3-overview/#gaining-access","title":"Gaining Access","text":"<p>You should contact your PI for access to Beagle3. You can also contact our Help Desk for assistance.</p>"},{"location":"beagle3-overview/#partitions","title":"Partitions","text":"Beagle3 Partition Nodes CPUs CPU Type GPUs GPU Type Total Memory beagle3 22 32 gold-6346 4 a40 256 GB beagle3 22 32 gold-6346 4 a100 256 GB beagle3 4 32 gold-6346 None None 512 GB"},{"location":"beagle3-overview/#quality-of-service","title":"Quality-of-Service","text":"<p>There are two quality-of-service (QoS) options available on the beagle3 partition. You can specify either one by using the --qos flag in your sbatch scripts or sinteractive commands.</p> <p><code>--qos=beagle3</code>: This QoS allows you to request up to 256 CPU-cores and 32 GPUs, and a maximum wall time of 48 hours. It is the default QoS for the beagle3 partition.</p> <p><code>--qos=beagle3-long</code>: This QoS allows you to request up to 128 CPU-cores and 16 GPUs, and a maximum wall time of 96 hours.</p>"},{"location":"beagle3-overview/#connecting-and-running-jobs","title":"Connecting and Running Jobs","text":"<p>You connect to and run jobs on Beagle3 in a similar manner to Midway. Your home space is the same on Midway3, and you can access other mount points on Beagle3 from Midway3 as well.</p>"},{"location":"beagle3-overview/#troubleshooting","title":"Troubleshooting","text":"<p>For further assistance, please contact our Help Desk.</p>"},{"location":"connecting/","title":"Accessing RCC resources","text":"<p>The information here describes how users can connect to Midway to access RCC resources. All users are responsible for knowing and abiding by the RCC User Policy. </p>"},{"location":"connecting/#rcc-account-credentials","title":"RCC account credentials","text":"<p>To connect to RCC resources, you must have an RCC user account (request an account). Your RCC account uses your UChicago CNetID and its corresponding password: </p> <pre><code>Username: CNetID\nPassword: CNetID password\n</code></pre> <p>Copy code</p> <p>Wherever you see grey boxes like the one above, click the icon in the top right corner of the box to copy the contents to your clipboard. It's especially useful for longer code snippets! </p>"},{"location":"connecting/#supported-protocols","title":"Supported protocols","text":"<p>There are five main ways to access RCC resources. the following table provides a summary of these methods: </p> Connection Method Description Access to Compute Nodes Data Transfer Data Sharing Secure Shell (SSH) Can be used to access data and software packages (compute nodes) Yes (two-way) Yes RCC Internal ThinLinc A remote desktop to resources and can be used to access data and software packages (compute nodes) Yes Yes (two-way) RCC Internal SAMBA (SMB) Can be used to access data No Yes (two-way) No Globus Can be used to access and share data and scheduled data transfers No Yes (two-way) External and RCC collaborators HTTP Can be used to share data for public access (legacy service) No Yes (one-way) Public"},{"location":"data-storage/","title":"Data Storage","text":"<p>Midway2 and Midway3 have a high-performance GPFS shared file system that houses users' home directories, shared project spaces, and high-throughput scratch space. The project and scratch directories of Midway2 and Midway3 are 'cross-mounted' and accessible from both systems' login and compute nodes, while <code>/home</code>, <code>/software</code>, and <code>/snapshots</code> are specific to each cluster and its respective login nodes.</p> <p> </p> <p>Folder Access</p> <p>You and you alone have access to your personal home directory (<code>home/&lt;CNetID&gt;</code>), whereas everyone who is a member of your research group (<code>pi-&lt;PI CNetID&gt;</code>) has access to your project folder (<code>project/&lt;PI CNetID&gt;</code>).</p>"},{"location":"data-storage/#quotas","title":"Quotas","text":"<p>The amount of data that can be stored in home directories, project directories, and shared scratch directories is controlled by quota. RCC enforces hard and soft limits on quotas. A soft quota can be exceeded for a short period of time called a grace period.  The hard quota cannot be exceeded under any circumstances.</p> Midway2Midway3 Name Location Soft Quota Hard Quota Suitable For Home <code>/home/&lt;CNetID&gt;</code> 30 GB  (or 300K files) 35 GB  (or 1M files) Personal scripts &amp; files Project <code>/project2/&lt;PI CNetID&gt;</code> variable variable Shared data, environments Scratch <code>/scratch/midway2/&lt;CNetID&gt;</code> 100 GB 5 TB Output of jobs Name Location Soft Quota Hard Quota Suitable For Home <code>/home/&lt;CNetID&gt;</code> 30 GB  (or 300K files) 35 GB  (or 1M files) Personal scripts &amp; files Project <code>/project/&lt;PI CNetID&gt;</code> variable variable Shared data, environments Scratch <code>/scratch/midway3/&lt;CNetID&gt;</code> 100 GB 5 TB Output of jobs"},{"location":"data-storage/#checking-available-storage","title":"Checking available storage","text":"<p>To check your current quotas use <code>rcchelp quota</code>. Typical output may look like this <pre><code>---------------------------------------------------------------------------\nfileset          type                   used      quota      limit    grace\n---------------- ---------------- ---------- ---------- ---------- --------\nhome             blocks (user)         8.77G     30.00G     35.00G     none\n                 files  (user)        157865     300000    1000000     none\nscratch          blocks (user)        16.07G    100.00G      5.00T     none\n                 files  (user)        193028   10000000   20000000     none\n---------------- ---------------- ---------- ---------- ---------- --------\n&gt;&gt;&gt; Capacity Filesystem: project2 (GPFS)\n---------------- ---------------- ---------- ---------- ---------- --------\nrcc              blocks (group)      259.10T    500.00T    501.00T     none\n                 files  (group)     45825436  384500000  385500000     none\n---------------- ---------------- ---------- ---------- ---------- --------\n---------------------------------------------------------------------------\n</code></pre> The following table describes the fields:</p> Field Meaning fileset File set or file system where this quota is valid. type Type of quota. Blocks are the amount of consumed disk space. Files are the number of files in a directory. Blocks or files quotas can be set at the user or group level. used The amount of disk space consumed or the number of files in the specified location. quota The soft quota (disk space or file count) associated with the specified location. It is possible for usage to exceed the soft quota for the grace period or up to the hard limit. limit The hard quota (disk space or file count) associated with the specified location. When your usage exceeds this limit, you will NOT be able to write to that filesystem. grace The amount of time remaining that the soft quota can be exceeded. None means that the quota is not exceeded. After a soft quota has been exceeded for longer than the grace period, it will no longer be possible to create new files. <p>Over quota?</p> <p>Errors may occur if you are over quota. See our FAQ page on data management for multiple strategies for getting back under quota.</p>"},{"location":"data-storage/#purchasing-more-storage","title":"Purchasing More Storage","text":"<p>Additional storage is available through the Cluster Partnership Program, a Research I Allocation, Research II Allocation or, in certain circumstances, a Special Allocation.</p>"},{"location":"data-storage/#persistent-space","title":"Persistent Space","text":"<p>Persistent spaces are where data go for medium- to long-term storage. The two persistent storage locations on Midway are the <code>home</code> and <code>project</code> directories. Both directories have frequent file system snapshots and tape backups for data protection.</p>"},{"location":"data-storage/#home-directories","title":"Home Directories","text":"<p>Every RCC user has a home directory located at <code>/home/&lt;CNetID&gt;</code>. The <code>HOME</code> environment variable points to this location. The home directory is accessible from all RCC compute systems and is generally used for storing frequently used items such as source code, binaries, and scripts. By default, a home directory is only accessible by its owner (mode <code>0700</code>) and is suitable for storing files that do not need to be shared with others.</p>"},{"location":"data-storage/#project-directories","title":"Project Directories","text":"<p>All RCC PI Groups are allocated a Project Directory located at <code>/project/&lt;PI CNetID&gt;</code> or <code>/project2/&lt;PI CNetID&gt;</code> where  is the CNetID of your RCC PI account holder. These directories are accessible by all members of the PI Group and are generally used for storing files that need to be shared by members of the group.   <p>The default permissions for files and directories created in a project directory allow group read/write with the group sticky bit set (mode <code>2770</code>). The group ownership is set to the PI group.</p>"},{"location":"data-storage/#scratch-space","title":"Scratch Space","text":""},{"location":"data-storage/#shared-scratch-space","title":"Shared Scratch Space","text":"<p>High-performance shared scratch space can be accessed using the SCRATCH environment variable. This scratch space is intended to be used for reading or writing data required by jobs running on the cluster. If a user is over quota, they can use scratch space as a temporary location to hold files (and/or compress them for archival purposes) but as scratch space is neither snapshotted nor backed up, it should always be viewed as temporary.</p> <p>Warning</p> <p>It is the responsibility of the user to ensure any important data in scratch space is moved to persistent storage.  Scratch space is meant to be used for temporary, short-term storage only.</p> <p>The default permissions for scratch space allow access only by its owner (mode <code>0700</code>). The standard quota for the high-performance scratch directory is 5 TB with a 100GB soft limit.  The grace period that the soft limit may be exceeded is 30 days for shared scratch space.</p>"},{"location":"data-storage/#local-scratch-space","title":"Local Scratch Space","text":"<p>There is also a scratch space that resides on the local solid-state drives of each node and can only be used for jobs that do not require distributed parallel I/O. The capacity of the local SSD on Midway3 is 960 GB, but the actual amount of usable space will be less than this and may depend on the usage of other users utilizing the same node if your job resource request does not give you exclusive access to a node.</p> <p>It is recommended that users use the local scratch space if they have high throughput I/O of many small files ( size &lt; 4 MB) for jobs that are not distributed across multiple nodes. To write files to local scratch use environment variables <code>$TMPDIR</code> or <code>$SLURM_TMPDIR</code>, which are set to <code>/tmp/jobs/${SLURM_JOB_ID}</code> and add a line at the very end of your Slurm script to copy or move the output to /project to save the output. Otherwise, all temporary files will be removed once the job is completed or crashed.</p>"},{"location":"data-storage/#cost-effective-data-storage","title":"Cost-Effective Data Storage","text":"<p>In addition to a high-performance GPFS file system, RCC also offers Cost-effective Data Storage (CDS) through the Cluster Partnership Program for long-term data storage. CDS is only available from login nodes and is meant to be used as a storage for less frequently accessed data. Before performing any computation on the data stored on CDS, it first needs to be copied to the GPFS file system.  </p>"},{"location":"data-storage/#data-recovery-and-backups","title":"Data Recovery and Backups","text":""},{"location":"data-storage/#snapshots","title":"Snapshots","text":"<p>Automated snapshots of home and project directories are available in case of accidental file deletion or other problems. Currently, snapshots are available for these time periods:</p> Midway2Midway3 Directory Snapshot kept Snapshot Path <code>/home/&lt;CNetID&gt;</code> 7 daily and 2 weekly <code>/snapshots/home/SNAPSHOT/home/&lt;CNetID&gt;</code> <code>/project2/&lt;folder&gt;</code> 7 daily and 2 weekly <code>/snapshots/project2/SNAPSHOT/project2/&lt;any_folder&gt;</code> Directory Snapshot kept Snapshot Path <code>/home/&lt;CNetID&gt;</code> 7 daily and 4 weekly <code>/snapshots/SNAPSHOT/home/&lt;CNetID&gt;</code> <code>/project/&lt;folder&gt;</code> 7 daily and 4 weekly <code>/snapshots/SNAPSHOT/project/&lt;any_folder&gt;</code> <p>The snapshots for the <code>home</code> and <code>project</code> directories are available from the login nodes. The {SNAPSHOT} refers to the time of the backup, e.g. daily-YYYY-MM-DD.05h30 or weekly-YYYY-MM-DD.05h30. To view the available snapshots of the <code>home</code> directory, for example, use the command <code>ls -l /snapshots/home/</code> to restore a file from a snapshot, simply copy the file to where you want it with either <code>cp</code> or <code>rsync</code>.</p>"},{"location":"example-job-scripts/","title":"Illustrative examples","text":"<p>Below are a number of example submission scripts that you can adapt to run your jobs on Midway. See also the materials from the RCC Slurm workshop for additional examples.</p> <p>The SLURM  documentation is always a good reference for all the <code>#SBATCH</code> parameters below.</p>"},{"location":"example-job-scripts/#simple-jobs","title":"Simple Jobs","text":"<p>A typical batch script for simple jobs is given below</p> Midway2Midway3 <pre><code>#!/bin/bash\n\n#SBATCH --job-name=single-node-cpu-example\n#SBATCH --account=pi-[group]\n#SBATCH --partition=broadwl  # accessible partitions listed by the sinfo command\n#SBATCH --ntasks-per-node=1  # number of tasks per node\n#SBATCH --cpus-per-task=1    # number of CPU cores per task\n\n# Load the require module(s)\nmodule load python\n\n# match the no. of threads with the no. of CPU cores\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK  \n\n# Load the require module(s)\npython analyze.py\n</code></pre> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=single-node-cpu-example\n#SBATCH --account=pi-[group]\n#SBATCH --partition=caslake  # accessible partitions listed by the sinfo command\n#SBATCH --ntasks-per-node=1  # number of tasks per node\n#SBATCH --cpus-per-task=1    # number of CPU cores per task\n\n# Load the require module(s)\nmodule load python\n\n# match the no. of threads with the no. of CPU cores\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK  \n\n# Load the require module(s)\npython analyze.py\n</code></pre> <p>Note</p> <ul> <li>If your application supports multithreading (e.g. with OpenMP), you want to specify the number of CPU cores per task greater than 1, e.g. <code>#SBATCH --cpus-per-task=8</code></li> <li>You can check the available partitions to your account via the command <code>rcchelp sinfo</code> to specify in <code>--partition</code>.</li> <li>You can concatenate more than one runs in a job script.</li> <li>If the job submission fails, please read the error message carefully: there are information regarding invalid combinations of <code>partition</code>, <code>account</code> or <code>qos</code> that may help you correct.</li> </ul>"},{"location":"example-job-scripts/#large-memory-jobs","title":"Large-Memory Jobs","text":"<p>If your calculaltions need more than about 60 GB of memory, submit the job to the <code>bigmem2</code> partition on Midway2. You can query the technical specification of the partition via <pre><code>scontrol show partition bigmem2\n</code></pre> and then <code>scontrol show node</code> to find out the memory capacity of its individual nodes.</p> <p>To submit a job to <code>bigmem2</code>, include this line in your sbatch script:</p> <pre><code>#SBATCH --partition=bigmem2\n</code></pre> <p>Additionally, it is important to use the <code>--mem</code> or <code>--mem-per-cpu</code> options. For example, to request 8 CPU cores and 128 GB of memory on a bigmem2 node, add the following to your sbatch script:</p> <pre><code>#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=8\n#SBATCH --mem=128G\n</code></pre> <p>These same options can also be used to set up an sinteractive session. For example, to access a <code>bigmem2</code> node with 1 CPU and 128 GB of memory, run:</p> <pre><code>sinteractive --partition=bigmem2 --ntasks=1 --cpus-per-task=8 --mem=128G\n</code></pre>"},{"location":"example-job-scripts/#mpi-jobs","title":"MPI Jobs","text":"<p>Many applications employ Message Passing Interface (MPI) for distributed and parallel computing to improve performance. For more information on the MPI libraries available on Midway, check with  <code>module avail openmpi</code> and <code>module avail intelmpi</code>. It is recommended to use the more recent modules to compile your codes (e.g. <code>intelmpi</code> 2021 and later, <code>openmpi</code> 3.0 and later).</p> <p>Below is a simple C program (<code>test-mpi.c</code>) that you can use as a test for your MPI build and the loaded MPI libraries.</p> <pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;mpi.h&gt;\n\nint main(int argc, char *argv[], char *envp[]) {\nint numprocs, rank, namelen;\nchar processor_name[MPI_MAX_PROCESSOR_NAME];\n\nMPI_Init(&amp;argc, &amp;argv);\nMPI_Comm_size(MPI_COMM_WORLD, &amp;numprocs);\nMPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\nMPI_Get_processor_name(processor_name, &amp;namelen);\n\nprintf(\"Process %d on %s out of %d\\n\", rank, processor_name, numprocs);\n\nMPI_Finalize();\n}\n</code></pre> <p>Copy <code>test-mpi.c</code> to your home directory on Midway, load the default OpenMPI module, and compile the program on a Midway login node:</p> <pre><code>module load openmpi\nmpicc test-mpi.c -o mytest\n</code></pre> Note <p>It is recommended to check that the version of <code>mpicc</code> is the one you wanted via <code>which mpicc</code>.</p> <p>Then prepare a job script <code>test.sbatch</code> to submit a job to Midway to run the program:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=test\n#SBATCH --output=test.out\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=28\n#SBATCH --partition=broadwl\n\n# Load the default OpenMPI module that you used to compile the source file.\nmodule load openmpi\n\n# Run the MPI program with mpirun. Although the -n flag is not required and\n# mpirun will automatically figure out the best configuration from the\n# Slurm environment variables, it is recommended to specify -n and/or -ppn\n# as explicit as possible.\n\nn=$(( SLURM_NUM_NODES * SLURM_NTASKS_PER_NODE ))\nmpirun -n $n --bind-to core --map-by core ./mytest\n</code></pre> <p>Note</p> <p>The options <code>--bind-to core --map-by core</code> added to the <code>mpirun</code> command indicates that the MPI tasks should be bound to physical CPU cores to improve performance.</p> <p>Submit the MPI job to the Slurm job scheduler from a Midway login node:</p> <pre><code>sbatch test.sbatch\n</code></pre> <p>Note</p> <p>Both OpenMPI and IntelMPI have the ability to launch MPI programs directly with the Slurm command srun. It is not necessary to use this mode for most jobs, but it may provide additional job launch options. For example, from a Midway login node it is possible to launch the above <code>hellompi</code> program using OpenMPI using 28 MPI processes:</p> <pre><code>srun -n28 hellompi\n</code></pre> <p>With IntelMPI, you need to also set an environment variable for this to work:</p> <pre><code>export I_MPI_PMI_LIBRARY=/software/slurm-current-$DISTARCH/lib/libpmi.so\nsrun -n28 hellompi\n</code></pre>"},{"location":"example-job-scripts/#hybrid-mpiopenmp-jobs","title":"Hybrid MPI/OpenMP Jobs","text":"<p>The following simple C source code (<code>test-hybrid.c</code>) illustrates a hybrid MPI/OpenMP program that you can use to test.</p> <pre><code>#include &lt;stdio.h&gt;\n#include &lt;omp.h&gt;\n#include \"mpi.h\"\n\nint main(int argc, char *argv[]) {\nint numprocs, rank, namelen;\nchar processor_name[MPI_MAX_PROCESSOR_NAME];\nint iam = 0, np = 1;\n\nMPI_Init(&amp;argc, &amp;argv);\nMPI_Comm_size(MPI_COMM_WORLD, &amp;numprocs);\nMPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\nMPI_Get_processor_name(processor_name, &amp;namelen);\n\n#pragma omp parallel default(shared) private(iam, np)\n{\nnp = omp_get_num_threads();\niam = omp_get_thread_num();\nprintf(\"Hello from thread %d out of %d from process %d out of %d on %s\\n\",\niam, np, rank, numprocs, processor_name);\n}\n\nMPI_Finalize();\n}\n</code></pre> <p>To run the program on the RCC cluster, copy <code>test-hybrid.c</code> to your home directory, then compile the code by entering the following commands into a terminal on a Midway2 login node:</p> <pre><code>module load openmpi\nmpicc -fopenmp test-hybrid.c -o mytest\n</code></pre> <p>Here we load the default OpenMPI compiler, but it should be possible to use any available MPI compiler to compile and run this example. Note that the option <code>-fopenmp</code> must be used here to compile the program because the code includes OpenMP directives (use <code>-openmp</code> or <code>-qopenmp</code> for the Intel compiler, or <code>-mp</code> for the PGI compiler).</p> <p>Then prepare <code>test.sbatch</code> is a submission script that can be used to submit a job to Midway2 to run the <code>mytest</code> program.</p> <pre><code>#!/bin/bash\n\n# A job submission script for running a hybrid MPI/OpenMP job on\n# Midway2.\n\n#SBATCH --job-name=test\n#SBATCH --output=test.out\n#SBATCH --ntasks=2\n#SBATCH --cpus-per-task=8\n#SBATCH --partition=broadwl\n#SBATCH --constraint=edr       # constraint for the inter-node MPI interface\n\n# Load the default OpenMPI module.\nmodule load openmpi\n\n# Set OMP_NUM_THREADS to the number of CPUs per task we asked for.\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n\nmpirun ./hellohybrid\n</code></pre> <p>The options are similar to running an MPI job, with some differences:</p> <ul> <li><code>--ntasks=2</code> specifies the number of MPI processes (or tasks).</li> <li><code>--cpus-per-task=8</code> allocates 8 CPUs for each task.</li> <li><code>export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK</code> sets the number of OpenMP threads to the number of requested cores (CPUs) for each task.</li> </ul> <p>You can submit <code>test.sbatch</code> using the following command from one of Midway2 login nodes:</p> <pre><code>sbatch test.sbatch\n</code></pre>"},{"location":"example-job-scripts/#gpu-jobs","title":"GPU Jobs","text":"<p>There are GPU nodes on both Midway2 and Midway3 where you can run GPU-enabled applications. You can check the partition <code>gpu2</code> (on <code>Midway2</code>) and <code>gpu</code> (on Midway3) to see their constituent nodes:</p> Midway2Midway3 <pre><code>scontrol show partition gpu2\n</code></pre> <pre><code>scontrol show partition gpu\n</code></pre> <p>and then check the features of the individual nodes, for example,</p> Midway2Midway3 <pre><code>scontrol show node midway2-gpu02\n</code></pre> <pre><code>scontrol show node midway3-0278\n</code></pre> <p>which shows NVIDIA Tesla K80, Tesla V100 or Quadro RTX6000 GPUs.</p> <p>To submit a job to one of the GPU nodes, you must specify the correct partition and the number of GPUs in the batch scripts, for example for job scripts on Midway2:</p> <p><pre><code>#SBATCH --partition=gpu2\n#SBATCH --gres=gpu:N\n</code></pre> where <code>N</code> is the number of GPUs  requested. Allowable settings for <code>N</code> range from 1 to 4 depending on the number of GPUs per node.</p> Midway2Midway3 <pre><code>#!/bin/bash\n\n#SBATCH --job-name=1gpu-example\n#SBATCH --account=pi-[group]\n#SBATCH --partition=gpu2\n#SBATCH --gres=gpu:1\n#SBATCH --ntasks-per-node=1 # num of tasker per node to drive the GPUs in the node\n#SBATCH --cpus-per-task=1   # set this to the desired number of threads\n\n# LOAD MODULES\nmodule load tensorflow\nmodule load cudnn\n\n# DO COMPUTE WORK\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\npython training.py\n</code></pre> <pre><code>#!/bin/sh\n\n#SBATCH --job-name=1gpu-example\n#SBATCH --account=pi-[group]\n#SBATCH --partition=gpu\n#SBATCH --gres=gpu:1\n# TO USE V100 specify --constraint=v100\n# TO USE RTX600 specify --constraint=rtx6000\n#SBATCH --constraint=v100   # constraint job runs on V100 GPU use\n#SBATCH --ntasks-per-node=1 # num cores to drive each gpu\n#SBATCH --cpus-per-task=1   # set this to the desired number of threads\n\n# LOAD MODULES\nmodule load tensorflow\nmodule load cudnn\n\n# DO COMPUTE WORK\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\npython training.py\n</code></pre> <p>Depending on the software packages you are using in the script, their dependency would be the CUDA and OpenACC modules. When you load the modules provided on Midway2 and Midway3 (e.g., <code>module load tensorflow</code>) the CUDA dependency modules will be automatically loaded (comparing the output of <code>module list</code> before and after doing <code>module load</code> command).</p> <p>If you build the codes yourself using one of those CUDA modules, remember to load these modules in your script.</p> <p>Here is an example batch script that request GPU resources, loads the CUDA libraries, and runs the MPI application. In this case, the application <code>your-app</code> is in charge of supporting hybrid MPI/GPU parallelization.</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=test-gpu   # job name\n#SBATCH --output=%N.out       # output log file\n#SBATCH --error=%N.err        # error file\n#SBATCH --time=01:00:00       # 1 hour of wall time\n#SBATCH --nodes=1             # 1 GPU node\n#SBATCH --ntasks-per-node=2   # 2 CPU cores to drive the GPUs\n#SBATCH --partition=gpu2      # gpu2 partition\n#SBATCH --gres=gpu:1          # Request 1 GPU per node\n\n\n# Load all required modules below. As an example we load cuda/10.1\nmodule load cuda/10.1\n\n# Launch your run\nmpirun -np 2 ./your-app input.txt\n</code></pre>"},{"location":"example-job-scripts/#job-arrays","title":"Job Arrays","text":"<p>Slurm job arrays provide a convenient way to submit a large number of independent processing jobs. For example, Slurm job arrays can be useful for applying the same or similar computation to a collection of data sets. Or, you can launch independent calculations each with a different set of input parameters by submitting a single sbatch script. When a job array script is submitted, a specified number of array tasks are created based on the \u201cmaster\u201d sbatch script.</p> <p>Consider the following example (from <code>array.sbatch</code>):</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=array\n#SBATCH --output=array_%A_%a.out\n#SBATCH --error=array_%A_%a.err\n#SBATCH --array=1-16\n#SBATCH --time=01:00:00\n#SBATCH --partition=broadwl\n#SBATCH --ntasks=1\n#SBATCH --mem=4G\n\n# Print the task id.\necho \"My SLURM_ARRAY_TASK_ID: \" $SLURM_ARRAY_TASK_ID\n\n# Add lines here to run your computation on each job\n./my_app -input $SLURM_ARRAY_TASK_ID\n</code></pre> <p>In this simple example, <code>--array=1-16</code> requests 16 array tasks (numbered 1 through 16). The \u201carray tasks\u201d are copies of the master script that are automatically submitted to the scheduler on your behalf. In each array task, the environment variable <code>SLURM_ARRAY_TASK_ID</code> is set to a unique value (in this example, numbers ranging from 1 to 16). The application should be responsible to use the array index to handle the corresponding data.</p> <p>Job array indices can be specified in several different ways. Here are some examples:</p> <p><pre><code># A job array with array tasks numbered from 0 to 31.\n#SBATCH --array=0-31\n</code></pre> or <pre><code># A job array with array tasks numbered 1, 2, 5, 19, 27.\n#SBATCH --array=1,2,5,19,27\n</code></pre> or <pre><code># A job array with array tasks numbered 1, 3, 5 and 7.\n#SBATCH --array=1-7:2\n</code></pre></p> <p>In the example sbatch script above, the <code>%A_%a</code> notation is filled in with the master job id (<code>%A</code>) and the array task id (<code>%a</code>). This is a simple way to create output files in which the file name is different for each job in the array.</p> <p>The remaining options in the sbatch script are the same as the options used in other, non-array settings; in this example, we are requesting that each array task be allocated 1 CPU (<code>--ntasks=1</code>) and 4 GB of memory (<code>--mem=4G</code>) on the broadwl partition (<code>--partition=broadwl</code>) for up to one hour (<code>--time=01:00:00</code>).</p> <p>Most partitions have limits on the number of array tasks that can run simultaneously. To achieve a higher throughput, consider Parallel batch jobs.</p> <p>For more information about Slurm job arrays, refer to the Slurm documentation on job arrays.</p>"},{"location":"example-job-scripts/#parallel-batch-jobs","title":"Parallel Batch Jobs","text":"<p>Computations involving a very large number of independent computations should be combined in some way to reduce the number of jobs submitted to Slurm. Here we illustrate one strategy for doing this using GNU Parallel and srun. The parallel program executes tasks simultaneously until all tasks have been completed.</p> <p>Here\u2019s an example script, <code>parallel.sbatch</code>:</p> <pre><code>#!/bin/sh\n\n#SBATCH --time=01:00:00\n#SBATCH --partition=broadwl\n#SBATCH --ntasks=28\n#SBATCH --mem-per-cpu=2G  # NOTE DO NOT USE THE --mem= OPTION\n\n# Load the default version of GNU parallel.\nmodule load parallel\n\n# When running a large number of tasks simultaneously, it may be\n# necessary to increase the user process limit.\nulimit -u 10000\n\n# This specifies the options used to run srun. The \"-N1 -n1\" options are\n# used to allocates a single core to each task.\nsrun=\"srun --exclusive -N1 -n1\"\n\n# This specifies the options used to run GNU parallel:\n#\n#   --delay of 0.2 prevents overloading the controlling node.\n#\n#   -j is the number of tasks run simultaneously.\n#\n#   The combination of --joblog and --resume create a task log that\n#   can be used to monitor progress.\n#\nparallel=\"parallel --delay 0.2 -j $SLURM_NTASKS --joblog runtask.log --resume\"\n\n# Run a script, runtask.sh, using GNU parallel and srun. Parallel\n# will run the runtask script for the numbers 1 through 128. To\n# illustrate, the first job will run like this:\n#\n#   srun --exclusive -N1 -n1 ./runtask.sh arg1:1 &gt; runtask.1\n#\n$parallel \"$srun ./runtask.sh arg1:{1} &gt; runtask.sh.{1}\" ::: {1..128}\n\n# Note that if your program does not take any input, use the -n0 option to\n# call the parallel command:\n#\n#   $parallel -n0 \"$srun ./run_noinput_task.sh &gt; output.{1}\" ::: {1..128}\n</code></pre> <p>In this example, our aim is to run script <code>runtask.sh</code> 128 times. The <code>--ntasks</code> option is set to 28, so at most 28 tasks can be run simultaneously.</p> <p>Here is the <code>runtask.sh</code> script that is run by GNU Parallel:</p> <pre><code>#!/bin/sh\n\n# This script outputs some useful information so we can see what parallel\n# and srun are doing.\n\nsleepsecs=$[ ( $RANDOM % 10 ) + 10 ]s\n\n# $1 is arg1:{1} from GNU parallel.\n#\n# $PARALLEL_SEQ is a special variable from GNU parallel. It gives the\n# number of the job in the sequence.\n#\n# Here we print the sleep time, host name, and the date and time.\necho task $1 seq:$PARALLEL_SEQ sleep:$sleepsecs host:$(hostname) date:$(date)\n\n# Sleep a random amount of time.\nsleep $sleepsecs\n</code></pre> <p>To submit this job, copy both <code>parallel.sbatch</code> and <code>runtask.sh</code> to the same directory, and run <code>chmod +x runtask.sh</code> to make <code>runtask.sh</code> executable. Then the job can be submitted to the Slurm queue:</p> <pre><code>sbatch parallel.sbatch\n</code></pre> <p>When this job completes, you should see output files with names <code>runtask.sh.N</code>, where <code>N</code> is a number between 1 and 128. The content of the first output file (i.e., <code>runtask.sh.1</code>) should look something like this:</p> <pre><code>task arg1:1 seq:1 sleep:14s host:midway2-0002 date:Thu Jan 10 09:17:36 CST 2017\n</code></pre> <p>Another file <code>runtask.log</code> is also created. It gives a list of the completed jobs. (Note: If the sbatch is submitted again, nothing will be run until <code>runtask.log</code> is removed.)</p> <p>It is also possible to use this same technique to run multithreaded tasks in parallel. Here is an example sbatch script, <code>parallel-hybrid.sbatch</code>, that distributes multithreaded computations (each using 28 CPUs) across 2 nodes:</p> <pre><code>#!/bin/sh\n\n#SBATCH --partition=broadwl\n#SBATCH --time=01:00:00\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=1\n#SBATCH --cpus-per-task=28\n#SBATCH --exclusive\n\n# Load the default version of GNU parallel.\nmodule load parallel\n\nsrun=\"srun --exclusive -N1 -n1 --cpus-per-task $SLURM_CPUS_PER_TASK\"\n\n# Instead of $SLURM_NTASKS, use $SLURM_NNODES to determine how\n# many jobs should be run simultaneously.\nparallel=\"parallel --delay 0.2 -j $SLURM_NNODES --joblog runtask.log --resume\"\n\n# Run the parallel command.\n$parallel \"$srun ./runtask.sh arg1:{1} &gt; runtask.sh.{1}\" ::: {1..6}\n</code></pre> <p>Another way to set up parallel runs without GNU Parallel is to launch background processes concurrently. This setup would be suitable for independent runs that use a single node exclusively.</p> <pre><code>#!/bin/sh\n\n#SBATCH --partition=broadwl\n#SBATCH --time=06:00:00\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=28\n#SBATCH --exclusive\n\nmodule load openmpi/4.1.1\nmpirun --cpu-set 0-7 --bind-to core -np 8 ./your-mpi-app1 &amp;\nmpirun --cpu-set 8-11 --bind-to core -np 4 ./your-mpi-app2 &amp;\nwait\n</code></pre> <p>Here the first <code>mpirun</code> uses 8 CPU cores for 8 tasks, and 2nd uses other 4 CPU cores, to avoid oversubscription.  The two \"&amp;\" mean to launch the mpirun commands to the background and the wait command makes sure all the processes complete before terminating the job.</p>"},{"location":"example-job-scripts/#cron-like-jobs","title":"Cron-like Jobs","text":"<p>Cron-like jobs are jobs that are submitted to the queue with a specified schedule. These jobs persist until they are canceled or encounter an error. The Midway2 cluster has a dedicated partition, <code>cron</code>, for running Cron-like jobs. Please contact our Help Desk to request submitting Cron-like jobs. These jobs are subject to scheduling limits and will be monitored.</p> <p>Here is an example of a batch script that internally submits a Cron job (<code>cron.sbatch</code>):</p> <pre><code>#!/bin/bash\n\n#SBATCH --time=00:05:00\n#SBATCH --output=cron.log\n#SBATCH --open-mode=append\n#SBATCH --account=cron-account\n#SBATCH --partition=cron\n#SBATCH --qos=cron\n\n# Specify a valid Cron string for the schedule. This specifies that\n# the Cron job run once per day at 5:15a.\nSCHEDULE='15 5 * * *'\n\n# Here is an example of a simple command that prints the host name and\n# the date and time.\necho \"Hello on $(hostname) at $(date).\"\n\n# This schedules the next run.\nsbatch --quiet --begin=$(next-cron-time \"$SCHEDULE\") cron.sbatch\n</code></pre> <p>After executing a simple command (print the host name, date and time), the script schedules the next run with another call to <code>sbatch</code> with the <code>--begin</code> option.</p>"},{"location":"example-job-scripts/#dependency-jobs","title":"Dependency Jobs","text":"<p>You can schedule jobs that are dependend upon the termination status of other previously scheduled jobs. This way you can concatenate your jobs into a pipeline, or even expand to more complicated dependencies.</p> <p>For example, <code>job1.sbatch</code> is a submission script you plan to submit a batch job to Midway:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=hellompi\n#SBATCH --output=hellompi.out\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=16\n#SBATCH --partition=broadwl\n\n# Load the MPI module that was used to build the application\nmodule load openmpi\n\nmpirun -np 32 ./hellompi\n</code></pre> <p>Submit the job script to the Slurm job scheduler from a Midway login node:</p> <pre><code>sbatch job1.sbatch\n</code></pre> <p>which returns the job ID, for example, <code>1234567</code>.</p> <p>You can then submit another job that is put on the waiting list of the queue (pending)</p> <pre><code>sbatch -dependency=afterany:1234567 job2.sbatch\n</code></pre> <p>This command indicates that <code>job2.sbatch</code> will be put in the queue after the job ID <code>1234567</code> is terminated for any reason. The dependency option flag can be <code>after</code>, <code>afterany</code>, <code>afterok</code> and <code>afternotok</code>, which are self-explanatory.</p> <p>For more information of job dependencies, please refer to the Slurm documenation.</p>"},{"location":"getting-started/","title":"Getting started","text":""},{"location":"getting-started/#help-requests","title":"Help Requests","text":"<p>You can contact us to get technical user support for RCC systems related issues. Please provide the RCC staff with all useful information when requesting assistance and submit requests using your UChicago email address. In the following section, we include instructions to submit an informative ticket.  </p> <ul> <li>Write an informative subject/title to the ticket/email that can include details such as cluster name, software name, brief description of the issue</li> <li>Submit screenshots of the error message when possible</li> <li>Explain briefly what you are trying to do and the problem you are encountering</li> <li>Include instructions on how to reproduce your issue with relevant details such as:<ul> <li>Submit the list of modules that were loaded<ul> <li>Output of <code>module list</code> command</li> </ul> </li> <li>Submit the <code>sbatch</code> script, along with the <code>.err</code> and <code>.out</code> files</li> <li>Submit the commands that led to the error, along with the error message</li> <li>Submit the job ID for SLURM job related issues  </li> <li>Submit the output of command <code>pwd</code> to inform us of your working directory  </li> </ul> </li> </ul> <p>We look forwarding to assisting you!</p>"},{"location":"globus/","title":"Globus (Advance file transfer and sharing platform)","text":"<p>Globus Online is a robust tool for transferring large data files to/from Midway. RCC has a customized Globus Online login site.</p> <ol> <li> <p>Go to globus.rcc.uchicago.edu and Select \u201cUniversity of Chicago\u201d for the existing organizational login:</p> <p></p> </li> <li> <p>Enter your CNetID and password when prompted:</p> <p></p> </li> <li> <p>You will need to link your University of Chicago credentials to a Globus Online account. Either create a new Globus Online account or sign in to your existing account if you have one.</p> </li> <li> <p>Once you are signed in, select the \"File Manager\" tab on the sidebar, then enter \"ucrcc#midway\". You can select \"UChicago RCC Midway\" to access your Midway2 files or \"UChicago RCC Midway3\" to access your Midway3 files.</p> <p></p> </li> <li> <p>You will then be able to perform actions such as transfer files, share collections, or create new directories. To learn more about how to use these tools, please refer to the \"Help\" tab on the left toolbar.</p> <p></p> </li> </ol> <p>There is extensive documentation on the Globus Online site as to how to transfer files in different modes. Please refer to their documentation for more details or contact us with any RCC specific issues.</p>"},{"location":"glossary/","title":"Glossary","text":"Term Definition Batch job A job is the Slurm\u2019s computing unit by which resources are allocated and shared. Users create job submission scripts to ask Slurm for resources such as cores, memory, walltime, etc. Slurm puts the requests in a queue and allocates requested resources based on jobs\u2019 priority. Compute cluster A group of independent computers connected via a fast network interconnect, managed by a resource manage, and act as a large parallel computer. Each node in a cluster can be a shared memory parallel computer. Compute node A compute node is a stand-alone computer connected to other compute nodes via a fast network interconnect. A compute node is where a batch job runs and is not usually accessible directly by the users. Core Smallest computation unit that can run a program (used to be called a processor, still is,  also called a CPU \u2013 Central Processing Unit). Distributed memory architecture Distributed memory architecture refers to a way to create a parallel computer. In this architecture, stand-alone compute nodes are connected using a fast interconnect such as Infiniband and exchange messages over the network. FLOPS Floating point Operation Per Second (FLOPS) is a measure of computing performance in terms of number of floating operations that a CPU can perfomr per second. Modern CPUs are capable of doing Tera FLOPS (10^12 floating point operations per second). GPU Graphics Processing Unit (GPU) is a specialized device initially used to generate computer output. GPUs have their own memory but should be hosted in a node. Each compute node can host one or more GPUs. Modern GPUs have many simple compute cores and have been used for parallel processing. HPC High Performance Computing (HPC) refers to the practice of aggregating computing power to achieve higher performance that would not possible by using a typical computer. Infiniband A computer network standard featuring high bandwidth and low latency. The current Infiniband devices are capable of transferring data at up to 100Gbits/sec with less than a microsecond latency. As of this writing, the popular Infiniband versions are FDR (Fourteen Data Rate) with 56Gbits/sec and EDR (Enhanced Data Rate) with 100Gbits/sec. Login node Login nodes (a.k.a. head nodes) are point of access to a parallel computer. Users usually connect to login nodes via SSH to compile and debug their code, review their results, do some simple tests, and submit their batch jobs to the parallel computer. Modules An open source software management tool used in most HPC facilities. Using modules enable users to selectively pick the software that they want and add them to their environment. Node A stand-alone computer system that contains one or more sockets, memory, storage, etc. connected to other nodes via a fast network interconnect. OpenMP Open Multi Processing (OpenMP) is a parallel programming model designed for shared memory architecture. In this programming mode, programmers insert compiler directives in their code and the compiler generates a code that can run on more than one core. Partition A subset of a compute cluster with a common feature. For example, compute nodes with GPU could form a partition. Shared memory architecture Shared memory architecture is a way to create a parallel computer. In this architecture, a large memory is shared among many cores and communication between cores is done via the shared memory. By introducing the multi-core CPUs, each computer is a shared-memory parallel computer. Slurm Simple Linux Utility for Resource Management (SLURM) is a software that manages high performance computing resources. SLURM coordinates running of many programs on a shared facility and makes sure that resources are used in a fair share manner. Socket A computational unit, packaged as one and usually made of a single chip often called processor. Modern sockets carry many cores (2,  4 on most laptops, 8 to 16 on most servers). SSH Secure Shell (SSH) is a protocol to securely access remote computers. Based on the client-server model, multiple users with an SSH client can access to a remote computer. Some operating systems such as Linux and Mac OS have a built-in SSH client and others can use one of many publicly available clients. Tightly-coupled nodes A set of compute nodes connected via fast Infiniband interconnect. These nodes can exchange data in a fast rate and are used to solve big problems that cannot fit in a single computer. Walltime The time that requires a program to finish execution."},{"location":"hardware-overview/","title":"Hardware Overview","text":""},{"location":"hardware-overview/#midway3-hpc-cluster","title":"Midway3 HPC Cluster","text":""},{"location":"hardware-overview/#operating-system-and-connectivity","title":"Operating System and Connectivity","text":"<p>Midway3 runs CentOs 8, and all nodes are connected via HDR Mellanox InfiniBand (100 Gbps) Interconnect.</p>"},{"location":"hardware-overview/#standard-compute-nodes","title":"Standard Compute Nodes","text":"<ul> <li>210 Intel Cascade Lake CPU-only compute nodes, each equipped with:<ul> <li>2x Intel Xeon Gold 6248R (48 cores per node)</li> <li>960 GB Local SSD Storage </li> <li>192 GB Memory </li> </ul> </li> </ul>"},{"location":"hardware-overview/#specialized-nodes","title":"Specialized Nodes","text":""},{"location":"hardware-overview/#gpu-nodes","title":"GPU Nodes","text":"<p>There are 11 GPU nodes that are part of the Midway3 communal resources. Each GPU node has the Standard Intel Compute Node specifications and the following GPU configurations:</p> <ul> <li>5 GPU nodes w/ 4x NVIDIA V100 GPUs per node</li> <li>5 GPU nodes w/ 4x NVIDIA Quadro RTX 6000 GPUs per node</li> <li>1 GPU node w/ 4x NVIDIA A100 GPUs per node</li> </ul>"},{"location":"hardware-overview/#big-memory-nodes","title":"Big Memory Nodes","text":"<p>There are 2 big memory nodes available to all users. Each big memory node has the Standard Intel Compute Node specifications, but with the following larger memory configurations:</p> <ul> <li>1 node w/ 768 GB of memory</li> <li>1 node w/ 1.54 TB of memory</li> </ul>"},{"location":"hardware-overview/#amd-nodes","title":"AMD Nodes","text":"<p>There are 40 nodes with AMD CPUs and the following configuration:</p> <ul> <li>2x AMD EPYC Rome processors (128 cores per node)</li> <li>960 GB Local SSD Storage </li> <li>256 GB Memory</li> </ul>"},{"location":"hardware-overview/#midway2-hpc-cluster","title":"Midway2 HPC Cluster","text":""},{"location":"hardware-overview/#operating-system-and-connectivity_1","title":"Operating System and Connectivity","text":"<p>Midway2 runs CentOs 8, and all standard nodes are connected via HDR InfiniBand (100 Gbps) interconnect.</p>"},{"location":"hardware-overview/#standard-compute-nodes_1","title":"Standard Compute Nodes","text":"<ul> <li>115 Intel Broadwell CPU-only compute nodes, each equipped with:<ul> <li>2x Intel E5-2680 v4 (28 cores per node)</li> <li>400 GB Local SSD Storage </li> <li>64 GB Memory </li> </ul> </li> </ul>"},{"location":"hardware-overview/#specialized-nodes_1","title":"Specialized Nodes","text":""},{"location":"hardware-overview/#gpu-nodes_1","title":"GPU Nodes","text":"<p>There are 6 GPU nodes that are part of the Midway2 communal resources. Each GPU node has the following configuration:</p> <ul> <li>GPU: 2x Nvidia K80</li> <li>CPU: 2 * Intel E5-2680 v4  2.40 GHz</li> <li>Memory: 128 GB </li> <li>Interconnect: InfiniBand FDR 56 Gb/s</li> </ul>"},{"location":"hardware-overview/#big-memory-nodes_1","title":"Big Memory Nodes","text":"<p>There is 1 big memory node available to all users. The big memory node has the Standard Intel Compute Node specifications, but with the following larger memory configurations:</p> <ul> <li>1 node w/ 512 GB of memory</li> </ul>"},{"location":"http/","title":"HTTP - Public folder","text":"<p>Midway2 only</p> <p>Please note that HTTP-based data sharing is currently supported on Midway2 only.</p> <p>RCC provides web access to data on their storage system via public_html directories in users\u2019 home directories.</p> Local path Corresponding URL /home/[your_CNetID]/public_html/research.dat http://users.rcc.uchicago.edu/~[your_CNetID]/research.dat <p>Ensure your home directory and <code>public_html</code> have the execute permissions. If the folder <code>public_html</code> does not exist, create it.  Optionally, ensure public_html has read permissions if you would like to allow indexing.</p> <p>You may set these permissions using the following commands: <pre><code>chmod o+x $HOME\nmkdir -p $HOME/public_html\nchmod o+x $HOME/public_html\n// optional; if you would like to allow directory listing.\nchmod o+r $HOME/public_html\n</code></pre> Files in public_html must also be readable by the web user, \"other\", but should not be made executable.</p> <p>You may set read permissions for web users/\"other\" using the following command: <pre><code>chmod o+r $HOME/public_html/research.dat\n</code></pre></p> <p>Note</p> <p>Use of these directories must conform with the RCC usage policy. Please notify RCC if you expect a large number of people to access data hosted here.</p>"},{"location":"jobs-management/","title":"Managing Jobs with Slurm","text":""},{"location":"jobs-management/#managing-jobs","title":"Managing Jobs","text":"<p>The Slurm job scheduler provides several command-line tools for checking on the status of your jobs and for managing them.</p>"},{"location":"jobs-management/#checking-job-status","title":"Checking Job Status","text":"<p>Use the <code>squeue</code> (slurm queue) command to check on the status of jobs. Running <code>squeue</code> with no flags will show the full queue (all pending and running jobs.)</p> <p>To view only the jobs that you have submitted, use the <code>--user</code> flag. <pre><code>squeue --user=&lt;CNetID&gt;\n</code></pre></p> <p>Any job with 0:00 in the TIME column is still waiting in the queue.</p> <p>To get information about all jobs that are waiting to run on the <code>gpu</code> partition, enter: <pre><code>squeue --state=PENDING --partition=gpu\n</code></pre></p> <p>To get information about all your jobs that are running on the <code>gpu</code> partition, type: <pre><code>squeue --state=RUNNING --partition=gpu --user=&lt;CNetID&gt;\n</code></pre></p> Advanced Tip <p>You can customize the output of <code>squeue</code> and <code>sacct</code> by configuring your slurm environment variables: <pre><code>export SACCT_FORMAT=\"jobid,partition,user,account%12,alloccpus,node%12,elapsed,totalcpu,maxRSS,ReqM\"\nexport SQUEUE_FORMAT=\"%13i %12j %10P %10u %12a %8T %9r %10l %.11L %5D %4C %8m %N\"\nsqueue -u cnetid\n</code></pre> You can put the two export commands into a configuration bash file <code>set_slurm_env.sh</code> like here, and <code>source set_slurm_env.sh</code> before running <code>squeue</code>.</p> <p>For more information, consult the command-line help by typing <code>squeue --help</code>, or visit the official online documentation.</p> <p>To get notification emails about the job status, add the following lines to your submission script replacing : <pre><code>#SBATCH --mail-type=ALL  # Mail events (NONE, BEGIN, END, FAIL, ALL)\n#SBATCH --mail-user=&lt;CNetID&gt;@rcc.uchicago.edu  # Where to send email\n</code></pre>"},{"location":"jobs-management/#pausing-and-resuming-jobs","title":"Pausing and Resuming Jobs","text":"<p>Jobs can be paused using the command: <pre><code>scontrol suspend &lt;job_id&gt;\n</code></pre> This can be especially useful if a job is producing a large output that needs to be moved to a new location before the job finishes.</p> <p>To resume a suspended job, run: <pre><code>scontrol resume &lt;job_id&gt;\n</code></pre></p>"},{"location":"jobs-management/#canceling-your-jobs","title":"Canceling your jobs","text":"<p>To cancel a job you have submitted, use the <code>scancel</code> command. This requires you to specify the id of the job you wish to cancel. </p> <p>For example, to cancel a job with id 8885128, do the following: <pre><code>scancel 8885128\n</code></pre> If you are unsure what is the id of the job you would like to cancel, see the JOBID column from running <code>squeue --user=&lt;CNetID&gt;</code>.</p> <p>To cancel all jobs you have submitted that are either running or waiting in the queue, enter the following: <pre><code>scancel --user=&lt;CNetID&gt;\n</code></pre></p>"},{"location":"jobs-management/#monitoring-job-memory","title":"Monitoring Job Memory","text":"<p>You can monitor your job by connecting to the compute node it is running on via SSH and using the <code>htop</code> command.</p> <p>To do this, run the following to see your running jobs and which compute nodes your jobs are running on: <pre><code>squeue --state=RUNNING --user=&lt;CNetID&gt;\n</code></pre> The last column of the output tells us which nodes are allocated for each job. You can connect to the compute node using the following command, where for example we are connecting to compute node midway2-0172. <pre><code>ssh midway2-0172\n</code></pre> Finally run: <pre><code>htop\n</code></pre> To view processes running on the node, including your job's process which will be listed under your CNetID in the USER column.</p>"},{"location":"jobs-overview/","title":"Running Jobs on Midway","text":"<p>This page describes core concepts for running programs on Midway2 or Midway3. We highly recommend reading it in its entirety. </p>"},{"location":"jobs-overview/#service-units-allocations-and-accounts","title":"Service Units, Allocations, and Accounts","text":"<p>All jobs running on Midway compute nodes consume Service Units (SUs). In short, SUs are a measure of the amount of computing resources (CPUs/GPUs) consumed on a compute cluster. </p> More information on SUs <p>In standard settings, 1 SU equals usage of 1 processing unit for 1 hour, but the exact calculation will vary depending on the amount of memory requested, as well as additional factors like the use of GPUs and CPU architecture. The aim of the Service Unit (SU) is to provide a \u201cfair\u201d account of computing resources.</p> <p>SUs are aquired through an allocation. Allocations are ultimately associated with Midway accounts, thus when you submit a job, you specify the account to which the SUs will be charged. If you submit a job on Midway2 without specifying an account, your default account (likely <code>pi-&lt;PI CNetID&gt;</code>) will be used. On Midway3 you must specify an account for a job to be successfully submitted.</p>"},{"location":"jobs-overview/#slurm-workload-manager","title":"Slurm Workload Manager","text":"<p>Midway2 and Midway3 are compute clusters shared by the entire University of Chicago community. Sharing computational resources creates unique challenges:</p> <ol> <li> <p>Jobs must be scheduled in a way that is fair to all users.</p> </li> <li> <p>Consumption of resources needs to be recorded.</p> </li> <li> <p>Access to resources needs to be controlled.</p> </li> </ol> <p>Consequently, the compute clusters use a scheduler to manage requests for access to compute resources. These requests are called jobs, and contain directions about the scripts/programs the user wants to run. In particular, we use the Slurm workload manager to schedule batch jobs as well as interactive access to compute nodes.  </p> <p>You can think of Slurm as the gatekeeper facilitating access the compute nodes. A user on a login node will submit a job to Slurm, which will decide (based on current node utilization and the requested parameters) which nodes to grant the user's job access to.  </p> <p>Once you have submitted a job via Slurm, there are several commands you may use to monitor and manage it.</p>"},{"location":"jobs-overview/#login-nodes-vs-compute-nodes","title":"Login nodes vs. Compute nodes","text":"<p>Once you have connected to Midway2 or Midway3 (see Connecting to Midway), you may work on one of the login nodes. Login nodes may be used for compiling and debugging code, installing software, editing and managing files, submitting jobs, or any other work that is not long-running or computationally intensive. Login nodes should never be used for computionally intensive work.</p> <p>All intensive computations should be performed on compute nodes. If you are unsure whether your computations will be intensive, please request an interactive session and continue your work once you have connected to the compute node.</p> <p>Warning</p> <p>Running computationally intensive jobs on the login nodes prevents other users from efficiently using the cluster. RCC System Administrators may terminate your processes without warning if your processes disrupt other users\u2019 work on the RCC cluster.  </p>"},{"location":"jobs-overview/#interactive-vs-batch-jobs","title":"Interactive vs. Batch Jobs","text":"<p>There are two main ways to run programs on Midway: Interactively, via an \"interactive job\", and non-interactively, via a \"batch job\".  </p> <p>In short, in an interactive session, you will load software modules and run your scripts in real-time, whereas when submitting batch jobs, you specify the software modules to be loaded and scripts to be run in advance.</p> <p>Interactive jobs allow you to interact with the program running on compute node/s (e.g., execute cells in a Jupyter Notebook) in real-time. This is great for exploratory work or troubleshooting. An interactive job will persist until you disconnect from the compute node, or until you reach the maximum requested time. *</p> <p>Batch jobs are non-interactive, as you submit a script to be executed on a compute node with no possibility of interactivity. A batch job doesn't require you to be logged in after submission, and ends when either (1) the script is finished running, (2) job's maximum time is reached, or (3) an error occurs.  </p> <p>The next page, Submitting Jobs, will show you how to initiate both types of jobs.</p>"},{"location":"jobs-overview/#partitions","title":"Partitions","text":"<p>Midway compute nodes are organized into \"partitions\", subsets of nodes typically grouped by their hardware or ownership. When submitting a job via Slurm, you specify the partition it will run on by setting the <code>--partition=&lt;partition&gt;</code> flag. The SLURM scheduler will allocate your job to any available compute node within the specified partition. If a user wants to submit a job to the particular compute node, this can be requested by adding <code>--nodelist=&lt;compute_node_ID&gt;</code>. Most users will submit jobs to a 'shared' partition: a partition accessible to all Midway users.  See the Partitions page for information about all of the Midway partitions.</p>"},{"location":"jobs-overview/#job-limits-and-qos","title":"Job Limits and QOS","text":"<p>To distribute computational resources fairly the RCC sets limits on the amount of computing resources that may be requested by a single user at any given time. These limits are enforced by the QOS (Quality of Service) assigned to each partition. A QOS is essentially a set of parameters, and each partition has its own, summarized on the Partitions page</p> <p>Groups participating in the cluster parternership program may customize resources limits for their partitions.</p> <p>Additional information on limits can be found by entering the command  <pre><code>rcchelp qos\n</code></pre> on any login or compute node on Midway2 or Midway3.</p> <p>Observe that these limits are often different depending on the partition.</p> <p>If your research requires a temporary exception to a particular limit, you may apply for a special allocation. Special allocations are evaluated on an individual basis and may or may not be granted.</p>"},{"location":"jobs-submitting/","title":"Submitting Jobs","text":"<p>This page describes how users can use Slurm scheduler to submit jobs (either Interactive or Batch) to Midway. The flowchart below illustrates the main steps in that process. </p> <p></p>"},{"location":"jobs-submitting/#interactive-jobs","title":"Interactive Jobs","text":"<p>Interactive jobs are the most intuitive way to use Midway, as they allow you to interact with the program running on compute node/s (e.g., execute cells in a Jupyter Notebook) in real-time. This is great for exploratory work or troubleshooting. An interactive job will persist until you disconnect from the compute node, or until you reach the maximum requested time. To request an interactive job with default parameters, run the following command while connected to a login node:  </p> Midway2Midway3 <pre><code>sinteractive\n</code></pre> <pre><code>sinteractive --account=pi-&lt;PI CNETID&gt;\n</code></pre> <p>Note</p> <p>On Midway3 you always need to explicitly specify the account to be charged for the job. Slurm will use the default partition (Midway2: <code>broadwl</code>, Midway3: <code>caslake</code>) if you do not specify it.</p> <p>Note</p> <p>On Midway3 to use the partitions with AMD CPUs, it is recommended that you log in to the <code>midway3-amd.rcc.uchicago.edu</code> login node and submit jobs from this node.</p> <p>As soon as the requested resources become available, <code>sinteractive</code> will do the following: 1. Log in to the compute node/s in the requested partition. 2. Change into the directory you were working in. 3. Set up X11 forwarding for displaying graphics. 4. Transfer your current shell environment, including any modules you have previously loaded.  </p> <p>By default, an interactive session times out after 2 hours. If you would like more than 2 hours, be sure to include a --time=HH:MM:SS flag to specify the necessary amount of time. For example, to request an interactive session for 6 hours, run the following command:</p> Midway2Midway3 <pre><code>sinteractive --time=06:00:00\n</code></pre> <pre><code>sinteractive --account=pi-&lt;PI's CNETID&gt; --time=06:00:00\n</code></pre> <p>There are many additional options for the sinteractive command, including options to select the number of nodes, the number of cores per node, the amount of memory, and so on. For example, to request exclusive use of two compute nodes on the default CPU partition for 8 hours, enter the following:</p> Midway2Midway3 <pre><code>sinteractive --exclusive --partition=broadwl --nodes=2 --time=08:00:00\n</code></pre> <pre><code>sinteractive --account=pi-&lt;PI's CNETID&gt; --exclusive --partition=caslake --nodes=2 --time=08:00:00\n</code></pre> <p>For more details about these and other useful parameters, read below about the <code>sbatch</code> command.</p> <p>Tip</p> <p>All options available in the <code>sbatch</code> command are also available for the <code>sinteractive</code> command. It's Slurm all the way down!</p>"},{"location":"jobs-submitting/#debug-qos","title":"Debug QOS","text":"<p>There is a debug QOS (Quality of Service) setup to help users quickly access some resources to debug or test their code before submitting their jobs to the main partition. The debug QOS will allow you to run one job and get up to 4 cores for 15 minutes without consuming SUs. To use the debug QOS, you have to specify <code>--time</code> as 15 minutes or less. For example, to get 2 cores for 15 minutes, you could run: <pre><code>sinteractive --qos=debug --time=00:15:00 --ntasks=2\n</code></pre> You can find out the available <code>qos</code> for your account with the command <code>rcchelp</code> <pre><code>rcchelp qos\n</code></pre></p>"},{"location":"jobs-submitting/#batch-jobs","title":"Batch Jobs","text":"<p>The <code>sbatch</code> command is used to request computing resources on the Midway clusters. Rather than specifying all the options in the command line, users typically write a sbatch script that contains all the commands and parameters neccessary to run a program on the cluster. Batch jobs are non-interactive, as you submit a program to be executed on a compute node with no possibility of interactivity. A batch job doesn't require you to be logged in after submission, and ends when either (1) the program is finished running, (2) job's maximum time is reached, or (3) an error occurs.</p>"},{"location":"jobs-submitting/#sbatch-scripts","title":"SBATCH Scripts","text":"<p>In an sbatch script, all Slurm parameters are declared with <code>#SBATCH</code>, followed by additional definitions.</p> <p>Here is an example of a Midway3 sbatch script:</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=example_sbatch\n#SBATCH --output=example_sbatch.out\n#SBATCH --error=example_sbatch.err\n#SBATCH --account=pi-shrek\n#SBATCH --time=03:30:00\n#SBATCH --partition=caslake\n#SBATCH --nodes=4\n#SBATCH --ntasks-per-node=14\n#SBATCH --mem-per-cpu=2000\n\nmodule load openmpi\nmpirun ./hello-mpi\n</code></pre> <p>And here is an explanation of what each of these parameters does:</p> Option Description <code>--job-name=my_run</code> Assigns name <code>my-run</code> to the job. <code>--output=my_run.out</code> Writes console output to file <code>my_run.out</code>. <code>--error=my_run.err</code> Writes error messages to file <code>my_run.err</code>. <code>--account=pi-shrek</code> Charges the job to the account <code>pi-shrek</code> (account format: <code>pi-&lt;PI CNetID&gt;</code>) <code>--time=03:30:00</code> Reserves the computing resources for 3 hours and 30 minutes max (actual time may be shorter if your run completes before this wall time). <code>--partition=caslake</code> Requests compute nodes from the Cascade Lake partition on the Midway3 cluster. <code>--nodes=4</code> Requests 4 compute nodes <code>--ntasks-per-node=14</code> Requests 14 cores (CPUs) per node, for a total of 14 * 4 = 56 cores. <code>--mem-per-cpu=2000</code> Requests 2000 MB (2 GB) of memory (RAM) per core, for a total of 2 * 14 = 28 GB per node. <p>In this example, we have requested 4 compute nodes with 14 CPUs each. Therefore, we have requested a total of 56 CPUs for running our program. The last two lines of the script load the OpenMPI module and launch the MPI-based executable that we have called <code>hello-mpi</code>.</p>"},{"location":"jobs-submitting/#submitting-a-batch-job","title":"Submitting a Batch Job","text":"<p>Continuing the example above, suppose that the sbatch script is saved in the current directory into a file called <code>example.sbatch</code>. This script is submitted to the cluster using the following command: <pre><code>sbatch ./example.sbatch\n</code></pre> or more generally: <pre><code>sbatch ./&lt;your_sbatch_file&gt;\n</code></pre></p> <p>See Example batch scripts for typical use cases.</p> <p>You can find more example sbatch submission scripts in the RCC SLURM workshop materials</p>"},{"location":"partitions/","title":"Slurm Partitions","text":"<p>Partitions are collections of compute nodes with similar characteristics. Normally, a user submits a job to a partition (via Slurm flag <code>--partition=&lt;partition&gt;</code>) and then the job is allocated to any idle compute node within that partition. To get a full list of available partitions, type the following command in the terminal <pre><code>sinfo -o \"%20P %5D %14F %4c %8G %8z %26f %N\"\n</code></pre> The typical output will include: </p> Column Description <code>AVAIL_FEATURES</code> Available features such as CPUs, GPUs, and internode interfaces <code>NODELIST</code> IDs of the compute nodes within the given partition <code>NODES(A/I/O/T)</code> Number of nodes by state in the format \"allocated/idle/other/total\" <code>S:C:T</code> Number of sockets, cores, and threads <p>If a user wants to submit their job to the particular compute node, this can be requested by adding the Slurm flag <code>--nodelist=&lt;compute_node_ID&gt;</code>. Compute nodes that differ in available features can be allocated by setting an additional constraint <code>--constraint=&lt;compute_node_feature&gt;</code>, for example <code>--constraint=v100</code> will allocate job to the compute node with NVIDIA V100 GPUs. </p>"},{"location":"partitions/#partitions","title":"Partitions","text":"<p>All Midway users can submit jobs to any of the shared partitions. </p> <p>Beagle3 users, in addition to shared partitions, have access to Beagle3 partitions too. </p> Midway2 - SharedMidway3 - SharedBeagle3 - Private Partition Nodes Cores/node CPU Type GPUs/node GPU Type Total Memory Per Node <code>broadwl</code> 323 28 e5-2680v4 None None 64 GB <code>broadwl-lc</code> 14 28 e5-2680v4 None None 64 GB <code>broadwl-lc</code> 1 28 e5-2680v4 None None 128 GB <code>bigmem2</code> 5 28 e5-2680v4 None None 512 GB <code>gpu2</code> 6 28 e5-2680v4 4 k80 128 GB <code>gpu2</code> 1 40 gold-6148 2 v100 96 GB Partition Nodes Cores/node CPU Type GPUs/node GPU Type Total Memory Per Node <code>caslake</code> 184 48 gold-6248r None None 192 GB <code>bigmem</code> 1 48 gold-6248r None None 768 GB <code>bigmem</code> 1 48 gold-6248r None None 1536 GB <code>amd-hm</code> 1 128 epyc-7702 None None 2048 GB <code>amd</code> 40 128 epyc-7702 None None 256 GB <code>gpu</code> 1 48 gold-6248r 4 a100 384 GB <code>gpu</code> 5 48 gold-6248r 4 v100 192 GB <code>gpu</code> 5 48 gold-6248r 4 rtx6000 192 GB Partition Nodes CPUs CPU Type GPUs GPU Type Total Memory <code>beagle3</code> 22 32 gold-6346 4 a40 256 GB <code>beagle3</code> 22 32 gold-6346 4 a100 256 GB <code>beagle3</code> 4 32 gold-6346 None None 512 GB"},{"location":"partitions/#partition-qos","title":"Partition QOS","text":"<p>This table details the job limits of each partition, set via a Quality of Service (QOS) accessible via <code>rcchelp qos</code>.</p> Midway2 QOS - SharedMidway3 QOS - Shared Partition Max Nodes Per User Max CPUs Per User Max Jobs Per User Max Wall Time <code>broadwl</code> 100 2800 100 36 H <code>gpu2</code> None None 10 36 H <code>bigmem2</code> None 112 5 36 H Partition Max Nodes Per User Max CPUs Per User Max Jobs Per User Max Wall Time <code>caslake</code> 100 4800 1000 36 H <code>gpu</code> None None 12 36 H <code>bigmem</code> 96 192 10 36 H <code>amd</code> 64 128 200 36 H <p>You may apply for a special allocation if your research requires a temporary exception to a particular limit. Special allocations are evaluated on an individual basis and may or may not be granted.</p>"},{"location":"partitions/#private-partitions-cpp","title":"Private Partitions (CPP)","text":"<p>These partitions are typically associated with a PI or group of PIs. They can be shared with other PIs or researchers across the University of Chicago and with external collaborators with a Midway account. </p> <ul> <li>General users: Check with your RCC account's PI for more information. </li> <li>PIs: Private partitions can be purchased via Cluster Partnership Program to accommodate the needs of your research group better. </li> </ul>"},{"location":"partitions/#institutional-partitions","title":"Institutional Partitions","text":"<p>Faculty and their group members can take advantage of institutional partitions dedicated to research within UChicago divisions, departments, and institutions:</p> <ul> <li><code>ssd</code>, <code>ssd-gpu</code>:   Social Science Research        <p>SSD Faculty (By default) and their group members (Apply) </p> </li> <li><code>kicp</code>, <code>kicp-gpu</code>: Cosmological Physics Research  <p>KICP Faculty (By default) and their group members (Apply)</p> </li> </ul> Midway3 Partition Nodes Cores/Node CPU Type GPUs GPU Type Total Memory <code>ssd</code> 18 48 gold-6248r None None 192 GB <code>ssd-gpu</code> 1 32 gold-6346 4 a100 256 GB <code>kicp</code> 6 48 gold-6248r None None 192 GB <code>kicp-gpu</code> 1 32 gold-5218 4 v100 192 GB"},{"location":"partitions/#institutional-partition-qos","title":"Institutional Partition QOS","text":"<p>This table details the job limits of each partition, set via a Quality of Service (QOS) accessible via <code>rcchelp qos</code>. </p> Midway3 QOS Partition AllowAccount QOS Max Wall Time <code>ssd</code> ssd ssd 36 H <code>ssd</code> ssd-stu ssd-stu 36 H <code>ssd-gpu</code> ssd ssd 36 H <code>ssd-gpu</code> ssd-stu ssd-stu 36 H <code>kicp</code> kicp kicp 48 H <code>kicp-gpu</code> kicp kicp 48 H <p>Note</p> <p>QOS for private and institutional partitions can be changed upon the owner's request. </p>"},{"location":"partitions/#do-i-have-access-to-a-partition","title":"Do I Have Access to a Partition?","text":"<p>To check if you have access to a partition, first determine which groups your account belongs to:  <pre><code>groups\n</code></pre> and then check AllowAccounts field in the partion summary:  <pre><code>scontrol show partition &lt;partition_name&gt;\n</code></pre> If AllowAccount is set to All then it is a shared partition available to all users. Otherwise, it is an institutional or private partition and one of your groups must match the AllowAccounts field in order to submit SLURM jobs to that partition. </p>"},{"location":"request_and_manage_allocations/","title":"Request and manage allocations","text":""},{"location":"request_and_manage_allocations/#checking-your-su-balance-and-usage","title":"Checking Your SU Balance and Usage","text":"<p>The <code>rcchelp</code> tool can be used to check account balances. After logging into Midway 2 or Midway 3, simply type: <pre><code>rcchelp balance\n</code></pre></p> <p>If you are a member of multiple groups, this will display the allocations and usage for all your groups. The <code>rcchelp balance</code> command has a number of options for summarizing allocation usage. For information on these options, type <pre><code>rcchelp balance --help\n</code></pre></p> <p>To see an overall summary of your usage, simply enter: <pre><code>rcchelp usage\n</code></pre></p>"},{"location":"samba/","title":"SAMBA (Network drive)","text":"<p>SAMBA allows one to connect to (or \u201cmount\u201d) their home and project directories on their local computer.   </p> <p>This method of accessing your RCC home and project space is only available from within the UChicago campus network. From off-campus, you will need to first connect through the UChicago VPN.</p> <p>Connecting from Windows </p> <p></p> <p>On a Windows computer, select \u201cMap Network Drive\u201d and enter one of the following UNC paths depending on which location on Midway you wish to connect to:  </p> Midway2Midway3 HomeProject2Scratch <pre><code>\\\\midwaysmb.rcc.uchicago.edu\\homes\n</code></pre> <pre><code>\\\\midwaysmb.rcc.uchicago.edu\\project2\n</code></pre> <pre><code>\\\\midwaysmb.rcc.uchicago.edu\\midway2-scratch\n</code></pre> HomeProjectScratch <pre><code>\\\\midway3smb1.rcc.uchicago.edu\\homes\n</code></pre> <pre><code>\\\\midway3smb1.rcc.uchicago.edu\\project\n</code></pre> <pre><code>\\\\midway3smb1.rcc.uchicago.edu\\midway3-scratch\n</code></pre> <p>Enter <code>ADLOCAL\\CNetID</code> for the username and enter your CNet password.  </p> <p>Connecting from macOS </p> <p> </p> <p>On a macOS X computer, select \u201cConnect to Server\u201d (from \"Go\" dropdown in Finder) and enter one of the following URLs depending on which location on Midway you wish to connect to:  </p> Midway2Midway3 HomeProject2Scratch <pre><code>smb://midwaysmb.rcc.uchicago.edu/homes\n</code></pre> <pre><code>smb://midwaysmb.rcc.uchicago.edu/project2\n</code></pre> <pre><code>smb://midwaysmb.rcc.uchicago.edu/midway2-scratch\n</code></pre> HomeProjectScratch <pre><code>smb://midway3smb1.rcc.uchicago.edu/homes\n</code></pre> <pre><code>smb://midway3smb1.rcc.uchicago.edu/project\n</code></pre> <pre><code>smb://midway3smb1.rcc.uchicago.edu/midway3-scratch\n</code></pre> <p>Enter <code>ADLOCAL\\CNetID</code> for the username and enter your CNet password.  </p> <p>Warning</p> <p>While transferring large files and/or datasets over SAMBA may be appealing, it slows file transfer for all other users. Please use Globus for large transfers.</p>"},{"location":"skyway-overview/","title":"Skyway","text":""},{"location":"skyway-overview/#what-is-skyway","title":"What is Skyway?","text":"<p>Skyway is an integrated platform developed at the RCC to allow users to burst computing workloads from the on-premise RCC cluster, Midway, to run on remote commercial cloud platforms such as Amazon AWS, Google GCP and Microsoft Azure. Skyway enables users to run computing tasks in the cloud from Midway in a seamless manner without needing to learn how to provision cloud resources. Since the user does not need to setup or manage cloud resources themselves, the result is improved productivity with a minimum learning curve.</p> <p>Please refer to the Skyway home page for more information.</p>"},{"location":"skyway-overview/#gaining-access","title":"Gaining Access","text":"<p>You first need an active RCC User account (see accounts and allocations page). Next, you should contact your PI or class instructors for access to Skyway. Alternatively, you can contact our Help Desk for assistance.</p>"},{"location":"skyway-overview/#connecting-and-running-jobs","title":"Connecting and Running Jobs","text":"<p>Once your RCC User account is active, you log in to the Midway cluster with your <code>CNetID</code> <pre><code>  ssh [CNetID]@midway2.rcc.uchicago.edu\n</code></pre> then log in to Skyway from Midway2: <pre><code>  ssh [CNetID]@skyway.rcc.uchicago.edu\n</code></pre> If successful, you will get access to the Skyway login node, where you can access to the following locations:</p> <ol> <li><code>/home/[CNetID]</code> This is the temporary home directory (no backup) for users on Skyway. Note, this is NOT the home file system on Midway, so you won\u2019t see any contents from your home directory on midway. Please do NOT store any sizable or important data here. (<code>TODO</code>: Add note here about changing $HOME environment variable to <code>/cloud/aws/[CNetID]</code>.)</li> <li><code>/project</code> and <code>/project2</code> This is the RCC high-performance capacity storage file systems from Midway, mounted on Skyway, with the same quotas and usages as on Midway. Just as with running jobs on Midway, /project and /project2 should be treated as the location for users to store the data they intend to keep. This also acts as a way to make data accessible between Skyway and midway as the /project and /project2 filesystems are mounted on both systems. Run <code>cd /project/&lt;labshare&gt;</code> or <code>/project2/&lt;labshare&gt;</code>, where <code>&lt;labshare&gt;</code> is the name of the lab account, to access the files by your lab or group. This will work even if the lab share directory does not appear in a file listing, e.g., <code>ls /project</code>.</li> <li><code>/cloud/[cloud]/[CNetID]</code> Options of [cloud]: aws or gcp This is the cloud scratch folder (no backup), which is intended for read/write of cloud compute jobs. For example, with Amazon cloud resources (AWS) The remote cloud S3 AWS bucket storage is mounted to Skyway at this path. Before submitting jobs to the cloud compute resources, users must first stage the data, scripts and executables their cloud job will use to the /cloud/aws/[CNetID] folder. After running their cloud compute job, users should then copy the data they wish to keep from the /cloud/aws/[CNetID] folder back to their project folder. Similarly, if users are using Google Cloud Platform (GCP), the scratch folder /cloud/gcp/[CNetID] should be used.</li> </ol> <p>You can create your own folders, upload data, write and compile codes, prepare job scripts and submit jobs in a similar manner to what you do on Midway.</p> <p>Skyway provides compiled software packages (i.e. <code>modules</code>) that you can load to build your codes or run your jobs. The list of the modules is given in the Skyway home page.</p> <p>You submit jobs to SLURM in a similar manner to what do on Midway. The difference is that you should specify different partitions and accounts corresponding to the cloud services you have access to (e.g. AWS or GCP). Additionally, the instance configuration should be specified via <code>--constraint</code>.</p>"},{"location":"skyway-overview/#troubleshooting","title":"Troubleshooting","text":"<p>For further assistance, please contact our Help Desk.</p>"},{"location":"ssh/","title":"SSH (Secure shell)","text":""},{"location":"ssh/#login-nodes","title":"Login nodes","text":"<p>When we say \"connect to RCC resources,\" what we're really saying is connect to one of Midway's login nodes. The login nodes are physical parts of the Midway cluster that are connected to the internet and serve as the \"foyer\" to the system. You connect to the login nodes to manage data, download and install packages, and submit jobs to the compute nodes, as the diagram below depicts.  </p> <p></p> <p>Upon logging in to Midway, you will automatically be connected to one of several login nodes.</p> <p>Warning</p> <p>The login nodes are NOT for computationally intensive work. For running computationally intensive programs, see Running Jobs on Midway.  </p> <p>Login and compute nodes are system-specific</p> <p>Note that Midway2 compute nodes can only be accessed from Midway2 login nodes, and likewise Midway3 compute nodes can only be accessed from Midway3 login nodes.  </p>"},{"location":"ssh/#connecting-with-ssh","title":"Connecting with SSH","text":"<p>Secure Shell (SSH) is a protocol that provides secure command-line access to remote resources such as Midway.</p> <p>Step 1: Open an SSH client === \"macOS or Linux Users\"\u00df</p> <pre><code> Open a **Terminal** (or iTerm2) window.\n</code></pre> Windows Users <p>Open a Powershell window.</p> <p>Mobaxterm</p> <p>Windows users running a version of Windows older than Windows 10\u2019s April 2018 release will have to download an SSH client to connect via SSH. We recommend the MobaXterm, client, although other options are available. Note that MobaXterm provides various functions such as direct file download which may offer a better experience than Powershell alone.</p> <p>Step 2: At the command line enter:</p> Midway2Midway3 <pre><code>ssh &lt;CNetID&gt;@midway2.rcc.uchicago.edu\n</code></pre> <pre><code>ssh &lt;CNetID&gt;@midway3.rcc.uchicago.edu\n</code></pre> <p>Step 3: Provide your CNetID password when prompted. Duo two-factor autentication will request you select from the available 2FA options to authenticate to Midway.</p> <pre><code>Duo two-factor authentication for user\n\nEnter a passcode or select one of the following options:\n\n1) receive a push code on your Duo app,\n2) Receive authentication through your phone number, and\n3) get an SMS code.\n\nPasscode or option (1-3):\n</code></pre> Note on SSH key-based authentication <p>In compliance with University security guidelines, 2FA is required with limited exceptions. If you believe you have a justifiable need for SSH key pairs, please contact our Help Desk and describe your situation. Once your justification is received, it will be reviewed by the RCC security team and we will follow up with you as soon as possible. </p> <p>Step 4: Choose from the available two-factor authentication options and finish the authentication process.</p> <p></p>"},{"location":"ssh/#x11-forwarding","title":"X11 Forwarding","text":"<p>X11 forwarding is a mechanism that allows you to forward a remote application's display to your local machine. To enable X11 forwarding when connecting to a Midway system with SSH, the -Y flag should be included:</p> Midway2Midway3 <pre><code>ssh -Y &lt;CNetID&gt;@midway2.rcc.uchicago.edu\n</code></pre> <pre><code>ssh -Y &lt;CNetID&gt;@midway3.rcc.uchicago.edu\n</code></pre> Note for macOS users <p>The program XQuartz is required to enable trusted X11 forwarding on a Mac.</p>"},{"location":"ssh/#data-sharing","title":"Data Sharing","text":""},{"location":"ssh/#file-permissions-and-ownership","title":"File Permissions and Ownership","text":"<p>Linux divides file permissions into read (<code>r</code>), write (<code>w</code>) and execute (<code>x</code>). The read permission allows to view or copy file contents, write permission allows to modify file content, and execute permission allows to run the file. These three permissions are defined for each of the three owner types typically referred to as User (<code>u</code>), Group (<code>g</code>), and Others (<code>o</code>). User is a single user who is the owner of the file, Group is a collection of users that has access to the file and Others consists of all the users on the system. Only the owner of a file or a directory is allowed to change its permissions or the group name to one of their groups. <pre><code>$ ls -l myfile.dat\n-rw-r--r-- 1 john pi-shreck 8444 Feb 20 12:49 myfile.dat\n</code></pre> Here is how you interpret the symbols on the left:</p> <p></p> <p>To set up user permissions to a folder recursively, you can run the following command in the absolute mode, providing three permission bits for the User (7), Group (5), and Others (5): <pre><code>$ chmod -R 755 myfolder\n</code></pre> where 7=4+2+1 (rwx for User), 5=4+0+1 (r-x for Group), and 5=4+0+1 (r-x for Others). This is equivalent to the following command in a symbolic mode:  <pre><code>$ chmod -R u=rwx,go=rx myfolder\n</code></pre> where, unlike the absolute mode, users can override (<code>=</code>), add (<code>+</code>) or remove (<code>-</code>) all or selected permissions for User (<code>u</code>), Group (<code>g</code>), or Others (<code>o</code>).</p> <p>Let\u2019s first summarize the default file system permission on Midway:</p> Directory Permissions Permissions bits <code>$HOME</code> drwx------ <code>700</code> \u2013 Accessible only to the owner <code>$SCRATCH</code> drwx------ <code>700</code> \u2013 Accessible only to the owner <code>/project/&lt;PI CNetID&gt;</code> drwxrws--- <code>770</code> \u2013 Read/write for the project group <code>/project2/&lt;PI CNetID&gt;</code> drwxrws--- <code>770</code> \u2013 Read/write for the project group <p>When new files or directories are created, the <code>umask</code> influences the default permissions of those files and directories.  The default value of <code>umask</code> is set to <code>0002</code>, which means that newly created files will have permissions of 664 (<code>-rw-r--r--</code>) and newly created directories will have permissions of 775 (<code>drwxrwxr-x</code>). In your home directory, the group owner will be set to your personal user group, the same as your CNetID, so you will still be the only user to access your files and directories. Note that in the project directories, the group owner will be the same as the directory owner and the default permission of 2775 (<code>drwxrwsr-x</code>). Here the extra bit <code>2</code> will replace group permission <code>x</code> with <code>s</code> to enable any user executing the folder files with the same permissions as the group owner of the file. </p> <p>Here is an example of what this means in practice:</p> <pre><code>$ ls -ld $HOME /project/rcc\ndrwx------ 108 wettstein wettstein 32768 2013-01-15 10:51 /home/wettstein\ndrwxrws---  24 root      rcc-staff 32768 2013-01-15 10:48 /project/rcc\n$ touch $HOME/newfile /project/rcc/newfile\n$ ls -l /project/rcc/newfile $HOME/newfile\n-rw-rw-r-- 1 wettstein wettstein 0 2013-01-15 10:48 /home/wettstein/newfile\n-rw-rw-r-- 1 wettstein rcc-staff 0 2013-01-15 10:48 /project/rcc/newfile\n</code></pre> <p>Both files are readable and writable by the group owner due to the default umask, but the group owner differs due to the sticky bit being set on <code>/project/rcc</code>. This applies only to newly created files and directories. If files or directories are moved from elsewhere, the ownership and permission may change.</p> <p>To change recursively a group owner use <code>chgrp -R</code>:  <pre><code>$ chgrp -R pi-shreck myfolder\n$ ls -l myfolder\n-rwxrwxr-x 1 john pi-shreck 0 Feb 20 12:49 myfile.dat\n-rwxrwxr-x 1 john pi-shreck 0 Feb 20 12:51 myfile2.dat\n</code></pre></p> <p>Sharing scripts with RCC</p> <p>If you want RCC to help you troubleshoot a Slurm submission script, please ensure that the script is not located in your <code>/home</code> or <code>/scratch</code> directories that no one except you can access. Instead, please place your script and associated input files in a project directory and set read permission to the group owner <code>pi-cnetid</code>.</p>"},{"location":"ssh/#advanced-access-control-via-acl","title":"Advanced Access Control via ACL","text":"<p>Access control list (ACL) provides an additional, more flexible permission mechanism for file systems. It is designed to assist with UNIX file permissions. ACL allows you to give permissions to any disk resource for any user or group. For more information, please visit the ACL manual at https://wiki.archlinux.org/index.php/Access_Control_Lists</p> <p>Note</p> <p>At present, ACL is only available on Midway2.</p>"},{"location":"ssh/#general-instructions","title":"General Instructions","text":"<p>This section discusses a more flexible mechanism to administer data permissions. Only Linux-based permissions are set for folders and files by default, as described in File System Permissions. However, this only supports the permissions at the owner/group/others level. A second mechanism is called \u201cAccess Control Lists\u201d (ACL), which provides precise control over any data (files or directories) customizable for individual users or groups. Before applying ACL to your data, please read and understand the following caveats.</p> <ul> <li> <p>By default, no ACL is set for user data. ACL provides a highly flexible permission control, however, it also brings increased complexity to user access and management. PIs will normally want to share an entire project folder with all group members; for this, the Linux-based permissions are enough. We suggest that users implement ACL controls only when necessary. One example is to protect confidential data in the project space by allowing only certain users to access confidential directories or files.</p> </li> <li> <p>After ACL is set, both Linux-based and ACL permissions will work together as a dual-guard system. The final effective access to data is granted only if permitted by both mechanisms. For example, if a folder is group-accessible to a user by Linux-based permission but restricted by ACL, the user cannot access this folder.</p> </li> <li> <p>Be sure you have enough knowledge setting up access via Linux-based permissions and ACL, i.e. you understand what \u201cusers\u201d, \u201cgroups\u201d and each attribute in \u201crwx\u201d mean and how to use them. Otherwise, please contact our Help Desk for assistance managing your data access. We are here and happy to help you set up the permissions to keep your data safe and accessible as required.</p> </li> </ul>"},{"location":"ssh/#examples","title":"Examples","text":""},{"location":"ssh/#sharing-folders-with-a-user-within-a-group","title":"Sharing folders with a user within a group","text":"<p>Suppose there is a folder tree as below, and you want to allow the folder <code>my_folder</code> to be accessible by the user <code>jim</code> only, and <code>jim</code> is already a member of your group <code>rcctemp1</code>:</p> <pre><code>/project2/rcctemp1\n   |- my_folder\n   |- other_stuff\n</code></pre> <p>Before using ACL, you need to confirm that this folder is permitted by all members in the group <code>rcctemp1</code>:</p> <pre><code>$ cd /project2\n$ chgrp -R rcctemp1 my_folder\n$ chmod -R 770 rcctemp1\n$ cd rcctemp1\n</code></pre> <p>At this moment, the folder <code>rcctemp1</code> becomes readable and writable by all members of group <code>rcctemp1</code>. Then, you can use the <code>setfacl</code> command to control the individual users access precisely. First, you need to remove the default group access by ACL:</p> <pre><code>$ setfacl -m g::--- my_folder\n</code></pre> <p>Although the command <code>ls -l</code> will still display group <code>rwx</code> access for the <code>my_folder</code> folder in the Linux-based permissions, users cannot access it anymore due to the permission set by ACL. Then, you can grant the user <code>jim</code> access to the folder:</p> <pre><code>$ setfacl -m u:jim:rwx my_folder\n</code></pre> <p>At this step, the user <code>jim</code> has both read and write permissions to the folder <code>my_folder</code>. You can set up permissions for each user the way you want.</p> <p>To view the list of configured accesses on the folder <code>my_folder</code>, run:</p> <pre><code>$ getfacl my_folder\n# file: my_folder\n# owner: root\n# group: rcctemp1\nuser::rwx\nuser:jim:rwx\ngroup::---\nmask::rwx\nother::---\n</code></pre> <p>To revoke the permissions of the user <code>jim</code> to the folder:</p> <pre><code>$ setfacl -x u:jim my_folder\n</code></pre> <p>To clean up (remove) all ACL controls to the folder:</p> <pre><code>$ setfacl -b my_folder\n</code></pre>"},{"location":"ssh/#sharing-folders-with-a-user-outside-a-group","title":"Sharing folders with a user outside a group","text":"<p>Suppose you would like to share your folder <code>/project2/pi-cnetid/my_own_folder/shared_data</code> with another RCC user with CNetID <code>coworkerA</code>, who is not in your group <code>pi-cnetid</code>. As the owner of the folder, you can execute the following two commands <pre><code>setfacl -Rm d:u:coworkerA:rw-,u:coworkerA:rw- /project2/pi-cnetid/my_own_folder/shared_data\nsetfacl -m u:coworkerA:--x /project2/pi-cnetid/my_own_folder\n</code></pre> The first command changes the ACL permission of the folder (and recursively its sub-folders and files) to allow the user <code>corworkerA</code> to read and write. The second command adds execute permission to <code>coworkerA</code> so that <code>coworkerA</code> can access the parent folder <code>/project2/pi-cnetid/my_own_folder</code> but without read nor write permissions.</p>"},{"location":"ssh/#multiple-affiliations","title":"Multiple Affiliations","text":"<p>Both general users and PIs can join multiple pi-accounts by submitting a request. Once approved by the corresponding PI who owns the pi-account, a requestor will be added to the new group without losing membership in any existing groups. This will allow not only access to project folders but also the use of resources dedicated to the pi-account, including SUs and dedicated partitions. </p>"},{"location":"ssh/#secure-copy-scp-data-transfer-through-ssh","title":"Secure Copy (SCP) - Data transfer through SSH","text":"<p>macOS and Linux systems provide a <code>scp</code> command, which can be accessed from the command line. </p> <p>To transfer files from your local computer to your home directory (see Data Storage for information on directories), open a terminal window and issue the command:  </p> <p>For single files:</p> Midway2Midway3 <pre><code>scp &lt;some file&gt; &lt;CNetID&gt;@midway2.rcc.uchicago.edu:\n</code></pre> <pre><code>scp &lt;some file&gt; &lt;CNetID&gt;@midway3.rcc.uchicago.edu:\n</code></pre> <p>For directories:</p> Midway2Midway3 <pre><code>scp -r &lt;some dir&gt; &lt;CNetID&gt;@midway2.rcc.uchicago.edu:\n</code></pre> <pre><code>scp -r &lt;some dir&gt; &lt;CNetID&gt;@midway3.rcc.uchicago.edu:\n</code></pre> <p>To transfer to a directory other than your home directory (for example, project):</p> Midway2Midway3 <pre><code>scp -r &lt;some dir&gt; &lt;CNetID&gt;@midway2.rcc.uchicago.edu:/project2\n</code></pre> <pre><code>scp -r &lt;some dir&gt; &lt;CNetID&gt;@midway3.rcc.uchicago.edu:/project\n</code></pre> <p>When prompted, enter your CNetID password.</p>"},{"location":"thinlinc/","title":"ThinLinc - Remote desktop","text":""},{"location":"thinlinc/#connecting-with-thinlinc","title":"Connecting with ThinLinc","text":"<p>ThinLinc is a remote desktop server used to connect to Midway and obtain a remote graphical user interface (GUI). We recommend using ThinLinc to use software that requires a GUI.</p>"},{"location":"thinlinc/#thinlinc-web-browser","title":"ThinLinc Web Browser","text":"<p>Point your web browser to the following web address:</p> Midway2Midway3 <p><pre><code>https://midway2.rcc.uchicago.edu.\n</code></pre> You will land on this page: </p> <p><pre><code>https://midway3.rcc.uchicago.edu.\n</code></pre> You will land on this page: </p> <p>Proceed to log in with your CNetID and password.</p> <p>Duo two-factor autentication will request you select from the available 2FA options to authenticate to Midway.</p> <pre><code>Duo two-factor authentication for user\n\nEnter a passcode or select one of the following options:\n\n1) receive a push code on your Duo app,\n2) Receive authentication through your phone number, and\n3) get an SMS code.\n\nPasscode or option (1-3):\n</code></pre>"},{"location":"thinlinc/#thinlinc-desktop-client","title":"ThinLinc Desktop Client","text":"<p>Download and install the appropriate ThinLinc client here:\u00df https://www.cendio.com/thinlinc/download</p> <p>Open the ThinLinc client and use the following information to set up your connection to Midway:</p> Midway2Midway3 <p><pre><code>Server: midway2.rcc.uchicago.edu\nUsername: CNetID\nPassword: CNetID password\n</code></pre> Your client should look similar to this: </p> <p><pre><code>Server: midway3.rcc.uchicago.edu\nUsername: CNetID\nPassword: CNetID password\n</code></pre> Your client should look similar to this: </p> <p>ThinLinc will default to open in a fullscreen window that fills <code>all monitors</code>. To change this use <code>Options</code> from the initial login interface. </p> <p>After clicking the <code>Connect</code> button, Duo two-factor autentication will request you select from the available 2FA options to authenticate to Midway.</p> <pre><code>Duo two-factor authentication for user\n\nEnter a passcode or select one of the following options:\n\n1) receive a push code on your Duo app,\n2) Receive authentication through your phone number, and\n3) get an SMS code.\n\nPasscode or option (1-3):\n</code></pre>"},{"location":"thinlinc/#the-thinlinc-interface","title":"The ThinLinc Interface","text":"<p>Upon successfully logging in via ThinLinc, you will be connected to a login node and presented with a desktop interface. Select Applications tab in the top left corner to access the terminal, file browser, and other utilities.</p> <p></p> <p>To view all available applications, click the 3x3 dot grid on the bottom of the Activties Tab:</p> <p></p> <p>To copy/paste text between your computer and ThinLinc (when copying code into the Terminal, for example), open the side toolbar by clicking the small blue handle. Click the Clipboard icon. The text field that just open will be synced with the clipboard on the server, so you can copy and paste to and from this text field.</p> <p></p> <p>With ThinLinc it is possible to maintain an active session after you have closed your connection to Midway. To disconnect from Midway but maintain an active session, simply close the ThinLinc window. You must have \"End existing session\" unchecked for this to occur.</p> <p>To exit ThinLinc and terminate your session completely, simply exit or close the ThinLinc application.</p>"},{"location":"user-policy/","title":"RCC User Policy","text":"<p>By collaborating with the Research Computing Center (RCC), you may have access to various RCC computer systems, networks, applications, data, and/or other technology assets. By using any RCC resource, you are agreeing to abide by the usage policy below and to use RCC resources in a responsible and ethical manner. Please read the information below carefully. Violations of the RCC usage policy can result in the removal of access to RCC resources and the reporting of suspicious activities to the appropriate authorities.</p>"},{"location":"user-policy/#general-usage-policy","title":"General usage policy","text":"<p>The following principles govern the usage of all RCC resources. You are required to abide by these principles.</p> <ul> <li>You are responsible for the proper use of the tools each computer system provides and for the confidentiality of any sensitive information entrusted to you.  </li> <li>You must not use RCC resources for illegal or malicious purposes such as harassment, disrupting communications or services, or unauthorized monitoring of communications.  </li> <li>You must refrain from the unethical use of RCC resources, including unauthorized use of computer accounts and resources assigned to others, use of computing facilities for private business or political purposes or private gain, academic or scientific dishonesty, or violation of software license agreements.  </li> <li>You will respect the confidentiality and privacy of individuals whose records you may have access to in accordance with RCC policy, University of Chicago ethical standards, and state and federal laws.  </li> <li>You should immediately report any suspected breach of security, policy violation, or suspicious activity to the RCC Help Desk and your supervisor, principal investigator, or sponsor.  </li> <li>You will not attempt to subvert or circumvent any system security features.  </li> <li>You will not attempt to subvert or circumvent any system that allocates resources.  </li> <li>You should be aware that all computer activity and files on these systems may be monitored by RCC system administrators and appropriate authorities.  </li> </ul> <p>Your account may be terminated by RCC staff for failure to follow these principles. The RCC provides computational and data storage resources for the sole purpose of supporting legitimate research activities at the University of Chicago. A user must refrain from using RCC resources for any task other than that which was described on their account application form. RCC users are also required to familiarize themselves with the University of Chicago\u2019s Eligibility and Acceptable Use Policy for Information Technology.</p>"},{"location":"user-policy/#user-accounts-and-passwords","title":"User accounts and passwords","text":"<p>Your account credentials are assigned to you alone and should not be shared with anyone, including co-workers, trainers, or computer support staff. If you believe your account password has been compromised, report the incident to RCC support staff immediately and change your password through the University of Chicago\u2019s CNetID password service. Make sure you are the only person who has access to your 2FA device.</p> <p>Many mechanisms exist for sharing data and working collaboratively with your colleagues, and the RCC will assist you with these tools as necessary. There is never a reason to share account and/or password information.</p>"},{"location":"user-policy/#data-policy-and-security","title":"Data policy and security","text":"<p>The RCC maintains an open research network that provides shared computing and data management resources to a large number of University of Chicago researchers and their collaborators. Therefore, the RCC cannot guarantee the complete security of data stored on any RCC system. While information security is a primary concern of the RCC, neither the RCC nor the University of Chicago shall be held liable for any breach of security resulting in the compromise of sensitive or confidential data. It is the sole responsibility of the user to ensure proper measures have been taken to protect sensitive or confidential information.</p> <p>RCC system administrators and support staff that have super-user privileges are able to view any and all data on RCC systems unless it is encrypted. RCC system administrators will only look at user data to provide assistance to the owner, or if there is sufficient reason to believe a serious problem or security threat exists that could disrupt the work of others.</p>"},{"location":"user-policy/#protected-health-information","title":"Protected Health Information","text":"<p>Currently, the RCC provides MidwayR, a secure data enclave, compute resource that is compliant with the Health Insurance Portability and Accountability Act of 1996 (HIPAA) regulations for the storage or processing of Protected Health Information (PHI).</p> <p>If your project necessitates the use of PHI data, please inform RCC staff of your requirements and we will work to determine if your data/project can be accommodated on MidwayR.</p>"},{"location":"user-policy/#data-encryption","title":"Data Encryption","text":"<p>The RCC provides encrypted file systems on MidwayR. Any data that is sensitive needs to be stored on MidwayR.</p>"},{"location":"user-policy/#data-integrity-and-retention-policy","title":"Data Integrity and Retention Policy","text":"<p>The RCC strives to maintain robust filesystems and archival storage facilities with the highest levels of performance and reliability. However, neither the RCC nor the University of Chicago shall be held liable for any loss of data. The RCC provides an archival tape backup system in a separate location from the main disk array for use in recovering data in the event of corruption, deletion, or machine failure.</p> <p>Note: Not all filesystems and machines are backed up. Due to limited space in the archival storage system, only /home and /project directories are backed up to archival tape. If your project has special data retention requirements, please alert RCC support staff so appropriate actions can be taken to help ensure the protection and recoverability of your data.</p>"},{"location":"FAQ/accounts-and-allocations/","title":"Accounts and Allocations FAQ","text":""},{"location":"FAQ/accounts-and-allocations/#accounts-and-access-to-midway","title":"Accounts and Access to Midway","text":"How do I become an RCC user?  <p>RCC user account requests should be submitted via our online application forms. See RCC Account Request for more information.</p> How do I access RCC systems?  <p>There are various ways to access RCC systems.</p> <p>To access RCC systems interactively, use ThinLinc or an SSH client with enabled X11 forwarding. See Connecting to RCC Resources for details.</p> <p>To access files stored on RCC systems, use SCP, Globus Online, or SAMBA. See Data Transfer for details.</p> How do I request access to a PI\u2019s account if I already have an account on Midway?  <p>Please submit a User Account Request and provide your CNetID and the PI Account name (typically pi- followed by the CNetID of the PI). The PI will receive an automated email requesting authorization for this request.</p> What is my RCC username and password?  <p>RCC uses the University of Chicago CNetIDs for user credentials. Once your RCC account is created, your RCC username and password will be the same as your CNetID credentials.</p> Can an external collaborator get a CNetID to log in to RCC?  <p>RCC can create CNetIDs for external collaborators. See RCC Account Request for more information.</p> What should I do if I left the university and my CNetID password no longer works? <p>You can use your CNetID for authentication after you have left, but IT Services may expire it when you leave. If you have an RCC account, but you still can\u2019t log in,  password authentication has likely been disabled by IT Services. Please contact our Help Desk to request re-enabling access to your account.</p> How do I change/reset my password? <p>RCC cannot change or reset your password. Go to the CNet Password Recovery page to change or reset your password.</p> What groups am I a member of?  <p>To list the groups you are a member of, type <code>groups</code> on any RCC system.</p> Will I still have access to Midway after I leave the University? <p>Typically, UChicago IT will terminate your CNET ID soon after leaving the university. In order to regain access to Midway, you will need to request a new account.</p>"},{"location":"FAQ/accounts-and-allocations/#allocations-and-service-units","title":"Allocations and Service Units","text":"What is an allocation?  <p>An allocation is a specified number of computing and storage resources granted to a PI or an education account. An allocation is necessary to run jobs on RCC systems. See RCC Allocations for more details.</p> What is a service unit (SU)?  <p>A service unit (SU) is roughly equal to 1 core-hour; for a more precise definition, see RCC Service Units.</p> How do I obtain an allocation?  <p>The RCC accepts proposals for large (\u201cResearch II\u201d) allocations bi-annually. Proposals for medium-sized allocations, special purpose allocations for time-critical research, and allocations for education and outreach may be submitted at any time. See RCC Allocations for more information.</p> How is compute cluster usage charged to my account?  <p>The charge associated with a job on any RCC system is a function of (1) the number of cores allocated to the job, and (2) the elapsed wall-clock time (in hours).</p> How do I check the balance of my allocation?  <p>The <code>rcchelp</code> tool is the easiest way to check your account balance. Run</p> <pre><code>rcchelp balance  \n</code></pre> How do I check how my allocation has been used?  <p>The <code>rcchelp</code> tool has several options for summarizing allocation usage. For a summary, run</p> <p><pre><code>rcchelp usage\n</code></pre> To see usage per job, run</p> <p><pre><code>rcchelp usage --byjob\n</code></pre> If you are the PI, you may use --byuser option to see the individual usage of your group members</p> <pre><code>rcchelp usage --byuser\n</code></pre>"},{"location":"FAQ/connecting/","title":"Connecting to Midway FAQ","text":"Why is ThinLinc spontaneously disconnecting? <p>Occasional ThinLinc instability is a known issue. First, wait 30 minutes to an hour and try again. If you are still having connection issues, try removing the following lines (or any similar) from the file <code>~/.bashrc</code> in your home directory (Unnecessary Anaconda configurations have been known to cause ThinLinc trouble): <pre><code>    __conda_setup=\"$('/software/python-anaconda-2020.02-el7-x86_64/bin/conda' 'shell.bash' 'hook' 2&gt; /dev/null)\"\nif [ $? -eq 0 ]; then\n    eval \"$__conda_setup\"\nelse\n    if [ -f \"/software/python-anaconda-2020.02-el7-x86_64/etc/profile.d/conda.sh\" ]; then\n        . \"/software/python-anaconda-2020.02-el7-x86_64/etc/profile.d/conda.sh\"\n    else\n        export PATH=\"/software/python-anaconda-2020.02-el7-x86_64/bin:$PATH\"\n    fi\nfi\nunset __conda_setup\n</code></pre></p> <p>If the problem still persists, please contact the RCC help desk.</p> What login shells are supported and how do I change my default shell?  <p>RCC supports the following shells: <pre><code>/bin/bash\n/bin/tcsh\n/bin/zsh\n</code></pre> Use this command to change your default shell: <pre><code>chsh -s /path/to/shell \n</code></pre></p> <p>It may take up to 30 minutes for that change to take effect.</p> Is remote access with Mosh supported?  <p>Yes. To use Mosh, first log in to Midway via SSH, and add the command module load mosh to your <code>~/.bashrc</code> (or <code>~/.zshenv</code> if you use zsh). Then, you can log in by entering the following command in a terminal window:</p> Midway2Midway3 <pre><code>mosh &lt;CNetID&gt;@midway2.rcc.uchicago.edu \n</code></pre> <pre><code>mosh &lt;CNetID&gt;@midway3.rcc.uchicago.edu\n</code></pre> Is SSH key authentication allowed on RCC machines?  <p>In compliance with University security guidelines, 2FA is required with limited exceptions. If you believe you have a justifiable need for SSH key pairs, please contact our Help Desk and describe your situation. Once your justification is received, it will be reviewed by the RCC security team and we will follow up with you as soon as possible.   </p> Why am I getting \u201cssh_exchange_identification: read: Connection reset by peer\u201d when I try to log in via SSH?  <p>You can get this error if you incorrectly enter your password too many times. This is a security measure that is in place to limit the ability for malicious users to use brute force SSH attacks against our systems.</p> <p>After 3 failed password entry attempts, an IP address will be blocked for 4 hours.</p> <p>While you wait for the block to be lifted, you should still be able to access the RCC system using ThinLinc.</p> Why am I getting prompted for YubiKey when I try to log in via SSH?  <p>There are few reasons to get that error message. Please enroll in two factor authentication if you have not done already by visiting https://2fa.rcc.uchicago.edu. Please make sure you run:</p> Midway2Midway3 <pre><code>ssh -Y CNetID@midway2.rcc.uchicago.edu \n</code></pre> <pre><code>ssh -Y CNetID@midway3.rcc.uchicago.edu\n</code></pre> <p>Finally, please make sure your RCC account has not expired.</p>"},{"location":"FAQ/data-management/","title":"Data Management FAQ","text":"How much storage space do I have? <p>Use the <code>quota</code> command to get a summary of your current file system usage and available storage space.</p> I'm over quota...what do I do? <p>You can meet user quota (1-4) or group quota (1-6) by following the steps listed below:</p> <ol> <li> <p>Remove unused data to meet quota requirements. If the group quota is exceeded, consider removing former users' directories if they are large. You need to let us know the path to folders you don't have permission to remove and ask PI to respond to this thread with approval.</p> </li> <li> <p>You can compress multiple files into zip or tar archives to reduce both file size and the total number of files.  </p> </li> <li> <p>Temporary solution: move files to /scratch with a higher quota limit. Note that /scratch is not backed up, and you should not use it for long-term storage.</p> </li> <li> <p>Move files to another storage. It could be a local machine or a cloud. See the data transfer section in the new user guide we are working on: https://rcc-uchicago.github.io/user-guide/midway23/midway_data_transfer/</p> </li> <li> <p>Ask PI to submit a research allocation request to get more storage (If standard research allocation is not enough - special research allocation can give temporary storage of a greater size) https://rcc.uchicago.edu/accounts-allocations/request-allocation</p> </li> <li> <p>Ask PI to purchase storage via the cluster partnership program: https://rcc.uchicago.edu/support-and-services/cluster-partnership-program </p> </li> </ol> Why can't I write files into my home directory? <p>An error writing files typically happens when a user is over-quota. Please ensure that you are under quota both in terms of size and number of files with the <code>quota</code> command.</p> How do I get my storage quota increased? <p>Additional storage space can be purchased through the Cluster Partnership Program. You may also request additional storage as part of a Research II Allocation or Special Allocation.</p> How do I share files with others? <p>The recommended way to share files with members of your group is to store them in the <code>/project</code> or <code>/project2</code> directory for your group. Project directories are created for all PI and project accounts. File and directory permissions can be customized to allow access to users within the group, as well as RCC users that do not belong to your group.</p> I accidentally deleted or lost a file. How do I restore it? <p>The best way to recover a recently deleted, corrupted or lost file is from a snapshot. See Data Recovery and Backups for more information.</p> How do I request a restore of my files from tape backup? <p>The RCC maintains tape backups of all home and project directories. These tape backups are intended for disaster recovery purposes only. There is no long-term history of files on tape. In most cases, you should use file system snapshots to retrieve recover files. See Data Recovery and Backups for more information.</p>"},{"location":"FAQ/general/","title":"General Questions","text":"How do I access the Data Visualization lab in the Zar room of Crerar Library?  <p>The Zar room and its visualization equipment can be reserved for events, classes, or visualization work by contacting our Help Desk. More information regarding RCC\u2019s visualization facilities can be found on RCC's Data Visualization page.</p> How do I cite RCC in my publications and talks?  <p>Citations and acknowledgements help RCC demonstrate the importance of computational resources and support staff in research at the University of Chicago. We ask that an acknolwedgment be given to the RCC in any presentation or publication of results that were made possible by RCC resources. Please reference the RCC as \u201cThe University of Chicago Research Computing Center\u201d in citations and acknowledgements. Here are a few examples of suggested text:</p> <p>\"This work was completed in part with resources provided by the University of Chicago Research Computing Center.\"</p> <p>\"We are grateful for the support of the University of Chicago Research Computing Center for assistance with the calculations carried out in this work.\"</p> <p>\"We acknowledge the University of Chicago Research Computing Center for support of this work.\"</p> <p>If you cite or acknowledge the RCC in your work, please notify the RCC by sending an email to info@rcc.uchicago.edu.</p>"},{"location":"FAQ/running-jobs/","title":"Running Jobs on Midway FAQ","text":""},{"location":"FAQ/running-jobs/#set-up-and-general-questions","title":"Set-up and general questions","text":"How do I submit a job to Midway? <p>RCC systems use Slurm to manage resources and job queues. For advice on how to run specific types of jobs, consult the Running jobs on midway section of the User Guide.</p> Can I login directly to a compute node? <p>You can start up an interactive session on a compute node with the <code>sinteractive</code> command. This command takes the same arguments as <code>sbatch</code>. More information about interactive jobs, see submitting Interactive Jobs.</p> How do I run jobs in parallel? <p>There are many ways to configure parallel jobs. The best approach will depend on your software and resource requirements. For more information on two commonly used approaches, see Parallel batch jobs and Job arrays.</p> Are there any limits to running jobs on Midway? <p>Run <code>rcchelp qos</code> on Midway to view the current \"Quality of Service\"--a set of parameters and contraints that includes maximum number of jobs and maximum wall time.</p> I am a member of multiple accounts. How do I choose which allocation is charged? <p>If you belong to multiple accounts, jobs will get charged to your default account unless you specify the <code>--account=&lt;account_name&gt;</code> option when you submit a job with sbatch. You may request a change in your default account by contacting our Help Desk.  </p> How can I get emails when my job starts and when it finishes? <p>For security reasons, sending out notification emails directly using the standard slurm command <code>#SBATCH --mail-user=&lt;CNetID&gt;@uchicago.edu</code> is not allowed. As a robust alternative, we suggest using the RCC mail server to send out notification emails. Update your script with the following lines: <pre><code>#SBATCH --mail-type=ALL                        # Mail events (NONE, BEGIN, END, FAIL, ALL)\n#SBATCH --mail-user=&lt;CNetID&gt;@rcc.uchicago.edu  # Where to send email\n</code></pre></p> How do I run jobs that need to run longer than the maximum wall time? <p>The RCC queuing system is designed to provide fair resource allocation to all RCC users. The maximum wall time is intended to prevent individual users from using more than their fair share of cluster resources.</p> <p>If you have specific computing tasks that cannot be solved with the current constraints, please submit a special request for resources to our Help Desk.</p> Can I create a cron job? <p>The RCC does not support users creating cron jobs. However, it is possible to use Slurm to submit \u201ccron-like\u201d jobs. See Cron-like jobs for more information.  </p>"},{"location":"FAQ/running-jobs/#job-submission-trouble","title":"Job submission trouble","text":"Why is my job not starting? <p>This could be due to a variety of factors. Running <code>squeue --user=&lt;userid&gt;</code> can will help to find the answer; see in particular the NODELIST(REASON) column in the <code>squeue</code> output. A job that is waiting in the queue may show one of the following labels in this column:</p> <p>(Priority): Other jobs currently have higher priority than your job.</p> <p>(Resources): Your job has enough priority to run, but there aren\u2019t yet enough free resources to run it.</p> <p>(QOSResourceLimit): Your job exceeds the QOS limits. The QOS limits include wall time, number of jobs a user can have running at once, number of nodes a user can use at once, and so on. For example, if you are at or near the limit of number of jobs that can be run at once, your job will become eligible to run as soon as other jobs finish.</p> <p>Please contact RCC support if you believe that your job is not being handled correctly by the Slurm queuing system.</p> <p>Note: If you see a large number of jobs that aren\u2019t running when many resources are idle, it is possible that RCC staff have scheduled an upcoming maintenance window. In this case, any jobs requesting a wall time that overlaps with the maintenance window will remain in the queue until after the maintainence period is over. The RCC staff will typically notify users via email prior to performing a maintenance and after a maintenance is completed.</p> Why does my job fail after a few seconds? <p>This is most likely because there is an error in your job submission script, or because the program you are trying to run is producing an error and terminating prematurely.</p> <p>If you need help troubleshooting the issue, please send your job submission script, as well as the error generated by your job submission script to ourHelp Desk</p> Why does my job fail with message \u201cexceeded memory limit, being killed\u201d? <p>Let's understand this with an example. Let's say on the main midway2 partition, broadwl, Slurm allocates 2 GB of memory per allocated CPU by default. If your computations require more than the default amount, you should adjust the memory allocated to your job with the <code>--mem</code> or <code>--mem-per-cpu</code> flags. For example, to request 10 cores and 40 GB of memory on a broadwl node, include these options when running <code>sbatch</code> or <code>sinteractive</code>: <code>--ntasks=1 --cpus-per-task=10 --mem=40G</code>.</p> Why does my <code>sinteractive</code> job fail with \u201cConnection closed.\u201d?  <p>There are two likely explanations for this error.</p> <p>One possibility is that you are over the time limit. The default walltime for sinteractive is 2 hours. This can be increased by including the <code>--time</code> flag to your <code>sinteractive</code> call.</p> <p>Another possiblity is that your job exceeded the memory limit. You can resolve this by requesting additional memory using <code>--mem</code> or <code>--mem-per-cpu</code>.</p> Why does my <code>sinteractive</code> job fail with <code>ssh: symbol lookup error: ssh: undefined symbol: EVP_KDF_ctrl, version OPENSSL_1_1_1b?</code> <p>The error <code>ssh: symbol lookup error: ssh: undefined symbol: EVP_KDF_ctrl, version OPENSSL_1_1_1b</code> indicates the mismatch version of the OpenSSL used by <code>sinteractive</code> and that by the <code>python</code> module loaded in your shell environment. There are two options to resolve this issue:</p> <p>1) Prepend <code>LD_LBIRARY_PATH</code> with the path to the SSH-compatible version of OpenSSL: <pre><code>export LD_LIBRARY_PATH=/lib64:$LD_LIBRARY_PATH\n</code></pre> and run <code>sinteractive</code> again.</p> <p>2) Unload the <code>python</code> module: <pre><code>module unload python\n</code></pre> then run <code>sinteractive</code> again, and load the <code>python/anaconda</code> module within the interactive session.</p>"},{"location":"FAQ/running-jobs/#technical-questions","title":"Technical questions","text":"What compilers does the RCC support? <p>The RCC supports the GNU, Intel, PGI and NVidia\u2019s CUDA compilers.</p> Which versions of MPI does RCC support? <p>The RCC maintains OpenMPI, IntelMPI, and MVAPICH2 compilers. See Message Passing Interface (MPI) for more information and instructions for using these MPI frameworks.</p> Can RCC help me parallelize and optimize my code? <p>The RCC support staff are available to consult with you or your research team to help parallelize and optimize your code for use on RCC systems. Contact our Help Desk to set up a consultation.</p> Does RCC provide GPU computing resources? <p>Yes. The RCC high-performance systems provide GPU-equipped compute nodes. For instructions on using the GPU nodes, see GPU jobs.</p>"},{"location":"FAQ/software/","title":"Software FAQ","text":"What software does RCC offer on its compute systems?  <p>Software available within RCC is constantly evolving. We regularly install new software, and new versions of existing software. Information about available software and how to use specific software pacakges can be found in the Software section of the User Guide.</p> <p>To view the current list of installed software on RCC systems, run <pre><code>module avail\n</code></pre> To view the list of available versions for a specific software, run <pre><code>module avail &lt;software&gt;\n</code></pre></p> How do I get help with RCC software?  <p>Documentation for many programs can be viewed with the following command.</p> <p><pre><code>man &lt;command&gt;\n</code></pre> Many programs also provide documentation through command-line options such as <code>--help</code> or <code>-h</code>. For example,</p> <p><pre><code>module load gcc\n</code></pre> <pre><code>gcc --help\n</code></pre> RCC also maintains supplementary documentation for software specific to our systems. Consult the Software page for more information.</p> Why is my favorite command not available?  <p>Most likely it is because you have not loaded the appropriate software module. Most software packages are only available after first loading the appropriate software module. See Software for more information on how to access pre-installed software on RCC systems.</p> Why do I get an error that says a module cannot be loaded due to a conflict? <p>Occassionally, modules are incompatible with each other and cannot be loaded simultaneously. The module command typically gives you hints about which previously loaded module conflicts with the one you are trying to load. If you see such an error, try unloading a module with this command:</p> <pre><code>module unload &lt;module-name&gt;\n</code></pre> How do I request installation of a new or updated software package?  <p>Please contact our Help Desk with the details of your software request, including what software package you need and which version of the software you prefer.</p> Why can\u2019t I run Gaussian? <p>Creators of Gaussian have historically had a strict usage policy, so we have limited its availability on RCC systems. If you need to use Gaussian for your research, please contact our Help Desk to request access.</p>"},{"location":"midwayR3/accessing/","title":"Accessing","text":""},{"location":"midwayR3/accessing/#accessing-midwayr3","title":"Accessing MidwayR3","text":"<p>To use MidwayR3 resources, you will need to have a MidwayR3 user account. Although both Midway and MidwayR3 use CNetID for authentication, they do not share accounts. If you do not have a MidwayR3 user account, please see the Getting Started section for how to apply for an account.</p> <p>Note</p> <p>General users can apply only after the PI has been approved for MidwayR3 account. Only authorized users listed in Data Use Agreement (DUA) and/or Internal Review Board (IRB) protocol can get access to a project hosted on MidwayR3 upon PI approval. If the list of authorized users is not set explicitly in the data use agreement, then any UChicago researcher approved by the PI can work with the project data hosted on MidwayR3.</p> <p>Please also note that you must have enabled  Two Factor Authentication for your CNetID before connecting to MidwayR.</p>"},{"location":"midwayR3/connecting/","title":"Connecting","text":""},{"location":"midwayR3/connecting/#quick-overview","title":"Quick Overview:","text":"<p>Because MidwayR3 has no connection to the Internet, accessing MidwayR3 is a two-step process where you first connect to the Secure Data Enclave (SDE) Desktop using the Azure Virtual Desktop (AVD) client and then log into MidwayR3.</p> <p></p> <ul> <li>You do not need to be connected to the University VPN before connecting to MidwayR. Azure takes care of encrypting and securing all communications between your local computer and the Virtual Desktop.</li> <li>You can connect from your web browser, in addition to the Microsoft Remote Desktop application.</li> <li>It is not possible to copy/paste between your local computer and the Virtual Desktop. However, you can still copy/paste from within the AVD environment.</li> </ul>"},{"location":"midwayR3/connecting/#connecting-to-sde-desktop","title":"Connecting To SDE Desktop","text":""},{"location":"midwayR3/connecting/#using-web-browser","title":"Using Web Browser","text":"<p>Navigate to https://rdweb.wvd.microsoft.com/arm/webclient on your computer's web browser. Select \"AVD Host\" to launch the Virtual Desktop:</p> <p></p> <p>You will be prompted for your username (cnetID@uchicago.edu) and password:</p> <p></p> <p>After logging in, you will arrive at the Desktop where you can launch applications:</p> <p></p>"},{"location":"midwayR3/connecting/#using-microsoft-remote-desktop-client","title":"Using Microsoft Remote Desktop Client","text":"<p>You can also connect from the Microsoft Remote Desktop App, available for download on the Windows or MacOS app store. After launching the app, click on the \"+\" symbol and select \"Add Workspace\":</p> <p></p> <p>In the dialog box, put the URL \"https://rdweb.wvd.microsoft.com\":</p> <p></p> <p>You should then be able to launch the AVD from within the App.</p>"},{"location":"midwayR3/connecting/#connecting-to-midwayr3","title":"Connecting To MidwayR3","text":"<p>Once you are connected to the SDE environment using the AVD client following the steps given above, please follow one of the methods below to connect to MidwayR3 from the SDE environment.</p>"},{"location":"midwayR3/connecting/#using-ssh-client","title":"Using SSH client","text":"<p>You can use Powershell or PuTTy terminal to connect to MidwayR3. Run the following command: ssh @sde.rcc.uchicago.edu:"},{"location":"midwayR3/connecting/#using-thinlinc","title":"Using ThinLinc","text":"<p>ThinLinc is a remote desktop server application. It is recommended to use ThinLinc when you run software that requires a graphical user interface, or \"GUI\" (e.g., Stata, MATLAB). To use ThinLinc to connect to MidwayR3, please take the following steps on the SDE desktop:</p> <ol> <li> <p>Open a browser (Chrome or Firefox) and enter    <code>https://sde.rcc.uchicago.edu</code> in the address bar.</p> </li> <li> <p>Enter your CNetID and password on the ThinLinc login page: </p> </li> <li> <p>Follow the two-factor authentication prompts: </p> </li> <li> <p>If the login process is successful, you will see a Linux desktop environment. To access the command-line shell, select the Applications menu, then the Terminal icon: </p> </li> <li> <p>After selecting the Terminal icon, you should see a Terminal window appear. Typically this will give a console prompt showing which login node you are connected to: </p> </li> </ol> <p>To exit ThinLinc, type <code>exit</code> in any Terminal window, select the top-right icon, then select the \"Log Out\" menu item and follow the instructions. Finally, close the browser window. </p>"},{"location":"midwayR3/connecting/#logging-out","title":"Logging Out","text":"<p>You can log out of the AVD by clicking the \"Log off\" application on the Desktop.</p> <p>Warning</p> <p>Once logged off, any data stored in your AVD user-space will be purged.</p>"},{"location":"midwayR3/data-transfer/","title":"Data transfer","text":""},{"location":"midwayR3/data-transfer/#transferring-data-to-the-sde-desktop-and-then-to-midwayr3","title":"Transferring Data to the SDE desktop and then to MidwayR3","text":"<p>MidwayR3 has no connection to the internet and can only be accessed by logging into the SDE desktop.  </p> <p>Warning</p> <p>Once your login session ends with Azure, all data that was downloaded will be purged from the AVD.</p>"},{"location":"midwayR3/data-transfer/#method-1-recommended-transferring-using-uchicago-box-from-within-the-sde-desktop","title":"Method #1 (recommended) : Transferring Using UChicago Box from within the SDE Desktop","text":"<p>Once you logged in to the MidwayR3 desktop (see Connecting to the SDE Desktop), you can open a browser and log in to a Box account at https://uchicago.account.box.com: </p> <p>Download files into the SDE desktop using the built-in Box Download function: </p> <p>By default it will copy the files into your Downloads folder, e.g. C:\\Users[CNetID]\\Downloads: </p> <p>When you've transferred all your files from Box to the SDE desktop, open the WinSCP application:  </p> <p>Connect to midwayr.rcc.uchicago.edu with your CNet ID and password: </p> <p>Add the host key if this is your first time using WinSCP to move files: </p> <p>Move the folders or files you wish to MidwayR3 using the Upload function -- please do remember there is a 30GB quota on the home directories and a 500GB quota (default) on project, so we strongly recommend keeping your data in project: </p> <p>Warning</p> <p>Once your login session ends with Azure, all data that was downloaded will be purged from the AVD.</p> <p>In special cases where you need to transfer more than 30GB, please contact us at midwayr-help@rcc.uchicago.edu. </p>"},{"location":"midwayR3/data-transfer/#method-2-transferring-using-a-hardware-encrypted-usb-device","title":"Method #2 : Transferring Using a Hardware-Encrypted USB Device","text":"<p>Hardware-encrypted USB drives (available from IT Services at the @TechBar in the Regenstein Library) are recognized by the AVD client, and data can be transferred directly (uploading and downloading) using one of those devices.</p>"},{"location":"midwayR3/overview/","title":"Welcome to MidwayR3 user guide","text":"<p>MidwayR3 is the RCC's secure cluster that provides a secure computing environment to support research with higher security standard requirements.</p> <p>Examples of sensitive data include:</p> <ul> <li>Personally Identifiable Information (PII)</li> <li>Protected Health Information (PHI)</li> <li>Controlled Unclassified Information (CUI)</li> <li>Data covered under the Health Insurance Portability and Accountability Act (HIPAA)</li> <li>Data covered under the Federal Information Security Management Act (FISMA)</li> <li>Data covered under the Federal Education Rights and Privacy Act (FERPA)</li> <li>Data with security requirements set by the MSU Institutional Review Board (IRB)</li> <li>Controlled access data from the NIH Database of Genotypes and Phenotypes (dbGaP)</li> <li>Commercial data with security requirements set by the Data Use Agreement (DUA)</li> </ul> <p>The research data classification is provided by University Research Administration. If you have any questions about MidwayR3, please email midwayr-help@rcc.uchicago.edu.</p>"},{"location":"midwayR3/overview/#system-overview","title":"System Overview","text":"<p>MidwayR3 is comprised of two login nodes and four compute nodes. The total installed storage on MidwayR3 is 441TB. It uses SLURM as its workload manager and the software environment module system to manage installed software.  Login Nodes: MidwayR3 hosts login nodes with the following specifications: </p> <ul> <li>CPUs: 2x Intel Xeon Gold 6130 2.1GHz</li> <li>Total cores per node: 16 cores</li> <li>Threads per core: 2</li> <li>Memory: 96GB of RAM</li> </ul> <p>Compute Nodes:  There are no limits on SU usage at the moment. PIs don't need to apply for SUs allocation. See Partitions</p> <p>Network:</p> <ul> <li>Intel Ethernet Controller 10Gbps Adapter</li> <li>Mellanox EDR Infiniband up to 100Gbps bandwidth and a sub-microsecond latency</li> <li>Neither compute nor login nodes have direct access to the Internet</li> </ul> <p>File Systems:</p> <ul> <li>MidwayR3 utilizes a GPFS filesystem, with <code>/home</code> and <code>/project</code> directories mounted for private and collaborative work.  The <code>/home/&lt;CNetID&gt;</code> directory has a strict quota of 30GB and the quota for <code>/project/pi-&lt;PI_CNETID&gt;-&lt;ProjectName&gt;</code> varies depending on the project with the default startup storage allocation of 500 GB. MidwayR3 does not have a scratch filesystem.</li> </ul> <p>Using MidwayR3:</p> <ul> <li>MidwayR3 nodes run CentOS 7. Its job scheduler is the SLURM. Slurm commands enable you to submit, manage, monitor, and control your jobs.</li> </ul> <p>Software:</p> <ul> <li>Organized in modules</li> <li>Use <code>module avail</code>, to see what is available</li> <li>To load a particular available package, for example, <code>gcc</code> version 8.2.0, do <code>module load gcc/8.2.0</code></li> <li>If you do not specify a version of the package, the default one is loaded</li> <li>To see what environmental variables are modified when <code>gcc/8.2.0</code> is loaded, do <code>module show gcc/8.2.0</code></li> <li>To unload <code>gcc/8.2.0</code>, do <code>module unload gcc/8.2.0</code></li> </ul>"},{"location":"midwayR3/partitions/","title":"Slurm Partitions","text":"<p>Partitions are collections of compute nodes with similar characteristics. Normaly, a user submits a job to a partition (via Slurm flag <code>--partition=&lt;partition&gt;</code>) and then the job is allocated to any idle compute node within that partition. To get a full list of available partitions, type the following command in the terminal <pre><code>sinfo -o \"%20P %5D %14F %4c %8G %8z %26f %N\"\n</code></pre> The typical output will include: </p> Column Description <code>S:C:T</code> Number of sockets, cores, and threads <code>NODES(A/I/O/T)</code> Number of nodes by state in the format \"allocated/idle/other/total\" <code>AVAIL_FEATURES</code> Available features such as CPUs, GPUs, internode intrefaces <code>NODELIST</code> Compute nodes IDs within the given partition <p>If a user wants to submit their job to the particular compute node, this can be requested by adding the Slurm flag <code>--nodelist=&lt;compute_node_ID&gt;</code>. Compute nodes that differ in available features can be allocated by setting an additional constraint <code>--constraint=&lt;compute_node_feature&gt;</code>, for example <code>--constraint=v100</code> will allocate job to the compute node with NVIDIA V100 GPUs.</p>"},{"location":"midwayR3/partitions/#midwayr3-shared-partitions","title":"MidwayR3 Shared Partitions","text":"<p>All MidwayR3 users can submit jobs to any of the following shared partitions:</p> MidwayR3 Partition Nodes CPUs CPU Type Total Memory Local Scratch skylake 4 40 gold-6148 96 GB 900 MB caslake-bigmem 1 40 gold-6248 1536 GB 900 MB"},{"location":"midwayR3/partitions/#midwayr3-institutional-partitions","title":"MidwayR3 Institutional Partitions","text":"<p>If you are a MidwayR3 researcher affiliated with the Booth School of Business, you are entitled to Booth purchased harware resources. Each node has 1.8 GB of local scratch.</p> MidwayR3 Partition Nodes Cores/nodes CPU Type GPUs GPU Type Total Memory Local Scratch Nodelist booth 1 48 gold-6248 None None 1536 GB 1.8 GB sde006 booth 2 48 gold-6248r None None 384 GB 1.8 GB sde[007-008] booth 1 48 gold-6248r 2 v100 384 GB 1.8 GB sde009"},{"location":"midwayR3/partitions/#midwayr3-qoc","title":"MidwayR3 QOC","text":"MidwayR3 QOS QOS Partitions Max Wall Time Max Sub Job / User normal skylake, caslake-bigmem 36 H 350 long skylake, caslake-bigmem, booth 7 Days 200 <p>To see a full list of QOS run the following <pre><code>sacctmgr list qos format=Name,MaxWall,MaxSubmitPU\n</code></pre></p> <p>Note</p> <p>QOS for private and institutional partitions can be changed upon owner's request.</p>"},{"location":"midwayR3/partitions/#private-partitions","title":"Private Partitions","text":"<p>Private MidwayR partitions are typically associated with a research group with access approved by PI. Private partitions can be purchased via RCC Cluster Partnership Program to better accomodate the needs of a research group. PI may request to change QOS of private partitions at any time.</p>"},{"location":"midwayR3/partitions/#do-i-have-access-to-a-partition","title":"Do I Have Access to a Partition?","text":"<p>To check if you have access to a partition, first determine which groups your account belongs to:  <pre><code>groups\n</code></pre> and then check AllowAccounts field in the partion summary:  <pre><code>scontrol show partition &lt;partition_name&gt;\n</code></pre> If AllowAccount is set to All then it is a shared partition available to all users. Otherwise, it is an institutional or private partition and one of your groups must match the AllowAccounts field in order to submit SLURM jobs to that partition. </p>"},{"location":"midwayR3/running-jobs/","title":"Running jobs on midwayR3","text":"<p>Running jobs on MidwayR3 is no different from running jobs on Midway. These HPC systems use SLURM scheduler to allocate jobs to compute nodes. The SUs are shared across Midway2, Midway3, and MidwayR, meaning that if you have allocated SUs on Midway2/Midway3 you will also have them on MidwayR3. However, the space allocation is different on MidwayR3. The default storage for each project is 500 GB, and it can be increased if required.   Upon connecting to midwayR3, you will be located on one of the midwayR3 login nodes. Login nodes may be used for compiling and debugging code, installing software, editing and managing files, and submitting jobs. Login nodes should not be used for computionally intensive work. All intensive computations should be performed on compute nodes. </p>"},{"location":"mistakes-to-avoid/list/","title":"Common Mistakes to Avoid","text":"<ol> <li> <p>Do not go over your storage quota. Exceeding your storage quota can lead to many problems including batch jobs failing, confusing error messages, and the inability to use X11 forwarding. Be sure to routinely run the <code>rcchelp quota</code> command to check your usage. If more space is needed, then you can remove files to comply with number-of-files and size quotas or request an allocation. </p> </li> <li> <p>Do not install conda environments using <code>conda create --name=&lt;env_name&gt;</code>.  By default, this command will install a virtual conda environment into <code>/home</code> directory, which has a low quota. Because Anaconda environments often require a large amount of storage and number of files this may easily result in exceeding quota. Instead install virtual environments inside /project or /project2 directories by running <code>conda create --prefix=/project/&lt;PI_CnetID&gt;/&lt;CNetID/anaconda/&lt;env_name&gt;</code>.</p> </li> <li> <p>Do not run jobs on the login nodes.  When you connect to a cluster via SSH, you land on the login node, which is shared by all users. The login node is reserved for submitting jobs, compiling codes, installing software, and running short tests that use only a few CPU cores and finish within a few minutes. Anything more intensive must be submitted to the Slurm job scheduler as either a batch or interactive job. Failure to comply with this rule may result in your account being temporarily suspended.</p> </li> <li> <p>Do not try to access the Internet from batch or interactive jobs.  All jobs submitted to the Slurm job scheduler run on the compute nodes that do not have Internet access. This includes ThinLinc sessions. Because of this, a running job cannot download files, install packages or connect to GitHub. Before submitting the job, you will need to perform these operations on the login node.</p> </li> <li> <p>Do not allocate more than one CPU core for serial jobs.  Serial codes cannot run in parallel, so using more than one CPU core will not cause the job to run faster. Instead, doing so will waste SUs allocated to your PI. See tips on figuring out if your code can run in parallel and for information about Job Arrays, which allow one to run many jobs simultaneously.</p> </li> <li> <p>Do not run jobs with a parallel code without first conducting a scaling analysis. If your code runs in parallel then you need to determine the optimal number of nodes and CPU-cores to use. The same is true if it can use multiple GPUs. To do this, perform a scaling analysis.</p> </li> <li> <p>Do not request a GPU for a code that can only use CPUs. Only codes that have been explicitly written to use GPUs can take advantage of GPUs.  Allocating a GPU for a CPU only code will not speed up the execution time but it will increase your queue time, waste resources and lower the priority of your next job submission. Furthermore, some codes are written to use only a single GPU.</p> </li> <li> <p>Do not use the system GCC when a newer version is needed The GNU Compiler Collection (GCC) provides a suite of compilers (gcc, g++, gfortran) and related tools. You can determine the version of the system GCC by running the command \"gcc --version\". If the system version is insufficient then load the appropriate environment module to make a newer version available. Run the command \"module avail gcc\". Learn more about environment modules.</p> </li> <li> <p>Do not load environment modules using only the partial name. A common practice for Python users is to issue the \"module load python\" command. You should always specify the full name of the environment module (e.g., module load python/anaconda-2022.05) to make sure the default version hasn't changed. Also, you should avoid loading environment modules in your ~/.bashrc file. Instead, do this in Slurm scripts and on the command line when needed.</p> </li> <li> <p>Do not write temporary files to <code>/scratch</code> if your job has high throughput I/O  Temporary files may accumulate and exceed your quota (both in terms of size and/or number of files) unless removed on time. If your job is not distributed across multiple nodes and has high throughput I/O of many small files (size &lt; 4 MB), you may have faster performance when writing temporary files to the local scratch compared to the shared scratch. However, the local scratch is not justified if your temporary files exceed the local scratch space. </p> </li> <li> <p>Do not compile and install heavy software using login nodes Sometimes software installation time can be dramatically reduced by using multiple cores. However, compute-intensive jobs are not permitted on login nodes and may be killed to provide equal opportunities for other connected users. Instead of login nodes, use a build partition, which is dedicated to software installation.</p> </li> </ol>"},{"location":"software/cmake/","title":"CMake","text":"<p>CMake is a widely used tool for configuring the build of a software package. It is recommended to load the latest version of <code>cmake</code> before configuring your build.</p> <pre><code>   module load cmake/3.19\n</code></pre>"},{"location":"software/compilers/","title":"Compilers","text":"<p>In addition to having access to the provided software modules, you can always compile and use your codes or other open-source codes on Midway. You can check out the source files from GitHub (via <code>git clone</code>) or copy from your local machine to your own space on Midway (e.g. under <code>/home</code> or <code>/project</code>).</p> <p>Depending on the requirements of the codes, you can load the compilers and libraries that are provided as modules.</p> <p>GNU GCC, Intel and AMD compilers are provided through modules on Midway2 and Midway3. The table below lists details about each of the module-provided compilers.</p> Midway2Midway3 Vendor Module Language Compiler GNU <code>gcc</code> C C++Fortran <code>gcc</code><code>g++</code><code>gfortran</code> Intel <code>intel</code> C C++Fortran <code>icc</code><code>icpc</code><code>ifort</code> Vendor Module Language Compiler GNU <code>gcc</code> C C++Fortran <code>gcc</code><code>g++</code><code>gfortran</code> Intel <code>intel</code> C C++Fortran <code>icc</code><code>icpc</code><code>ifort</code> AMD <code>aocc</code> C C++ <code>clang</code><code>clang++</code> NVIDIA <code>nvhpc</code> C C++Fortran <code>nvc</code><code>nvc++</code><code>nvfortran</code> <p>Note</p> <p>AMD compilers are available on the Midway3 AMD cluster and with <code>module use /software/modulefiles-amd</code>.</p> <p>Each module may have different versions. The default version is always loaded if you do not specify explicitly with <code>module load</code>. You should check with <code>module avail</code> to see what versions are available. For example, on Midway3 <code>module avail gcc</code> will return</p> <p><pre><code>---------------------------- /software/modulefiles -----------------------------\ngcc/7.4.0  gcc/10.2.0(default) \n</code></pre> and <code>module avail intel</code> <pre><code>---------------------------- /software/modulefiles -----------------------------\nintel/16.0               \nintel/18.0.5             \nintel/19.1.1(default)\nintel/2022.0\n</code></pre> You can check the changes to the environment variables made by a particular module by the <code>module show</code> command.</p>"},{"location":"software/compilers/#multithreading-with-openmp","title":"Multithreading with OpenMP","text":"<p>To compile your code or software packages that support multithreading with OpenMP, you just need to add to the compiling flags <code>-fopenmp</code> for GCC and AMD compilers and <code>-qopenmp</code> for Intel compilers.</p>"},{"location":"software/compilers/#message-passing-interface-mpi","title":"Message-passing interface (MPI)","text":"<p>To compile your code or software packages with MPI, you need to load the MPI modules that are available. The list of libraries and software suites that provide MPI libraries is given as below.</p> Midway2Midway3 Library Module Language Wrapper OpenMPI <code>openmpi</code> C C++Fortran <code>mpicc</code><code>mpicxx</code><code>mpif90</code> MPICH <code>mpich</code> C C++Fortran <code>mpicc</code><code>mpicxx</code><code>mpif90</code> Intel <code>intelmpi</code><code>oneaapi</code> C C++Fortran <code>mpiicc</code><code>mpiicpc</code><code>mpiifort</code> Library Module Language Wrapper OpenMPI <code>openmpi</code> C C++Fortran <code>mpicc</code><code>mpicxx</code><code>mpif90</code> MPICH <code>mpich</code> C C++Fortran <code>mpicc</code><code>mpicxx</code><code>mpif90</code> Intel <code>intelmpi</code> C C++Fortran <code>mpiicc</code><code>mpiicpc</code><code>mpiifort</code> NVIDIA <code>nvhpc</code> C C++Fortran <code>nvc</code><code>nvc++</code><code>nvfortran</code> <p>Note</p> <p>For AMD C/C++ compilers <code>clang</code> and <code>clang++</code> (available with <code>module load aocc</code>), you need to load a MPI module (e.g. <code>openmpi</code> or <code>intelmpi</code>) to compile MPI codes.</p> <p>Note</p> <p>Experienced users can build the MPI libraries of their preferences in their own space using the provided compilers above.</p>"},{"location":"software/compilers/#gpu-codes","title":"GPU codes","text":"<p>To compile GPU codes, you can use NVIDIA CUDA Toolkit and HPC SDK, or Intel OneAPI.</p>"},{"location":"software/compilers/#nvidia-toolsets","title":"NVIDIA toolsets","text":""},{"location":"software/compilers/#cuda-toolkit","title":"CUDA Toolkit","text":"<p>There are several NVIDIA CUDA toolkit versions on Midway2 and Midway3. You can check the version provided with <code>module avail cuda</code>. On Midway3 there are several CUDA versions:</p> <p><pre><code>--------------------------- /software/modulefiles -----------------------------\ncuda/10.2  cuda/11.2  cuda/11.3  cuda/11.5 cuda/11.7 cuda/12.0 \n</code></pre> The current version of the GPU driver on the GPU nodes supports all the above CUDA toolkit versions. You can check the GPU driver version via the <code>nvidia-smi</code> command after loading a <code>cuda</code> module.</p> <p>Note</p> <p>Although you can compile your CUDA code on the login node with the CUDA toolkit module loaded,  running the generated binary on the login node will fail because there is no GPU on the login node.</p>"},{"location":"software/compilers/#nvidia-hpc-sdk","title":"NVIDIA HPC SDK","text":"<p>NVIDIA HPC SDK provides another toolset for compiling GPU-enabled C/C++/Fortran codes via OpenACC. NVIDIA HPC SDK also provides a set of GPU-optimized tools and math libraries. These compilers are available through the <code>nvhpc</code> module. <pre><code>module load nvhpc\n</code></pre> and check for the location of the compilers <pre><code>which nvc++\nwhich nvfortran\n</code></pre></p>"},{"location":"software/compilers/#intel-oneapi","title":"Intel oneAPI","text":"<p>The DPC++ Compiler compiles C++ and SYCL* source files with code for both CPU and a wide range of compute accelerators such as GPU and FPGA. You can load the <code>oneapi</code> module on Midway2 to get access to this compiler: <pre><code>module load oneapi\n</code></pre> and remember to source the shell script to setup the necessary environment variables: <pre><code>source /software/oneapi-2021.beta7-el7-x86_64/inteloneapi/setvars.sh\n</code></pre> and check for the location of the compilers <pre><code>which dpcpp\n</code></pre></p>"},{"location":"software/compilers/#go","title":"Go","text":"<p>Go is an open-source compiled programming language that gain an rapidly increasing interest and usage by the industry.  Although Go is not a traditional compiler, we include it here for convenience. You can load Go as a module on Midway3.</p>"},{"location":"software/compilers/#java","title":"Java","text":"<p>Java is available as modules on Midway2 and Midway3. You can check the available modules via <code>module avail java</code>.</p>"},{"location":"software/dev-tools/","title":"Developer Tools","text":""},{"location":"software/dev-tools/#debuggers","title":"Debuggers","text":"<p>On Midway3 GDB and Valgrind as modules for debugging and memory leak checking with your code.</p> <p>To debug your code with <code>gdb</code>, you compile your code with <code>-g</code> and then run <code>gdb</code>: <pre><code>  g++ -g -o test test.cpp\n  module load gdb\n  gdb --args ./test param1 param2\n</code></pre> You can also use <code>gdb</code> to debug your Python codes. Alternatively, use <code>pdb</code> <pre><code>  python3 -m pdb myscript.py\n</code></pre> To check if there is any memory leak with your code, use <code>valgrind</code> <pre><code>  g++ -g -o test test.cpp\n  module load valgrind\n  valgrind --leak-check=full --track-origins=yes ./test param1 param2\n</code></pre> Please refer to the official documentation of GDB and Valgrind for more information.</p> <p>For CUDA codes, after loading the CUDA toolkit module you can use <code>cuda-gdb</code> and <code>cuda-memcheck</code>.</p>"},{"location":"software/dev-tools/#profilers","title":"Profilers","text":"<p>TAU is a tool for profiling and tracing toolkit for performance analysis of parallel programs written in Fortran, C, C++, UPC, Java, Python. You can load <code>tau/2.31</code> on Midway3.</p> <p>The TAU binaries and scripts in the subfolders <code>$TAU_HOME/bin</code>, and several <code>Makefile.*</code> in <code>$TAU_HOME/lib</code> . To use TAU, you need to rebuild your code using one of the scripts inside <code>$TAU_HOME/bin</code>: C codes use <code>tau_cc.sh</code>; C++ codes use <code>tau_cxx.sh</code> (see for example, the doc page at OLCF). Should a new <code>Makefile.foo</code> be needed, then the <code>CC</code> and <code>CXX</code> environment variables need to be exported: </p> <p><pre><code>export CC=tau_cc.sh CXX=tau_cxx.sh F90=tau_f90.sh\n</code></pre> before the first <code>cmake</code> run, or before running <code>make</code>.</p> <p>Run the generated binaries as usual (e.g. <code>mpirun -np 4 ./binary args</code>) the output will now include the files <code>profile.*</code> in the working directory. At this point, run <code>paraprof</code> to launch the GUI analysis (need <code>module load java</code>), or <code>pprof</code> for command-line output.</p> <p>Different options for compile time are available (e.g. <code>-optVerbose</code>), options for run time (e.g. <code>TAU_TRACK_MEMORY_LEAKS=1</code>)</p>"},{"location":"software/libraries/","title":"Libraries","text":"<p>There are several commonly used libraries that are available as modules on Midway2 and Midway3. After loading the module into your environment, you can find several environment variables and paths are added: <pre><code>module show [module-name]\n</code></pre> These added paths can be used in your Makefile or in the build configuration with cmake.</p>"},{"location":"software/libraries/#gsl","title":"GSL","text":"<p>The GNU Scientific Library GSL is a numerical library for C and C++ programmers.</p> <p><pre><code>module load gsl\n</code></pre> which sets up the paths and environment variables for the libraries.</p>"},{"location":"software/libraries/#fftw3","title":"FFTW3","text":"<p>FFTW3 can be loaded via <pre><code>module load fftw3\n</code></pre> which sets up the paths and environment variables for the libraries.</p>"},{"location":"software/libraries/#intel-oneapi-mkl","title":"Intel oneAPI MKL","text":"<p>Intel oneAPI MKL can be loaded via <pre><code>module load mkl\n</code></pre> which sets up the paths and environment variables for the libraries. The MKL libraries support core math functions include BLAS, LAPACK, ScaLAPACK, sparse solvers, fast Fourier transforms, and vector math.</p>"},{"location":"software/libraries/#nvidia-hpc-sdk","title":"NVIDIA HPC SDK","text":"<p>NVIDIA HPC SDK provides another toolset for compiling GPU-enabled C/C++/Fortran codes via OpenACC. NVIDIA HPC SDK also provides a set of GPU-optimized tools and math libraries. These compilers are available through the <code>nvhpc</code> module.</p>"},{"location":"software/software-overview/","title":"Software","text":"<p>The best way to view the most current software offerings on Midway2 and Midway3 login nodes is to check the list of available software modules with the <code>module avail</code> command.</p> <p>All users are eligible to install software packages privately in their home and project directories. It is recommended to use a <code>build</code> partition rather than login nodes when compilation and installation processes are time-consuming and require a significant amount of resources. To start an interactive session simply run: <pre><code>sinteractive --account=&lt;pi-account&gt; --partition=build\n</code></pre></p> <p>If you need software not currently available in the module system and believe that multiple research groups can benefit from installing this software, send a detailed request to our Help Desk providing a link to the software and requested version.</p>"},{"location":"software/software-overview/#using-software-modules","title":"Using Software Modules","text":"<p>RCC uses Environment Modules for managing software. The modules system permits us to set up the shell environment to make running and compiling software easier. It also allows us to make available many software packages and libraries that would otherwise conflict with one another.</p> <p>When you first log into Midway, you will be entered into a  basic user environment with minimal software available.  The <code>module</code> system is a script-based system used to manage the user environment and to \u201cactivate\u201d software packages.  In order to access software that is installed on Midway, you must first load the corresponding software module.</p> <p>Basic <code>module</code> commands:</p> Command Description <code>module avail</code> lists all available software modules <code>module avail [name]</code> lists modules matching [name] <code>module load [name]</code> loads the named module <code>module unload [name]</code> unloads the named module <code>module list</code> lists the modules currently loaded for the user <p>Module dependencies</p> <p>Note that some modules require other specific modules, i.e., dependencies, to be loaded (or unloaded). If there is a conflict, you will need to explicitly unload the conflicting module (<code>module unload ...</code>), then load the desired module again. In certain cases, usually with loading an out-of-date module, you may get an error such as <code>Error: Requirement...</code> if a dependency is absent. In those situations, you can try <code>module load -f &lt;module&gt;</code> to force the module to load.</p>"},{"location":"software/software-overview/#commonly-used-applications","title":"Commonly Used Applications","text":"<p>This guide contains instructions for some commonly used applications and environments including:</p> <ul> <li>Alphafold</li> <li>CryoSPARC</li> <li>GROMACS </li> <li>LAMMPS</li> <li>MATLAB </li> <li>Mathematica</li> <li>NAMD</li> <li>Perl </li> <li>Python and Jupyter Notebook</li> <li>R</li> <li>Singularity</li> <li>Spark</li> <li>Stata </li> <li>Tensorflow and PyTorch </li> </ul> Note on software for AMD CPUs <p>For the <code>amd</code> partitions on Midway3, you need the software modules that are built specifically for AMD CPUs. <pre><code>module use /software/modulefiles-amd\nmodule list\n</code></pre></p>"},{"location":"software/apps-and-envs/alphafold/","title":"Alphafold","text":"<p>AlphaFold is an artificial intelligence program developed by DeepMind, a subsidiary of Alphabet, which performs predictions of protein structure.</p>"},{"location":"software/apps-and-envs/alphafold/#available-modules","title":"Available modules","text":"<p><code>Alphafold2</code> is available as modules on Midway3 that you can check via <code>module avail alphafold</code>.</p> <pre><code>module avail alphafold\n---------------------- /software/modulefiles----------------------------------\nalphafold/2.0.0(default)  alphafold/2.2.0  alphafold/2.3.2  \n</code></pre> <p>The AlphaFold source code and running scripts (e.g. <code>run_alphafold.py</code>) can be found at the Alphafold GitHub.</p> <p>The training data sets for different versions of Alphafold are accessible under <code>/software/alphafold-data/</code>, <code>/software/alphafold-data-2.2/</code> and <code>/software/alphafold-data-2.3/</code>.</p>"},{"location":"software/apps-and-envs/alphafold/#example-job-script","title":"Example job script","text":"<p>Typically, Alphafold2 uses OpenMM, a GPU-accelerated molecular simulation package, to relax the candidate protein. OpenMM requires the CUDA toolkit to run on a GPU node.</p> <p>If you want to run on a CPU-only node without the relaxation run for the candidate protein, you can run the python script <code>run_alphafold.py</code> with <code>--use_gpu_relax=false</code>.</p> <p>The following example job script illustrates how to use the <code>alphafold/2.3.2</code> module on a GPU node with 2 GPUs and up to 16 CPU cores for multithreading on Midway3.</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=alphafold2\n#SBATCH --account=[your-accountname]\n#SBATCH --partition=gpu\n#SBATCH --nodes=1\n#SBATCH --time=04:00:00\n#SBATCH --ntasks-per-node=1\n#SBATCH --cpus-per-task=16\n#SBATCH --gres=gpu:2\n#SBATCH --constraint=v100\n#SBATCH --mem=64G\n\nmodule load alphafold/2.3.2 cuda/11.3\n\ncd $SLURM_SUBMIT_DIR\n\necho \"GPUs available: GPU ID $CUDA_VISIBLE_DEVICES\"\necho \"CPU cores: $SLURM_CPUS_PER_TASK\"\n\nDOWNLOAD_DATA_DIR=/software/alphafold-data-2.3\n\npython run_alphafold.py  \\\n  --data_dir=$DOWNLOAD_DATA_DIR  \\\n  --uniref90_database_path=$DOWNLOAD_DATA_DIR/uniref90/uniref90.fasta  \\\n  --mgnify_database_path=$DOWNLOAD_DATA_DIR/mgnify/mgy_clusters_2022_05.fa  \\\n  --bfd_database_path=$DOWNLOAD_DATA_DIR/bfd/bfd_metaclust_clu_complete_id30_c90_final_seq.sorted_opt  \\\n  --uniref30_database_path=$DOWNLOAD_DATA_DIR/uniref30/UniRef30_2021_03 \\\n  --pdb70_database_path=$DOWNLOAD_DATA_DIR/pdb70/pdb70  \\\n  --template_mmcif_dir=$DOWNLOAD_DATA_DIR/pdb_mmcif/mmcif_files  \\\n  --obsolete_pdbs_path=$DOWNLOAD_DATA_DIR/pdb_mmcif/obsolete.dat \\\n  --model_preset=monomer \\\n  --max_template_date=2022-1-1 \\\n  --db_preset=full_dbs \\\n  --use_gpu_relax=true \\\n  --output_dir=out_alphafold_2.1.1_multi-monomer \\\n  --fasta_paths=T1083.fasta,T1084.fasta\n</code></pre>"},{"location":"software/apps-and-envs/cryosparc/","title":"CryoSPARC","text":"<p>CryoSPARC (Cryo-EM Single Particle Ab-Initio Reconstruction and Classification) is a state of the art software to process cryo-electron microscopy (cryo-EM) data. It is designed as a dispatcher for cryo-EM workloads on a group of servers and workstations. RCC provides support for CryoSPARC on the Beagle3 cluster. </p>"},{"location":"software/apps-and-envs/cryosparc/#installation-and-setup","title":"Installation and Setup","text":"<p>In order to use CryoSPARC on Beagle3, you need to request for a license from CryoSPARC and send it to RCC via this form. RCC will then setup your account and provide you with your account details. Each user will also recieve a dedicated base port for their account, usually ranging from 39100-39300. </p>"},{"location":"software/apps-and-envs/cryosparc/#getting-started","title":"Getting Started","text":"<p>CryoSPARC's GUI can be accessed via Thinlinc. After landing in a Thinlinc session, open a terminal window and run:</p> <pre><code>cryosparcm start\n</code></pre> <p>You may check the status of CryoSPARC at any point to learn CryoSPARC's status by using:</p> <p><pre><code>cryosparcm status\n</code></pre> Now, to access the GUI, open a browser within Thinlinc and type the host machine name (<code>midway3-login3</code>) in the address bar along with the port number assigned to you. The hostmachine name is provided in the <code>config.sh</code> file in the <code>master</code> folder of your installation directory. </p> <p>Example</p> <p>You may type something like <code>http://midway3-login3.rcc.local:39190/</code> in the address bar of the Thinlinc browser. </p> <p>Info</p> <p>RCC's CryoSPARC host machine name is midway3-login3. You are required to use this hostname at all times.</p>"},{"location":"software/apps-and-envs/cryosparc/#troubleshooting","title":"Troubleshooting","text":""},{"location":"software/apps-and-envs/cryosparc/#sock-error","title":"Sock Error","text":"<p>If the error message looks like,  <code>unix:///tmp/cryosparc-supervisor\u20136410667835282660811.sock refused connection (already shut down?)</code>,  follow the steps mentioned below.</p> <ol> <li> <p>Run <code>cryosparcm stop</code> </p> </li> <li> <p>Delete <code>/tmp/*.sock</code> file that belongs to your user account. The exact name of the the <code>*.sock</code> file will be in the error message.</p> </li> <li> <p>Kill any interfering zombie processes that are still running. You can find the process IDs using: <pre><code>ps -ax | grep \"supervisord\"\nps -ax | grep \"cryosparc2_command\"\nps -ax | grep \"mongod\"\n</code></pre> <pre><code>kill &lt;PID&gt;\n</code></pre></p> </li> <li>Run <code>cryosparcm start</code> to start CryoSPARC again. </li> </ol>"},{"location":"software/apps-and-envs/cryosparc/#database-failure","title":"Database Failure:","text":"<ol> <li>Kill the mongo processes. You can find the process IDs using:</li> </ol> <p><code>ps -ax | grep \u201cmongod\u201d</code> <code>kill &lt;PID&gt;</code></p> <ol> <li> <p>Delete the <code>.lock</code> file at <code>&lt;cryosparc-install-dir&gt;/db</code></p> </li> <li> <p>Start CryoSPARC again using:</p> </li> </ol> <p><code>cryosparcm start</code></p>"},{"location":"software/apps-and-envs/cryosparc/#database-spawn-error","title":"Database Spawn Error","text":"<p>If the error message looks like, </p> <pre><code>Starting cryoSPARC System master process..\nCryoSPARC is not already running.\ndatabase: ERROR (spawn error)\n</code></pre> <p>then follow the steps mentioned below</p> <ol> <li> <p>Make a complete copy of your <code>db</code> directory as a backup and keep it safe <pre><code>cp -rav db db_backup\n</code></pre></p> </li> <li> <p>Stop CryoSPARC <pre><code>cryosparcm stop\n</code></pre></p> </li> <li> <p>Remove the original folder  <pre><code>rm -rf db\n</code></pre></p> </li> <li> <p>Kill zombie processes <pre><code>ps -ax | grep \"supervisord\" (kill only the process that is running from your cryosparc install)\nps -ax | grep \"cryosparc_command\" (kill all the matching processes related to your cryosparc instance)\nps -ax | grep \"mongod\" (kill only the process running your cryosparc database)\n</code></pre></p> </li> <li> <p>Start cryosparc which  will recreate the database <pre><code>cryosparcm start\n</code></pre></p> </li> <li> <p>Stop cryosparc  <pre><code>cryosparcm stop\n</code></pre></p> </li> <li> <p>Run  <pre><code>cp -rav db_backup db\n</code></pre></p> </li> <li> <p><code>cd</code> into the <code>db</code> directory that has all your original database files and run the following bash commands <pre><code>eval $(cryosparcm env)\n</code></pre> <pre><code>mongod --dbpath ./ --repair\n</code></pre></p> </li> <li> <p>Start cryoSPARC again  <pre><code>cryosparcm start\n</code></pre></p> </li> </ol>"},{"location":"software/apps-and-envs/gromacs/","title":"GROMACS","text":"<p>GROMACS is a free and open-source software suite for high-performance molecular dynamics and output analysis.</p> <p>Keywords: <code>biology</code>, <code>physics</code>, <code>chemistry</code>, <code>molecular dynamics</code></p>"},{"location":"software/apps-and-envs/gromacs/#available-modules","title":"Available modules","text":"<p>There are several GROMACS modules on Midway2 and Midway3 that you can check via <code>module avail gromacs</code>:</p> Midway2Midway3 <pre><code>---------------------------- /software/modulefiles2 ----------------------------\ngromacs/5.0.7-cuda+intelmpi-5.1+intel-16.0      \ngromacs/5.1.4-cuda-7.5+intelmpi-5.1+intel-16.0  \ngromacs/2019.2+intelmpi-2018.2.199+intel-18.0   \ngromacs/2019.3+intelmpi-2018.2.199+intel-18.0   \ngromacs/2021.1+intelmpi-2019.up7+intel-19.1.1   \n</code></pre> <pre><code>---------------------------- /software/modulefiles -----------------------------\ngromacs/2020.4(default)  gromacs/2021.5  \n</code></pre> <p>You can then show the dependency of individual modules, for example, <pre><code>module show gromacs/2021.1\n</code></pre> which gives on Midway3 <pre><code>-------------------------------------------------------------------\n/software/modulefiles/gromacs/2021.5:\n\nmodule-whatis   {setup gromacs 2021.5 compiled with the system compiler}\nconflict        gromacs\nmodule          load gcc/7.4.0 openmpi/4.1.2+gcc-7.4.0 cuda/11.2 plumed/2.7.3\nprepend-path    PATH /software/gromacs-2021.5-el8-x86_64/bin\nprepend-path    LD_LIBRARY_PATH /software/gromacs-2021.5-el8-x86_64/lib64\nprepend-path    LIBRARY_PATH /software/gromacs-2021.5-el8-x86_64/lib64\nprepend-path    PKG_CONFIG_PATH /software/gromacs-2021.5-el8-x86_64/lib64/pkgconfig\nprepend-path    CPATH /software/gromacs-2021.5-el8-x86_64/include\nprepend-path    MANPATH /software/gromacs-2021.5-el8-x86_64/share/man\n</code></pre></p> <p>In this case you can see this module was compiled with <code>openmpi/4.1.2+gcc-7.4.0</code>, <code>cuda/11.2</code> and <code>plumed/2.7.3</code>. As a result, this version supports GPU acceleration and should be used on GPU nodes.</p> Note <p>GROMACS is under active development. You are encouraged to build the latest stable version from source code in your own space using the provided compilers.</p>"},{"location":"software/apps-and-envs/gromacs/#example-job-script","title":"Example job script","text":"<p>An example batch script to run GROMACS for Midway3 is given as below <pre><code>!/bin/bash\n#SBATCH --job-name=gmx-bench\n#SBATCH --account=pi-[cnetid]\n#SBATCH --time=01:00:00\n#SBATCH --partition=gpu\n#SBATCH --gres=gpu:1\n#SBATCH --constraint=v100\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=32\n\nmodule load gromacs/2021.5\n\ncd $SLURM_SUBMIT_DIR\n\nexport GMX_PATH=/software/gromacs-2021.5-el8-x86_64/bin\nsource $GMX_PATH/GMXRC\n\nntasks_per_node=$SLURM_NTASKS_PER_NODE\nnumnodes=$SLURM_JOB_NUM_NODES\nn=$(( ntasks_per_node * numnodes ))\n\nt=1000\n\nmpirun -np $n gmx_mpi mdrun -ntomp 1 -pin on -nb gpu -nsteps $t \\\n   -v -s init.tpr\n</code></pre> where <code>init.tpr</code> is an existing portable binary run input file.</p>"},{"location":"software/apps-and-envs/lammps/","title":"LAMMPS","text":"<p>LAMMPS (Large-scale Atomic/Molecular Massively Parallel Simulator) is a classical molecular dynamics code with a focus on materials modeling.</p> <p>Keywords: <code>materials science</code>, <code>physics</code>, <code>chemistry</code>, <code>molecular dynamics</code></p>"},{"location":"software/apps-and-envs/lammps/#available-modules","title":"Available modules","text":"<p>There are several LAMMPS modules on Midway2 and Midway3 that you can check via <code>module avail lammps</code>:</p> Midway2Midway3 <pre><code>---------------------------- /software/modulefiles2 ----------------------------\nlammps/17Nov2016+intelmpi-5.1+intel-16.0\nlammps/23Jun2022+oneapi-2021  \n</code></pre> <pre><code>---------------------------- /software/modulefiles -----------------------------\nlammps/29Oct2020 \nlammps/20Sep2021(default)\nlammps/20Sep2021-gpu\nlammps/24Mar2022\nlammps/24Mar2022-gpu\n</code></pre> <p>The <code>gpu</code> suffix indicates that this module support GPU acceleration and should run on a GPU node. You can then show the dependency of individual modules, for example, on Midway3 if you do <pre><code>module show lammps/24Mar2022\n</code></pre> you will get <pre><code>-------------------------------------------------------------------\n/software/modulefiles/lammps/24Mar2022:\n\nmodule-whatis   {setup lammps 24Mar2022 compiled with the system compiler}\nconflict        lammps\nmodule          load intelmpi/2021.5+intel-2022.0 mkl/2020.up1\nprepend-path    PATH /software/lammps-24Mar2022-el8-x86_64/bin\nprepend-path    LD_LIBRARY_PATH /software/lammps-24Mar2022-el8-x86_64/lib64\nprepend-path    LIBRARY_PATH /software/lammps-24Mar2022-el8-x86_64/lib64\nprepend-path    CPATH /software/lammps-24Mar2022-el8-x86_64/include\nprepend-path    MANPATH /software/lammps-24Mar2022-el8-x86_64/share/man\n</code></pre></p> Note <p>LAMMPS is under active development. You are encouraged to build the latest stable version from source code in your own space using the provided compilers.</p> <p>In this case you can see this module was compiled with <code>intelmpi/2021.5+intel-2022.0</code> and <code>mkl/2020.up1</code>. After loading the module, you can run <pre><code>lmp -h\n</code></pre> to see the features that are supported by the executable <code>lmp</code>.</p>"},{"location":"software/apps-and-envs/lammps/#example-job-script","title":"Example job script","text":"<p>An example batch script to run LAMMPS is given as below <pre><code>!/bin/bash\n#SBATCH --job-name=gmx-bench\n#SBATCH --account=pi-[cnetid]\n#SBATCH --time=01:00:00\n#SBATCH --partition=caslake\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=16\n\nmodule load lammps/24Mar2022\n\ncd $SLURM_SUBMIT_DIR\n\nntasks_per_node=$SLURM_NTASKS_PER_NODE\nnumnodes=$SLURM_JOB_NUM_NODES\nn=$(( ntasks_per_node * numnodes ))\n\nmpirun -np $n lmp -input in.txt\n</code></pre></p>"},{"location":"software/apps-and-envs/mathematica/","title":"Mathematica","text":"<p>Mathematica is powerful and intuitive computation software.  It is capable of geometric, audio, graphical, and raw data analysis.  The embedded Wolfram Language is an incredibly powerful scripting tool for doing sybolic math analysis and granting command line style access to the plethora of algorithms within the software.  Mathematica has a GUI and CLI that can be used.</p>"},{"location":"software/apps-and-envs/mathematica/#getting-started","title":"Getting Started","text":"<p>To gain access to Mathematica, a Mathematica module must be loaded with the command:</p> <pre><code>module load mathematica\n</code></pre> <p>A full list of available Mathematica versions can be obtained by calling the command:</p> <pre><code>module avail mathematica\n</code></pre>"},{"location":"software/apps-and-envs/mathematica/#using-mathematicas-graphical-interface","title":"Using Mathematica\u2019s Graphical Interface","text":"<p>To use Mathematica\u2019s GUI interface on Midway, we recommend connecting to Midway via ThinLinc. </p> <p>Note that once connected via ThinLinc, you will be accessing a Midway login node.  In order to run Mathematica with its GUI interface on a compute node, obtain a terminal in the ThinLinc desktop and issue the sinteractive command.  This will deliver you to a compute node.  From there, you can launch Mathematica with the commands:</p> <pre><code>module load mathematica\nmathematica\n</code></pre> <p>and have access to the GUI interface.</p>"},{"location":"software/apps-and-envs/mathematica/#using-mathematicas-textual-interface","title":"Using Mathematica\u2019s Textual Interface","text":"<p>Once a Mathematica software module has been loaded, Mathematica\u2019s command line interface can be started with the command <code>math</code>.</p> <pre><code>$ module load mathematica\n$ math\nMathematica 8.0 for Linux x86 (64-bit)\nCopyright 1988-2011 Wolfram Research, Inc.\n\nIn[1]:= a=1;\n\nIn[2]:= b=2;\n\nIn[3]:= a+b\n\nOut[3]= 3\n\nIn[4]:= Quit[];\n</code></pre> <p>More information about using the command line interface to Mathematica is available here: http://reference.wolfram.com/language/tutorial/UsingATextBasedInterface.html</p>"},{"location":"software/apps-and-envs/mathematica/#running-mathematica-jobs-with-slurm","title":"Running Mathematica Jobs with SLURM","text":"<p>To submit Mathematica jobs to Midway\u2019s resource scheduler, SLURM, the Mathematica commands to be executed must be containined in a single .m script.  The .m script will then be passed to the <code>math</code> command in an sbatch file.  For example:</p> <p><code>math-simple.m</code> is a basic Mathematica script that computes the sum of A and B:</p> <pre><code>A = Sum[i, {i,1,100}]\nB = Mean[{25, 36, 22, 16, 8, 42}]\nAnswer = A + B\nQuit[];\n</code></pre> <p>This script can be submited to SLURM with <code>math-simple.sbatch</code> which will send the job to a compute node:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=math-simple\n#SBATCH --output=math-simple.out\n#SBATCH --error=math-simple.err\n#SBATCH --partition=sandyb\n#SBATCH --time=00:05:00\n#SBATCH --ntasks=1\n\nmodule load mathematica\n\nmath -run &lt; math-simple.m\n</code></pre> <p>To run this example, download both files to a directory on Midway.  Then, enter the following command to submit the job to the scheduler:</p> <pre><code>sbatch math-simple.sbatch\n</code></pre> <p>Output from this example can be found in the file named math-simple.out which will be created in the same directory.</p>"},{"location":"software/apps-and-envs/mathematica/#using-multiple-cpus-in-mathematica","title":"Using Multiple CPUs in Mathematica","text":"<p>Mathematica can be run in parallel using the built in <code>Parallel</code> commands or by utilizing parallel API.  Parallel Mathematica jobs are limited to one node, but can utilize all CPU cores on the node if allocated.  A parallel Mathematica script must either be submitted to a node that was requested with the <code>exclusive</code> flag or the script must specify the number of processors allocated.  As an example of the latter, the following Mathematica script would be appropriate for a SLURM request of 1 node with 8 tasks per node.</p>"},{"location":"software/apps-and-envs/mathematica/#sample-parallel-job-submission","title":"Sample Parallel Job Submission","text":"<p>SBATCH script:</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=mathematica_example\n#SBATCH --output=mathematica_example.out\n#SBATCH --error=mathematica_example.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=8\n\nmodule load mathematica\n\nmath -run &lt; ./sample-parallel.m\n</code></pre> <p>Mathematica script:</p> <pre><code>(*Limits Mathematica to requested resources*)\nUnprotect[$ProcessorCount];$ProcessorCount = 8;\n\n(*Prints the machine name that each kernel is running on*)\nPrint[ParallelEvaluate[$MachineName]];\n\n(*Prints all Mersenne PRime numbers less than 2000*)\nPrint[Parallelize[Select[Range[2000],PrimeQ[2^#-1]&amp;]]];\n</code></pre>"},{"location":"software/apps-and-envs/matlab/","title":"MATLAB","text":"<p>RCC provides the Matlab programming environment on all Midway compute resources.  Most Matlab toolboxes are also available (see: https://itservices.uchicago.edu/page/matlab-tah-toolboxes).  When running compute- or memory-intensive Matlab jobs on Midway, it is important to run on compute nodes, and not on the login nodes.</p> <p>Note</p> <p>Compute- and memory-intensive jobs running on the login nodes are subject to termination without warning by RCC system administrators as this impacts the performance of the login nodes and ability for other users to work.</p>"},{"location":"software/apps-and-envs/matlab/#getting-started","title":"Getting Started","text":"<p>To gain access to Matlab, a Matlab module must be loaded with the command:</p> <pre><code>module load matlab\n</code></pre> <p>A full list of the available Matlab versions can be obtained by issuing the command:</p> <pre><code>module avail matlab\n</code></pre>"},{"location":"software/apps-and-envs/matlab/#using-matlabs-textual-interface","title":"Using Matlab\u2019s Textual Interface","text":"<p>On Midway, Matlab can be launched at the terminal with the commands:</p> <pre><code>module load matlab\nmatlab\n</code></pre> <p>This will launch Matlab\u2019s textual interface. We recommend running Matlab on a compute node as opposed to a login node. </p>"},{"location":"software/apps-and-envs/matlab/#using-matlabs-gui-interface","title":"Using Matlab\u2019s GUI Interface","text":"<p>To use Matlab\u2019s GUI interface on Midway, we reccomend connecting to Midway via ThinLinc. </p> <p>Note that once connected via ThinLinc, you will be accessing a Midway login node.  In order to run Matlab with its GUI interface on a compute node, obtain a terminal in the ThinLinc desktop and issue the sinteractive command.  This will deliver you to a compute node.  From there, you can launch Matlab with the command:</p> <pre><code>module load matlab\nmatlab\n</code></pre> <p>and have access to the GUI interface.</p>"},{"location":"software/apps-and-envs/matlab/#running-matlab-jobs-with-slurm","title":"Running Matlab Jobs with SLURM","text":"<p>To submit Matlab jobs to Midway\u2019s resource scheduler, SLURM, the Matlab commands to be executed must be containined in a single .m script.</p> <p><code>matlab_simple.m</code> is a basic Matlab script that computes and prints a 10x10 magic square</p> <p><code>matlab_simple.sbatch</code> is a submission script that submits Matlab program to the default queue</p> <p>To run this example, download both files to a directory on Midway.  Then, enter the following command to submit the program matlab_simple.m to the scheduler:</p> <pre><code>sbatch matlab_simple.sbatch\n</code></pre> <p>Output from this example can be found in the file named matlab.out which will be created in the same directory.</p>"},{"location":"software/apps-and-envs/matlab/#matlab-parallel","title":"Matlab Parallel","text":"<p>To run MATLAB effectively using parallel computing techniques requires a few basic concepts which can be optimized and expanded upon.  The MATLAB Parallel Computing Toolbox User\u2019s Guide is the official documentation and should be referred to for further details, examples and explanations.  Here, we provide some Midway-specific considerations that RCC users should be aware of.</p> <p>RCC reccomends MATLAB 2014b for parallel matlab computing as it relaxes the restriction on number of workers available through the PCT.</p> <p>NOTE: At this time, RCC does not support the Matlab Distributed Compute Server (MDCS).  As such, parallel Matlab jobs are limited to a single node with the \u201clocal\u201d pool through use of the Parallel Compute Toolbox (PCT). </p>"},{"location":"software/apps-and-envs/matlab/#basic-pct-operation","title":"Basic PCT Operation","text":"<p>The most basic level of parallelization in Matlab is achieved through use of a <code>parfor</code> loop in place of a <code>for</code> loop.  The iterations of a <code>parfor</code> loop are distributed to the workers in the active matlabpool and computed concurrently.  For this reason, care must be taken to ensure that each iteration of the parfor loop is independent of every other.</p> <p>The overall procedure for leveraging parfor in your Matlab script is as follows:</p> <ol> <li> <p>Create a local matlabpool</p> </li> <li> <p>Call <code>parfor</code> in place of <code>for</code> in your Matlab scripts and functions</p> </li> </ol> <p>A simple Matlab script that uses parfor can be downloaded here: <code>matlab_parfor.m</code> and is shown below.</p> <pre><code>% start the matlabpool with maximum available workers\n% control how many workers by setting ntasks in your sbatch script\npc = parcluster('local')\nparpool(pc, str2num(getenv('SLURM_CPUS_ON_NODE')))\n\n% run a parfor loop, distributing the iterations to the SLURM_CPUS_ON_NODE workers\nparfor i = 1:100\n\n        ones(10,10)\n\nend\n</code></pre>"},{"location":"software/apps-and-envs/matlab/#submitting-a-pct-matlab-job-to-slurm","title":"Submitting a PCT Matlab Job to SLURM","text":"<p>Compute intensive jobs that will consume non-trivial amounts of CPU and/or memory resources should not be run on Midway\u2019s login nodes.  Instead, the job should be submitted to the scheduler and run on a compute node.  A sample submission script for the above example Matlab sample is provided here: <code>matlab_parfor.sbatch</code> and is shown below.</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=whatever\n#SBATCH --output=matlab_parfor.out\n#SBATCH --error=matlab_parfor.err\n#SBATCH --partition=sandyb\n#SBATCH --time=00:10:00\n#SBATCH --nodes=1\n#SBATCH --ntasks=16\n\nmodule load matlab/2014b\n\nmatlab -nodisplay &lt; matlab_parfor.m\n</code></pre>"},{"location":"software/apps-and-envs/matlab/#running-multiple-pct-matlab-jobs","title":"Running Multiple PCT Matlab Jobs","text":"<p>Specific care must be taken when running multiple PCT jobs on Midway.  When you submit multiple jobs that are all using PCT for parallelization, the multiple matlabpools that get created have the ability to interfere with one another which can lead to errors and early termination of your scripts.</p> <p>The Matlab PCT requires a temporary \u201cJob Storage Location\u201d where is stores information about the Matlab pool that is in use.  This is simply a directory on the filesystem that Matlab writes various files to in order to coordinate the parallelization of the matlabpool.  By default, this information is stored in /home/YourUsername/.matlab/ (the default \u201cJob Storage Location\u201d).  When submitting multiple jobs to SLURM that will all use the PCT, all of the jobs will attempt to use this default location for storing job information thereby creating a race condition where one job modifies the files that were put in place by another.  Clearly, this situation must be avoided.</p> <p>The solution is to have each of your jobs that will use the PCT set a unique location for storing job information.  To do this, a temporary directory must be created before launching matlab in your submission script and then the matlabpool must be created to explicitly use this unique temporary directory.  An example sbatch script <code>matlab_multi.sbatch</code> to do this is shown below:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=whatever\n#SBATCH --output=matlab_parfor.out\n#SBATCH --error=matlab_parfor.err\n#SBATCH --partition=sandyb\n#SBATCH --time=00:10:00\n#SBATCH --nodes=1\n#SBATCH --ntasks=16\n\nmodule load matlab/2014b\n\n# Create a temporary directory on scratch\nmkdir -p $SCRATCH/$SLURM_JOB_ID\n\n# Kick off matlab\nmatlab -nodisplay &lt; multi_parfor.m # Cleanup local work directory\nrm -rf $SCRATCH/$SLURM_JOB_ID\n</code></pre> <p>And the corresponding Matlab script <code>multi_parfor.m</code> shown here:</p> <pre><code>% create a local cluster object\npc = parcluster('local')\n\n% explicitly set the JobStorageLocation to the temp directory that was created in your sbatch script\npc.JobStorageLocation = strcat(getenv('SCRATCH'),'/', getenv('SLURM_JOB_ID'))\n\n% start the matlabpool with maximum available workers\n% control how many workers by setting ntasks in your sbatch script\nparpool(pc, str2num(getenv('SLURM_CPUS_ON_NODE')))\n\n% run a parallel for loop\nparfor i = 1:100\n    ones(10,10)\nend\n</code></pre>"},{"location":"software/apps-and-envs/namd/","title":"NAMD","text":"<p>NAMD  is a parallel molecular dynamics code designed for high-performance simulation of large biomolecular systems.</p> <p>Keywords: <code>biology</code>, <code>physics</code>, <code>chemistry</code>, <code>molecular dynamics</code></p>"},{"location":"software/apps-and-envs/namd/#available-modules","title":"Available modules","text":"<p>There are several NAMD modules on Midway2 and Midway3 that you can check via <code>module avail namd</code>:</p> Midway2Midway3 <pre><code>---------------------------- /software/modulefiles2 ----------------------------\nnamd/2.11+intelmpi-5.1+intel-16.0 \nnamd/2.12+intelmpi-5.1+intel-16.0\nnamd/2.13+intelmpi-5.1+intel-16.0\nnamd/2.14+intelmpi-5.1+intel-16.0   \n</code></pre> <pre><code>---------------------------- /software/modulefiles -----------------------------\nnamd/2.14(default)\nnamd/2.14+intel-2022.0\nnamd/2.14+intel-2022.0+cuda-11.5\nnamd/2.14+intel-2022.0+cuda-11.5+multi\nnamd/2.14+intel-2022.0+multi\n</code></pre> <p>The <code>multi</code> suffix indicates that the module can run across multiple nodes. The <code>cuda-11.5</code> indicates that the module support GPU acceleration via CUDA. You can then show the dependency of individual modules, for example, on Midway3 if you do <pre><code>module show namd/2.14+intel-2022.0+multi\n</code></pre> you will get <pre><code>-------------------------------------------------------------------\n/software/modulefiles/namd/2.14+intel-2022.0+multi:\n\nmodule-whatis   {setup namd 2.14 multiple-node compiled with intel-2022.0}\nconflict        namd\nmodule          load intelmpi/2021.5+intel-2022.0\nprepend-path    PATH /software/namd-2.14-el8-x86_64+intel-2022.0/bin-multi\nsetenv          FI_PROVIDER mlx\nsetenv          NAMD_HOME /software/namd-2.14-el8-x86_64+intel-2022.0/bin-multi\nsetenv          CONV_RSH ssh\n</code></pre></p> <p>In this case you can see this module was compiled with <code>intelmpi/2021.5+intel-2022.0</code>. </p>"},{"location":"software/apps-and-envs/namd/#example-job-script","title":"Example job script","text":"<p>An example batch script to run NAMD for Midway3 is given as below <pre><code>#!/bin/bash\n#SBATCH --job-name=\"test-namd\"\n#SBATCH --account=pi-[cnetid]\n#SBATCH -t 00:30:00\n#SBATCH --partition=gpu\n#SBATCH --nodes=2             # 2 nodes\n#SBATCH --ntasks-per-node=1   # 1 process per node\n#SBATCH --cpus-per-task=2     # 2 threads mapping to 2 cores per node (1 of them for inter-node comm)\n#SBATCH --gres=gpu:2          # 2 GPUs per node\n#SBATCH --constraint=v100\n\nmodule load namd/2.14+intel-2022.0+cuda-11.5+multi\n\n# calculate total processes (P) and procs per node (PPN)\nPPN=$(( $SLURM_CPUS_PER_TASK * $SLURM_NTASKS_PER_NODE ))\nP=$(( $PPN * $SLURM_NNODES ))\n\nmpirun -np $P $NAMD_HOME/namd2 +ppn $PPN +devices 0,1 apoa1.namd\n</code></pre></p>"},{"location":"software/apps-and-envs/perl/","title":"Perl","text":"<p>Perl is available as a software module. No additional perl modules have been installed. Installing local modules using local::lib with cpanm is the preferred method. Here is an example to install and test Math::CDF:</p> <pre><code>module load perl\neval $(perl -I$HOME/perl5/lib/perl5 -Mlocal::lib)\ncpanm Math::CDF\nperl -e \"require Math::CDF\"\n</code></pre> <p>To have the appropriate environment available during login, it is recommended to put these lines in the $HOME/.bashrc:</p> <pre><code>module load perl\n[ $SHLVL -eq 1 ] &amp;&amp; eval \"$(perl -I$HOME/perl5/lib/perl5 -Mlocal::lib)\"\n</code></pre> <p>Additional details on local::lib can be in the local::lib documentation.</p>"},{"location":"software/apps-and-envs/python/","title":"Python and Anaconda","text":""},{"location":"software/apps-and-envs/python/#getting-started","title":"Getting Started","text":"<p>Different versions of Python on Midway are offered as modules. To check the full list of Python modules use the <code>module avail python</code> command.</p> <p>The command <code>module load python</code> will load the default module: an Anaconda distribution of Python. Note that there are multiple different Anaconda distributions available.  </p> <p>Once you load an Anaconda distribution, you can list all available public environments with: <pre><code>conda env list  \n</code></pre> To activate an environment, run: <pre><code>source activate &lt;ENV NAME&gt;\n</code></pre> where <code>&lt;ENV NAME&gt;</code> is the name of the environment for a public environment, or the full path to the environment, if you are using a personal one. You can deactivate an environment with:  <pre><code>conda deactivate\n</code></pre></p> <p>Danger</p> <p>Never run <code>conda init</code>! Use <code>source activate</code> instead of <code>conda activate</code>. <code>conda init</code> has been known to break ThinLinc.</p>"},{"location":"software/apps-and-envs/python/#managing-environments","title":"Managing Environments","text":"<p>With each Anaconda distribution, we have a small selection of widely used environments. Many, such as Tensorflow or DeepLabCut should be loaded through their modules (i.e., <code>module load tensorflow</code>), which automate the loading of other relevant libraries that are available as modules.</p> <p>If you need packages not available in the global environment, you can make a personal environment for them. If you want to copy an existing environment to modify it, you can do that with: <pre><code>conda create --prefix=/path/to/new/environment --clone &lt;EXISTING ENVIRONMENT&gt;\n</code></pre> If you want to make a clean environment, you can do that with <pre><code>conda create --prefix=/path/to/new/environment python=&lt;PYTHON VERSION NUMBER&gt;\n</code></pre></p> <p>Once your environment is set up how you want, especially if it is in your scratch space, you may want to create a backup of the environment into a YAML file. You do that after activating the environment with <code>conda env export &gt; environment.yml</code>. That YAML file can then be used to recreate the environment with <code>conda env create --prefix=/path/to/new/environment -f environment.yml</code>.</p> <p>Note</p> <p>Anaconda may sometimes cause issues with ThinLinc. If you are experiencing frequent, spontaneous disconnections from ThinLinc, remove any sections involving \"conda\" or \"anaconda\" from the file <code>~/.bashrc</code> (in your home directory).</p>"},{"location":"software/apps-and-envs/python/#managing-packages","title":"Managing Packages","text":"<p>In the Anaconda distributions of Python, you should generally be using a personal environment to manage packages. Once you activate your environment <pre><code>source activate [your-env]\n</code></pre> you can install packages with <code>conda install</code> or <code>pip install</code> into this environment. As per the advice of the Anaconda software authors, any  <code>pip install</code> packages should be installed after <code>conda install</code> packages.</p>"},{"location":"software/apps-and-envs/python/#using-python","title":"Using Python","text":"<p>On Midway, <code>python</code> can be launched, after loading a desired module, at the terminal with the command:</p> <pre><code>python\n</code></pre> <p>To leave the launched interactive shell, use:</p> <p><pre><code>exit()\n</code></pre> or <pre><code>quit()\n</code></pre></p> <p>If you already have a python script, use this command to run it:</p> <pre><code>python your_script.py\n</code></pre>"},{"location":"software/apps-and-envs/python/#python-interactive-plotting","title":"Python Interactive Plotting","text":"<p>For interactive plotting, it is necessary to set the matplotlib backend to a graphical backend. Here is an example:</p> <pre><code>#!/usr/bin/env python\n\nimport matplotlib\nmatplotlib.use('Qt4Agg')\nimport matplotlib.pyplot as plt\n\nplt.plot([1,2,3,4])\nplt.ylabel('some numbers')\nplt.show()\n</code></pre> <p>If you are saving files and viewing them with the display command, you may experience rapid flickering. There seems to be an issue with image transparency, use a command like this to disable the transparency:</p> <pre><code>display -alpha off &lt;image&gt;\n</code></pre>"},{"location":"software/apps-and-envs/python/#running-jupyter-notebooks","title":"Running Jupyter Notebooks","text":"<p>Jupyter Notebook is a useful tool for python users because it provides interactive web-based computing. You can launch Jupyter Notebooks on Midway, open it in the browser on your local machine and have all the computation work done on Midway. If you want to perform heavy compute, you will need to start an interactive session (please see Running Jobs on how to get an interactive session) before launching Jupyter notebook otherwise you may use one of the login nodes.</p> <p>The steps to launch Jupyter are as follows:</p> <p>Step 1: Load the desired Python module. This can be done on a login node, or on a compute node via an interactive job.</p> <p>Step 2: Determine the IP address of the host you are on. Whether you are on a login node or a compute node, you can use this command to get your IP address:</p> <p><pre><code>HOST_IP=`/sbin/ip route get 8.8.8.8 | awk '{print $7;exit}'`\necho $HOST_IP\n</code></pre> which can be either <code>128.135.x.y</code> (an external address), or <code>10.50.x.y</code> (on-campus address).</p> <p>Step 3: Launch Jupyter with:</p> Midway2Midway3 <p><pre><code>jupyter-notebook --no-browser --ip=$HOST_IP\n</code></pre> or <pre><code>jupyter-lab --no-browser --ip=$HOST_IP\n</code></pre></p> <p><pre><code>jupyter-notebook --no-browser --ip=$HOST_IP --port=15021\n</code></pre> or <pre><code>jupyter-lab --no-browser --ip=$HOST_IP --port=15021\n</code></pre></p> <p>where 15021 is an arbitrary port number rather than 8888. If there is a problem with the port already in use, your browser will complain. In that case, please try the another port with the flag <code>--port=&lt;port number&gt;</code>, or use the command <code>shuf</code>  to get a random number for the port: <pre><code>PORT_NUM=$(shuf -i15001-30000 -n1)\n</code></pre> and launch the Notebook server as earlier <pre><code>jupyter-notebook --no-browser --ip=$HOST_IP --port=$PORT_NUM\n</code></pre></p> <p>which will give you two URLs with a token, one with the external address <code>128.135.x.y</code>, and another with the on-campus address <code>10.50.x.y</code>, or your local host <code>127.0.0.0</code>. The on-campus address is only valid when you are connecting to Midway2 or Midway3 via VPN.</p> <pre><code>http://128.135.167.77:15021/?token=9c9b7fb3885a5b6896c959c8a945773b8860c6e2e0bad629\n</code></pre> <p>If you do not specify <code>--no-browser --ip=</code>, the web browser will be launched on the node and the URL returned cannot be used on your local machine.</p> <p>Step 4: Open a web browser on your local machine with the returned URLs.</p> <p>If you are using on-campus network or VPN, you can use copy and paste (or <code>Ctrl</code> + mouse click on) the URL with the external address, or the URL with the on-campus address into the address bar.</p> <p>As of April 2023: If you are on Midway2, you can open the URL with the external address without VPN. If you are on Midway3, you need to connect via VPN to open either URLs.</p> <p>Without VPN, you can use SSH tunneling to connect to the Jupyter server launched on the Midway2 (or Midway3) login nodes in Step 3 from your local machine. To do that, open another terminal window on your local machine and run</p> <p><pre><code>ssh -N -f -L 15021:&lt;HOST_IP&gt;:15021 &lt;your-CNetID&gt;@midway3.rcc.uchicago.edu\n</code></pre> where <code>HOST_IP</code> is the external IP address of the login node obtained from Step 2, and 15021 is the port number used in Step 3.</p> <p>This command will create an SSH connection from your local machine to <code>midway3</code> node and forward the 15021 port to your local host at port 15021. The port number should be consistent across all the steps (15021 in this example). You can find out the meaning for the arguments used in this command at explainshell.com.</p> <p>After successfully logging with 2FA as usual, you will be able to open the URL <code>http://127.0.0.1:15021/?token=....</code>, or equivalently, <code>localhost:15021/?token=....</code> in the browser on your local machine.</p> <p>Step 5: To kill Jupyter, go back to the first terminal window where you launch Jupyter Notebook and press <code>Ctrl+c</code> and then confirm with <code>y</code> that you want to stop it.</p>"},{"location":"software/apps-and-envs/python/#running-jupyterlab","title":"Running JupyterLab","text":"<p>JupyterLab is the next-generation IDE-like counterpart of Jupyter Notebook with more advanced features for data science, scientific computing, computational journalism, and machine learning. It has a modular structure that allows you to create and execute multiple documents in different tabs in the same window.</p>"},{"location":"software/apps-and-envs/r/","title":"R","text":"<p>R has become an important tool for quantitative research and data analysis in many fields.</p> <p>See this tutorial for step-by-step instructions on how to set up and use R effectively on midway2. This tutorial should also be easily transferrable to midway3 as R is set up similarly on midway3.</p> <p>To find the list of currently available R modules, run:</p> <pre><code>module avail R\n</code></pre> <p>The RStudio IDE is also available as <code>rstudio</code> modules:</p> <pre><code>module avail rstudio\n</code></pre> <p>When using RStudio, we recommend connecting to the RCC cluster via ThinLinc.</p>"},{"location":"software/apps-and-envs/singularity/","title":"Singularity","text":"<p>Singularity is a widely-adopted container runtime that implements a unique security model to mitigate privilege escalation risks and provides a platform to capture a complete application environment into a single file (SIF).</p>"},{"location":"software/apps-and-envs/singularity/#available-modules","title":"Available Modules","text":"<p>Singularity is available on and Midway3 that you can check via <code>module avail singularity</code>. It is recommended to load the latest version of <code>singularity</code> to have bugfixes and new features.</p> <pre><code>module load singularity/3.9.2\n</code></pre> <p>Since March 2022, Singularity has become a Linux Foundation project and renamed to Apptainer. You can load a version of Apptainer on Midway3: <pre><code>module load apptainer/1.1.4\n</code></pre> Singularity commands are highly compatible with Apptainer and vice versa.</p> <p>You can pull container Singularity and Docker container images from external sources to your spaces on the login nodes: <pre><code>singularity pull ubuntu.sif docker://ubuntu:latest\n</code></pre> and execute them on the compute nodes. You can bind and mount the paths on Midway to the containers at run time.</p> <p>There are instructions to use Singularity on Midway3 given here.</p>"},{"location":"software/apps-and-envs/singularity/#example-job-script","title":"Example job script","text":"<p>Suppose that you have pulled the image from the Internet (e.g. Docker Hub) to your folder on Midway3. In practice, you may want to bind mount the folders outside the container (e.g. where your input data is located and where output data is to be stored) with those inside the container. The following batch script illustrates a simple use case.</p> <p><pre><code>#!/bin/bash\n#SBATCH --job-name=test-singularity\n#SBATCH --nodes=1\n#SBATCH --time=05:00:00\n#SBATCH --account=pi-&lt;group&gt;\n#SBATCH --partition=caslake\n\nmodule load apptainer/3.9.2\n\nsingularity exec --bind /path/outside/image/:/path/inside/image/ \\\n                 --bind $PWD:/run/user \\\n                 your_image.sif your_script.py arg1 arg2\n</code></pre> In this example, <code>/path/outside/image/</code> is the path in your Midway3 directory, e.g. <code>/project/[pi-cnetied]/your-folder/</code> and <code>/path/inside/image/</code> is the path inside the container, e.g. <code>/tmp/</code>. <code>$PWD</code> is the present working directory (on Midway3) and <code>/run/user</code> is the one present inside the container. The python script when executed inside the container will read input from <code>/path/inside/image</code> and generate output to <code>/run/user/</code>. You can bind multiple folders.</p>"},{"location":"software/apps-and-envs/singularity/#known-issues","title":"Known issues","text":"<p>As a default, Singularity uses the <code>/tmp</code> directory on the local machine (whichever node or login node you happen to be working on) to dump temporary and cache files generated during the build process. After a container is built, these are usually deleted. For containers with a large total size (more than a few GB), you may encounter an error <code>no space left on device</code></p> <p>If you see this, then it most likely means that /tmp got filled up on the machine you're using. To get around this issue, create <code>faketmp</code> and <code>fakecache</code> directories, and redirect Singularity's default temporary output to <code>SINGULARITY_TMPDIR</code> and <code>SINGULARITY_CACHEDIR</code> <pre><code>export $SINGULARITY_CACHEDIR=$SCRATCH/$user/container/fakecache\nexport $SINGULARITY_TMPDIR=$SCRATCH/$user/container/faketmp\n</code></pre> You can delete everything in the <code>faketmp</code> and <code>fakecache</code> directories after creation of your container.</p>"},{"location":"software/apps-and-envs/spark/","title":"Spark","text":"<p>Apache Spark is a fast and general engine for large-scale data processing.  It has a Scala, Java, and Python API and can be run either on either a single node or multi-node configuration. For both cases, it is recommended to have exclusive access of the node in Slurm.</p>"},{"location":"software/apps-and-envs/spark/#single-node-examples","title":"Single Node Examples","text":"<p>Here is the SparkPi and pi.py examples from the Spark distribution running on a single node:</p> <p>sbatch script <code>spark-single-node.sbatch</code></p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=spark\n# Exclusive mode is recommended for all spark jobs\n#SBATCH --exclusive\n#SBATCH --nodes=1\n#SBATCH --time=10\n\nmodule load spark\n\n# This syntax tells spark to use all cpu cores on the node.\nexport MASTER=\"local[*]\"\n\n# This is a scala example\nrun-example SparkPi\n\n# This is a python example. \n# For production jobs, you'll probably want to have a python module loaded.\n# This will use the system python if you don't have a python module loaded.\nspark-submit --master $MASTER $SPARK_HOME/examples/src/main/python/pi.py\n</code></pre>"},{"location":"software/apps-and-envs/spark/#multi-node-examples","title":"Multi-node Examples","text":"<p>For multi-node Spark jobs, a helper script was written to launch the master and work tasks in the slurm allocation. Here are the same examples as above, but with Spark running on multiple nodes:</p> <p>sbatch script <code>spark-multi-node.sbatch</code></p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=spark-multi-node\n# Exclusive mode is recommended for all spark jobs\n#SBATCH --exclusive\n#SBATCH --nodes=4\n#SBATCH --time=10\n\nmodule load spark\n\n# This command starts the spark workers on the allocated nodes\nstart-spark-slurm.sh\n\n# This syntax tells the spark workers where the master is\nexport MASTER=spark://$HOSTNAME:7077\n\n# This is a scala example\nrun-example SparkPi\n\n# This is a python example.\n# For production jobs, you'll probably want to have a python module loaded.\n# This will use the system python if you don't have a python module loaded.\nspark-submit --master $MASTER $SPARK_HOME/examples/src/main/python/pi.py\n</code></pre>"},{"location":"software/apps-and-envs/stata/","title":"Stata","text":"<p>Stata is a powerful statistical software package that is widely used in scientific computing. RCC users are licensed to use Stata on all RCC resources. Stata can be used interactively or as a submitted script. Please note that if you would like to run it interactively, you must still run it on a compute node, in order to keep the login nodes free for other users. Stata can be run in parallel on up to 16 nodes.</p> <p>NOTE: Stata examples in this document are adapted from a Princeton tutorial. You may find it useful if you are new to Stata or want a refresher.</p>"},{"location":"software/apps-and-envs/stata/#getting-started","title":"Getting Started","text":"<p>If you need to use the Stata GUI, connect to Midway with ThinLinc.</p> <p>Obtain an interactive session on a compute node. This is necessary so that your computation doesn\u2019t interrupt other users on the login node. Now, load Stata:</p> <pre><code>sinteractive\nmodule load stata\nxstata\n</code></pre> <p>This will open up a Stata window. The middle pane has a text box to enter commands at the bottom, and a box for command results on top. On the left there\u2019s a box called \u201cReview\u201d that shows your command history. The right-hand box contains information about variables in the currently-loaded data set.</p> <p>One way Stata can be used is as a fancy desktop calculator. Type the following code into the command box:</p> <pre><code>display 2+2\n</code></pre> <p>Stata can do much more if data is loaded into it. The following code loads census data that ships with Stata, prints a description of the data, then creates a graph of life expectancy over GNP:</p> <pre><code>sysuse lifeexp\ndescribe\ngraph twoway scatter lexp gnppc\n</code></pre>"},{"location":"software/apps-and-envs/stata/#running-stata-from-the-command-line","title":"Running Stata from the command line","text":"<p>This is very similar to running graphically; the command-line interface is equivalent to the \u201cResults\u201d pane in the graphical interface. Again, please use a compute node if you are running computationally-intensive calculations:</p> <pre><code>sinteractive\nmodule load stata\nstata\n</code></pre>"},{"location":"software/apps-and-envs/stata/#running-stata-jobs-with-slurm","title":"Running Stata Jobs with SLURM","text":"<p>You can also submit Stata jobs to SLURM, the scheduler. A Stata script is called a \u201cdo-file,\u201d which contains a list of Stata commands that the interpreter will execute. You can write a do-file in any text editor, or in the Stata GUI\u2019s do-file editor: click \u201cDo-File Editor\u201d\u201d in the \u201cWindow\u201d menu. If your do-file is named \u201cexample.do,\u201d you can run it with either of the following commands:</p> <pre><code>stata &lt; example.do\nstata -b do example.do\n</code></pre> <p>Here is a very simple do-file, which computes a regression on the sample data set from above:</p> <pre><code>version 13 // current version of Stata, this is optional but recommended.\n\nsysuse lifeexp\ngen loggnppc = log(gnppc)\nregress lexp loggnppc\n</code></pre> <p>Here is a submission script that submits the Stata program to the default queue on Midway:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=stataEx\n#SBATCH --output=stata_example.out\n#SBATCH --error=stata_example.err\n#SBATCH --nodes=1\n#SBATCH --tasks-per-node=1\n\nmodule load stata\n\nstata -b stata_example.do\n</code></pre> <p><code>stata_example.do</code> is our example do-file, and <code>stata_example.sbatch</code> is the submission script.</p> <p>To run this example, download both files to a directory on Midway.  Enter the following command to submit the program to the scheduler:</p> <pre><code>sbatch stata_example.sbatch\n</code></pre> <p>Output from this example can be found in the file named <code>stata_example.log</code>, which will be created automatically in your current directory.</p>"},{"location":"software/apps-and-envs/stata/#running-parallel-stata-jobs","title":"Running Parallel Stata Jobs","text":"<p>The parallel version of Stata, Stata/MP, can speed up computations and make effective use of RCC\u2019s resources. When running Stata/MP, you are limited to 16 cores and 5000 variables. Run an interactive Stata/MP session:</p> <pre><code>sinteractive\nmodule load stata\nstata-mp\n# or, for the graphical interface:\nxstata-mp\n</code></pre> <p>Here is a sample do-file that would benefit from parallelization. It runs bootstrap estimation on another data set that ships with Stata.</p> <pre><code>version 13\n\nsysuse auto\nexpand 10000\nbootstrap: logistic foreign price-gear_ratio\n</code></pre> <p>Here is a submission script that will run the above do-file with Stata/MP:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=stataMP\n#SBATCH --output=stata_parallel.out\n#SBATCH --error=stata_parallel.err\n#SBATCH --nodes=1\n#SBATCH --tasks-per-node=16\n\nmodule load stata\nstata-mp -b stata_parallel.do\n</code></pre> <p>Download <code>stata_parallel.do</code> and <code>stata_parallel.sbatch</code> to Midway, then run the program with:</p> <pre><code>sbatch stata_parallel.sbatch\n</code></pre>"},{"location":"software/apps-and-envs/tf-and-torch/","title":"Tensorflow and PyTorch","text":"<p>To use Tensorflow or PyTorch on Midway's GPU nodes, you may use an existing installation of either package provided as an Anaconda environment (see Python and Jupyter Notebook page), or install them into your own personal environment. </p> <p>Importantly, you must use an existing installation of CUDA and/or CuDNN, which you will first load via <code>module load cuda/&lt;version&gt;</code> or <code>module load cudnn/&lt;version&gt;</code> (which automatically loads cuda).</p> <p>Versions, versions, versions</p> <p>As of March 2023, we find the combination of module versions <code>python/anaconda-2021.05</code>, <code>cuda/11.2</code>, and <code>cudnn/11.2</code> to be the most stable. If wish to use newer versions of Python or CUDA, be sure to check the version compatibility as a first troubleshooting step when checking GPU engagement. </p> <p>With the CUDA module/s loaded, and being connected to a GPU node, you should be able to import either Tensorflow and PyTorch and check GPU engagment with the following steps: </p>"},{"location":"software/apps-and-envs/tf-and-torch/#gpu-enagement","title":"GPU Enagement","text":"<p>Here are a few quick tips on how to make sure you're actually using a GPU.</p>"},{"location":"software/apps-and-envs/tf-and-torch/#checking-in-terminal","title":"Checking in terminal","text":"<p>Before you even run your script, it can be useful to check to ensure </p> <p>NVIDIA has a built in System Management Interface that makes this simple with one command: <pre><code> nvidia-smi\n</code></pre></p> <p>You should see details about the device, if it is detected.</p>"},{"location":"software/apps-and-envs/tf-and-torch/#tensorflow","title":"Tensorflow","text":"<p>Here's how to check if tensorflow sees your GPU/s. <pre><code>import tensorflow as tf\n</code></pre> The one-liner: <pre><code>print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n</code></pre> For more info: <pre><code>gpus = tf.config.experimental.list_physical_devices('GPU')\ntf.config.experimental.get_device_details(gpus[0])\n</code></pre></p>"},{"location":"software/apps-and-envs/tf-and-torch/#pytorch","title":"PyTorch","text":"<p>And here's how to check with PyTorch <pre><code>import torch\ntorch.cuda.device_count()\ntorch.cuda.get_device_name()\n</code></pre></p>"},{"location":"software/geospatial/","title":"RCC Support for Geospatial Data","text":"<p>The RCC-GIS portal provides information for locating data, taking classes, leveraging GIS software, and exploring research projects on campus. RCC-GIS engages in interdisciplinary research and education with UChicago users who want to incorporate GIS methods and software. Spatial analysis research tools benefit any discipline using location-based data. RCC-GIS offers many services to the UChicago community, such as: cartography, data mining and transformation, spatial statistics, GIS desktop software, and high-performance computing solutions.</p> <p>RCC-GIS also offers complimentary workshops and bootcamp courses on cutting-edge GIS methods and software. These courses allow UChicago researchers to independently overcome challenges associated with location-based data.</p>"},{"location":"software/geospatial/#training-education","title":"Training &amp; Education","text":"<p>RCC-GIS offers training and workshops on a variety of topics relevant to spatial analytics, GIS software, spatial statistics, and spatial data mining.</p>"},{"location":"software/geospatial/#gis-software-support","title":"GIS software support","text":"<p>RCC-GIS distributes and supports various GIS software platforms for analytics and map creation on a personal computer or in a server-based environment.</p>"},{"location":"software/geospatial/#spatial-data-mining","title":"Spatial Data Mining","text":"<p>Locating, cleaning, and utilizing spatial data can be challenging. RCC-GIS helps users accomplish these tasks with various strategies and tools.</p>"},{"location":"software/geospatial/#multi-disciplinary-research","title":"Multi-Disciplinary Research","text":"<p>RCC-GIS enables the integration of spatial analysis with any discipline using location-based data from economics to agriculture and archaeology to medicine.</p>"},{"location":"software/geospatial/geocoding/","title":"Geocoding","text":"<p>Welcome to the University of Chicago RCC-GIS Geocoding Service. This application allows UChicago affiliates to take lists of street addresses or place names and convert them into latitude and longitude coordinates. The coordinate pairs can then be used in any sort of mapping application or spatial analysis method.</p> <p></p> <p>The engine behind the RCC-GIS Geocoding Service is the ESRI\u2019s World Geocoder for ArcGIS. The Geocoding Service has the ability to retrieve coordinates for places around the world. However, coverage does differ from country to country. Click here to see what level of detail is available for different parts of the world. The RCC-GIS Geocoding Service is available to any UChicago affiliate with an active CNetID login and works on a credit-based system. All users are allocated 2000 credits by default. 2000 credits will allow a user to geocode 50,000 records. If a user needs to geocode more records, a request must be forwarded by email to gis-help@rcc.uchicago.edu for a larger allocation.</p>"},{"location":"software/geospatial/geocoding/#1-formatting-data-for-processing","title":"1. Formatting Data for Processing","text":"<p>Records must be formatted in a particular way for processing by the RCC-GIS Geocoding Service. The RCC-GIS Geocoding service requires data to be uploaded in a CSV (comma-separated value) format in the standard UTF-8 encoding. Different parts of the world have different formats and subdivisions for street addresses and place names. Records should be either in one column or\u00a0divided accordingly for processing. The following column headers are acceptable for your CSV file:</p> <p>ID ADDRESS NEIGHBORHOOD CITY SUBREGION REGION or STATE or ST POSTAL or ZIP or ZIPCODE COUNTRYCODE</p> <p>It is NOT necessary to provide data for all the variables listed above. However, if more data is provided, the geocoding service should provide a higher match rate.</p> <p>Example File: A formatted US address file can be downloaded from here.\u00a0 International address file formatting\u00a0 For the CSV file creation, RCC recommends the use of OpenOffice or LibreOffice over excel.</p>"},{"location":"software/geospatial/geocoding/#2-sign-in-and-execution-procedure","title":"2. Sign In and Execution Procedure","text":"<p>Log on to the enterprise ArcGIS Online portal for the University of Chicago by clicking on \u201cSign in with Enterprise Login\u201d.</p> <p></p> <p></p> <p></p> <ol> <li>Enter the portal\u2019s URL \u201cuchicago.maps.arcgis.com\u201d and click Continue.</li> <li>Sign in to the University of Chicago portal by clicking on UCHICAGO.</li> <li>Enter your University of Chicago CNetID username and password and click LOG IN.</li> <li>Upload your file to be geocoded by clicking Select File.</li> <li>Browse to your file\u2019s location, highlight it, and click Open.</li> <li>Click the Submit button to activate the geocoding service.</li> <li>The geocoding service page will notify you that your file has been uploaded. Refresh your browser to see the progress with your data. (The geocoding service will process approximately 250,000 - 500,000 records per hour.)</li> </ol> <p>When completed, click the link to Download the Geocoded File. Your geocoded file will be available for download for 7 days. After that time, it will be deleted from the queue.</p>"},{"location":"software/geospatial/geocoding/#3-activate-geocoding-service","title":"3. Activate Geocoding Service","text":"<p>Click the above link or navigate to http://geocoder.rcc.uchicago.edu</p>"},{"location":"software/geospatial/geocoding/#4-interpreting-geocoding-output","title":"4. Interpreting Geocoding Output","text":"<p>The downloaded output file will include the user's original data along with 3 new variables, LATITUDE, LONGITUDE, and MATCH SCORE.</p>"},{"location":"software/geospatial/geocoding/#latitudelongitude","title":"Latitude/Longitude","text":"<p>The latitude and longitude variables are the real-world coordinates as interpreted by the ESRI\u2019s World Geocoder for ArcGIS.</p>"},{"location":"software/geospatial/geocoding/#match-score","title":"Match Score","text":"<p>The match score is a calculation of how closely the interpreter came to finding the exact same address or place name. A perfect match score of 100% is optimal. However, a match score above 90% may also be suitable for many cases.</p> <ul> <li>Example: a score of 92% may occur when the user provides the following address: 1100 E. 57th, Chicago, IL. A score of 100% might have been achieved if the user included the street type (ST) in the address record. Therefore, a perfect score could be achieved for 1100 E. 57th St., Chicago, IL.</li> </ul> <p>Most match scores below 90% should be scrutinized. A low match score will still produce a latitude/longitude coordinate pair but it may be incorrectly placed. If the interpreter cannot locate a street address, it defaults to the next highest location variable.</p> <ul> <li>Example: if the user has 1100 N. Woodlawn Ave., Chicago, IL as a record, the interpreter may produce a match score of 72% along with a latitude/longitude coordinate pair. However, since 1100 N. Woodlawn Ave. does not exist, the interpreter will assign the location to the center of Chicago, IL instead. IT WILL NOT PRODUCE AN ERROR, ONLY A LOWER MATCH SCORE.</li> </ul> <p>Any records with a low match score should be re-evaluated, validated with another geocoding service, or dropped from the record-set altogether.</p>"},{"location":"software/geospatial/geocoding/#note","title":"Note","text":"<p>Please refer to the FAQ section if your geocoding process fails. If you have any questions or issues with the RCC-GIS Geocoding Service, please email us: gis-help@rcc.uchicago.edu.</p>"},{"location":"tutorials/kicp/","title":"KICP Tutorial","text":"<p>Note</p> <p>This page was migrated from the previous user guide with minimal editing. Some details may now be out of date. See the main sections of this guide for the most up-to-date content. </p> <p>The KICP has exclusive access to a number of compute nodes associated with the RCC Midway cluster.  KICP users access those nodes through the same login nodes and interfaces as the primary cluster, making it trivial to move computational work between the two sets of resources. Most of the documentation available on this site is applicable to KICP members and the KICP nodes, however there are some specific differences which are described here.</p> <p>Email sent to kicp@rcc.uchicago.edu will be assigned a trouble ticket and reviewed by the RCC Help Desk.  Please don\u2019t hesitate to ask questions if you encounter any issues, or have any requests for software installation.</p>"},{"location":"tutorials/kicp/#get-an-account","title":"Get an account","text":"<p>Please complete the RCC User Account Request form to request an account and put KICP as the PI (note: this request will be reviewed for KICP membership).  Please clearly state your connection to the KICP, particularly if you are not a local or senior member.  If you are requesting access for someone not at the University of Chicago (i.e. someone who doesn\u2019t have a CNetID), the account creation process will involve creating a CNetID.</p> <p>To access the rest of the Midway cluster you will need to be added to a different account than KICP, typically provided by a faculty member acting as PI. All KICP faculty are eligible to act as PI for themselves and others, and many already have PI accounts on the Midway cluster.</p>"},{"location":"tutorials/kicp/#submit-a-job","title":"Submit A Job","text":"<p>As a shared resource, Midway uses a batch queueing system to allocate nodes to individuals and their jobs.  Midway uses the Slurm batch queuing system, which is similar to the possibly more familiar PBS batch system.</p> <p>Please see the Midway2 and Midway3 HPC Systems section of this User Guide for information on using Midway to perform computational tasks, typically by submitting batch jobs. The Slurm commands, reiterated below, can be used as described in that documentation, however KICP users may need to point to one of the two KICP partitions, kicp and kicp-ht, and select the kicp account.</p> <p>NOTE: Specifying \u2013account=kicp and \u2013partition=kicp is generally optional for users who belong to the KICP group and no other, however specifying them is generally good practice.</p> Useful Commands Description sbatch -p kicp -a kicp Submit a job to the Slurm scheduling system. sinteractive -p kicp Run an interactive job on a KICP compute node squeue -p kicp List the submitted and running jobs in the KICP partition. squeue -u $USER List the current users\u2019 own submitted and running jobs. sinfo -p kicp List the number of available and allocated KICP nodes. scancel job_id Cancel the job identified by the given job_id (e.g. 3636950). scancel -u $USER Cancel all jobs submitted by the current user <p>There are many ways to submit a batch job, depending on what that job requires (number of processors, number of nodes, etc). Slurm will automatically start your job in the directory from which it was submitted.  To submit a job, create a batch script, say my_job.sh and submit with the command sbatch my_job.sh.  The following is a list of commonly used sbatch commands.  A more complete list can be found in the sbatch man page.</p> <p>The following is a good example batch script:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=my_job\n#SBATCH --output=my_job_%j.out\n#SBATCH --time=24:00:00\n#SBATCH --partition=kicp\n#SBATCH --account=kicp\n#SBATCH --nodes=1\n#SBATCH --exclusive\n\necho $SLURM_JOB_ID starting execution `date` on `hostname`\n\n# load required modules (change to your requirements!)\n# example: module load openmpi/1.8\n\n# uncomment below if your code uses OpenMP to properly set the number of threads\n# export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n\n# the commands to run your job\n# example: mpirun ./my_task\n# Note: slurm will automatically tell MPI how many tasks and tasks per node to use\n</code></pre>"},{"location":"tutorials/kicp/#kicp-queues","title":"KICP Queues","text":"<p>KICP has the access to the following queues (partition in Slurm terminology):</p> Partition Wallclock limit Job limits kicp 48h 256 cores, 64 jobs per user kicp-ht 36h 64 cores/job, 32 jobs per user kicp-long 100h 128 cores/queue, 64 cores/user <p>access to kicp-long requires special authorization.</p> <p>If you are running jobs with significant I/O or communication between nodes (typically MPI jobs), then you should use the the tightly-coupled, infiniband nodes accessed through the kicp and kicp-long partitions. Purely serial or embarrassingly parallel jobs with a large calculation to I/O ratio (say MCMC likelihood sampling) should use the high-throughput nodes in the kicp-ht queue.  The limits for kicp-ht were relaxed to encourage use.  If users start to conflict, they may be restricted to prevent a single user from dominating those nodes.</p> <p>Midway also includes two large memory (256GB) and four GPU enabled nodes, as well as a significantly larger set of nodes that are shared with the rest of the University.  Accessing these resources requires a separate allocation.  Please contact the RCC for more details.</p>"},{"location":"tutorials/kicp/#storage","title":"Storage","text":"<p>Your home directory has a 30G quota, and should be used for small files and codes.</p> <p>KICP has a 50TB allocation in <code>/project/kicp/</code>, and each user is initially given a 1TB quota and their own subdirectory (<code>/project/kicp/$USER)</code>. If you require more space, please let the RCC know and your quota may be increased on a case-by-case basis.</p> <p>New project space is no longer allocated under /project but under /project2.</p> <p>Both home and project space are backed up hourly to disk, and daily to tape.</p> <p>Finally, there is a high-performance filesystem mounted on /scratch/midway2 which should be used during runs and has a 5TB quota. This directory is not backed up and should not be used for long-term storage. In future, files older than a to be determined age may be removed automatically, so please practice good data management.</p>"},{"location":"tutorials/kicp/#snapshots-and-backups","title":"Snapshots and Backups","text":"<p>We all inadvertently delete or overwrite files from time to time.  Snapshots are automated backups that are accessible through a separate path.  Snapshots of a user\u2019s home directory can be found in <code>/snapshots/\\*/home/*cnetid*/</code> where the subdirectories refer to the frequency and time of the backup, e.g. daily-2012-10-04.06h15 or hourly-2012-10-09.11h00.</p>"},{"location":"tutorials/kicp/#software","title":"Software","text":"<p>Many common astrophysical codes and libraries have been installed or built on Midway. Other common astrophysics packages require configuration at compilation that prevent them from being installed system-side. Look here for program specific compilation flags, installation instructions, etc for these packages. Please contact the RCC if you notice any problems with any of the software or instructions.</p>"},{"location":"tutorials/kicp/#idl","title":"IDL","text":"<p>IDL is installed on Midway, however the RCC is unable to provide licenses to the entire community. Users who have their own licenses or license servers may configure them to be able to use IDL on Midway\u2019s login and compute nodes. Contact RCC for more details.</p>"},{"location":"tutorials/kicp/#cosmomc","title":"CosmoMC","text":"<p>CosmoMC is a Markov-Chain Monte-Carlo (MCMC) code which is integrated with the theoretical power spectrum code CAMB.  Since it is often modified by users, we don\u2019t install a system-wide version, however we have verified that the following parameters give good performance (Warning: under construction, don\u2019t use these instructions without first talking to the RCC).</p> <p>Specific installation instructions for a non-mpi build using the intel compiler and the intel math kernel library mkl 10.3 (note, these differ slightly from those provided by the CosmoMC readme ):</p> <ul> <li> <p>Download CosmoMC from cosmologist.info and untar on Midway</p> </li> <li> <p>Load the modules appropriate for the compiler you intend to use.  In this case a non-mpi build with the intel compiler: <code>module load intel/12.1 cfitsio/3+intel-12.1 mkl/10.3</code></p> </li> <li> <p>Edit the CosmoMC Makefile located in the source subdirectory</p> </li> </ul> <p>The WMAP7 likelihood code and data are already configured and installed on Midway in the <code>/project/kicp/opt/WMAP/</code> directory. The stock v4 and v4p1 versions from Lambda  are installed, as is a patched version of v4 with special optimizations from Cora Dvorkin &amp; Wayne Hu.  Select the version you wish to use and change the WMAP variable to point to the full directory, e.g. <code>WMAP = /project/kicp/opt/WMAP/likelihood_v4p1</code>.</p> <ul> <li>Modify the compiler and optimization options</li> </ul> <pre><code>F90C = ifort\nFFLAGS = -O2 -openmp -fpp\nLAPACKL = $(MKLROOT)/lib/intel64/libmkl_lapack95_lp64.a \\\n-Wl,--start-group \\\n$(MKLROOT)/lib/intel64/libmkl_intel_lp64.a \\\n$(MKLROOT)/lib/intel64/libmkl_sequential.a \\\n$(MKLROOT)/lib/intel64/libmkl_core.a \\\n-Wl,--end-group -lpthread\n</code></pre> <ul> <li>Run make</li> </ul> <p>Note, this section is under construction.  Updated build instructions for a variety of compilers and mpi support will come soon.</p>"},{"location":"tutorials/kicp/#art","title":"ART","text":"<p>ART has default compilation flags for Midway.  Set the environment variable PLATFORM to midway. This platform file will automatically detect the MPI environment and compiler option you are using and configure the code accordinly.</p>"},{"location":"tutorials/kicp/#ramses","title":"RAMSES","text":"<p>Ramses is a cosmological hydrodynamic adaptive mesh refinement code originally written by Romain Teyssier.  It is public, and can be downloaded .  Oscar Agertz has compiled and run Ramses on Midway and reports good performance with the following makefile configuration:</p> <pre><code>F90 = mpif90 -O3\nFFLAGS = -cpp -DNVAR=$(NVAR) -DNDIM=$(NDIM) -DNPRE=$(NPRE) \\\n-DSOLVER$(SOLVER) -DNOSYSTEM -DNVECTOR=$(NVECTOR)\nLIBMPI =\nLIBS = $(LIBMPI)\n</code></pre>"},{"location":"tutorials/kicp/#gadget","title":"Gadget","text":"<p>This refers to the public version of Gadget 2.0.7. The following Makefile configuration should work under all combination of compilers, MPI libraries, and Gadget options (including HDF5 support):</p> <pre><code>CC = mpicc\nOPTIMIZE = -O3\nMPICHLIB =\nHDF5INCL = -DH5_USE_16_API\nHDF5LIB = -lhdf5\n</code></pre> <p>The code requires that modules are loaded for fftw2, gsl, mpi, and an optional hdf5.  Make sure to load compiler and MPI library specific versions of the modules as necessary.  Some examples are given below:</p> <ul> <li>Intel compiler + Intel MPI (note, loading intelmpi will automatically load intel/12.1):</li> </ul> <pre><code>module load intelmpi/4.0+intel-12.1 fftw2/2.1.5+intelmpi-4.0+intel-12.1 hdf5/1.8 gsl/1.15\n</code></pre> <ul> <li>Intel compiler + OpenMPI:</li> </ul> <pre><code>module load openmpi/1.6+intel-12.1 fftw2/2.1.5+openmpi-1.6+intel-12.1 hdf5/1.8 gsl/1.15\n</code></pre> <ul> <li>GCC + OpenMPI:</li> </ul> <pre><code>module load openmpi/1.6 fftw2/2.1.5+openmpi-1.6 hdf5/1.8 gsl/1.15\n</code></pre>"},{"location":"tutorials/kicp/#automating-large-numbers-of-tasks","title":"Automating Large Numbers of Tasks","text":"<p>Researchers often need to perform a number of calculations that vary only in their initial conditions or input parameters. Such tasks naturally arise when exploring the predictions of a model over a range of parameters or when testing a numerical calculation for convergence. Automating these tasks is critical, both for computational efficiency and to minimize human error and ensure the calculation is reproducible.</p> <p>This tutorial will discuss a number of techniques and tools available on Midway for automating the running of tasks and their respective advantages and disadvantages. In particular we will focus on those tasks which are entirely independent of each other and where the total number of tasks is known (and fixed).</p> <p>When deciding between the various techniques, users should consider the following:</p> <ul> <li>overhead or cost of starting each task (including cost of starting remote processes)</li> <li>waiting time each batch job will spend in the queue</li> <li>total number of jobs compared to available resources and limits</li> <li>the average calculation time per job and its variance</li> <li>the cost in developer time needed for a given solution</li> </ul> <p>As a semi-realistic example, this tutorial will use the CLASS code to compute the non-linear matter power specturm for a range of the neutrino parameter N_eff.</p>"},{"location":"tutorials/kicp/#class-and-classy","title":"CLASS and classy","text":"<p>CLASS [1104.2932] is a Boltzmann code similar to CMBFAST, CAMB, and others. It can be used to compute a number of large-scale structure and CMB observables and since it is designed to perform calculations within MCMC-type likelihood analyses, it is a good option for these exercises.</p> <p>To install CLASS and its Python wrapper, classy, use the following commands:</p> <pre><code>module load git python/2.7-2014q3\ngit clone https://github.com/lesgourg/class_public\ncd class_public\nmake\n</code></pre> <p>NOTE: This will install the Class python wrappers in your .local directory while remembering where you compiled CLASS. Make sure you delete them both after completing the exercises.</p> <p>classy is a Python wrapper for the CLASS code which we will use for convenience. It allows us to avoid the common issue of dealing with parameter files.</p> <p>The code that uses classy to compute the non-linear matter power spectrum for a given N_eff is as follows:</p> <pre><code>#!/bin/env python\n\ndef compute_pk(N_eff=3.04, output=\"pk.dat\"):\n    import numpy as np\n    from classy import Class\n\n    # initialize Class with default parameters save N_eff\n    c = Class()\n    c.set({'output':'mPk', 'non linear':'halofit', 'N_eff':N_eff})\n    c.compute()\n    with open(output, \"w\") as output:\n        for k in np.logspace(-3., 0.5, 100):\n            print &gt;&gt;output, \"%.6e %.6e\" % (k, c.pk(k, z=0.0))\n    c.struct_cleanup()\n\n    # if necesssary for visualization, add a 5 second delay\n    #import time; time.sleep(5)\n\n# perform work associated with i out of N steps\ndef work(i, N=100):\n    N_eff_min = 2.5\n    N_eff_max = 4.5\n    N_eff = (N_eff_max-N_eff_min)*float(i)/float(N) + N_eff_min\n    output = \"pk_{}.dat\".format(i)\n    compute_pk(N_eff, output)\n\n# collect the resulting matter power spectra and plot \ndef plot_pk(file_pattern=\"pk_*.dat\",output=\"pk.png\"):\n    import pylab, glob\n    import numpy as np\n\n    f = pylab.figure(figsize=(5,5))\n    for data in glob.glob(file_pattern):\n        (k, pk) = np.loadtxt(data, unpack=True)\n        f.gca().loglog(k, pk, color='k', alpha=0.05)\n    f.gca().set_xlabel(\"k [Mpc/h]\")\n    f.gca().set_ylabel(\"P(k)\")\n    f.tight_layout()\n    f.savefig(output)\n\nif __name__ == \"__main__\":\n    import sys\n    if len(sys.argv) == 3:\n        work(int(sys.argv[1]), int(sys.argv[2]))\n    else:\n        plot_pk()\n\n    print \"done\"\n</code></pre> <p>Run this code without any input parameters to generate the following png figure from the resulting output files.</p>"},{"location":"tutorials/kicp/#parallel-programming","title":"Parallel Programming","text":"<p>Implementing your own parallel scheme is useful when the tasks are not completely independent, or represent only a part of a larger, non-trivial workflow. Calculations that rely on large pre-calculated tables or have costly initilization may also benefit from an explicit scheme, as those costs can be amortized over a larger number of tasks.</p>"},{"location":"tutorials/kicp/#multiprocessing","title":"Multiprocessing","text":"<p>Smaller numbers of tasks can be divided amongst workers on a single node. In high level languages like Python, or in lower level languages using threading language constructs such as OpenMP, this can be accomplished with little more effort than a serial loop. This example also demonstrates using Python as the script interpreter for a Slurm batch script, however note that since Slurm copies and executes batch scripts from a private directory, it is necessary to manually add the runtime directory to the Python search path.</p> <pre><code>#!/bin/env python\n\n#SBATCH --job-name=multiprocess\n#SBATCH --output=logs/multiprocess_%j.out\n#SBATCH --time=01:00:00\n#SBATCH --partition=kicp\n#SBATCH --account=kicp\n#SBATCH --nodes=1\n#SBATCH --exclusive\n\nimport multiprocessing\nimport sys\nimport os\n\n# necessary to add cwd to path when script run \n# by slurm (since it executes a copy)\nsys.path.append(os.getcwd()) \nfrom pk import work\n\n# get number of cpus available to job\ntry:\n    ncpus = int(os.environ[\"SLURM_JOB_CPUS_PER_NODE\"])\nexcept KeyError:\n    ncpus = multiprocessing.cpu_count()\n\n# create pool of ncpus workers\np = multiprocessing.Pool(ncpus)\n\n# apply work function in parallel\np.map(work, range(100))\n</code></pre>"},{"location":"tutorials/kicp/#mpi","title":"MPI","text":"<p>Process and threaded level parallelism is limited to a single machine.</p> <pre><code>#!/bin/env python\n\n#SBATCH --job-name=mpi\n#SBATCH --output=logs/mpi_%j.out\n#SBATCH --time=01:00:00\n#SBATCH --partition=kicp\n#SBATCH --ntasks=100\n\nfrom mpi4py import MPI\nfrom pk import work\n\ncomm = MPI.COMM_WORLD\nrank = comm.Get_rank()\nsize = comm.Get_size()\n\nwork(rank, size)\n</code></pre> <p>MPI programs and Python scripts must be launched using mpirun as shown in this Slurm batch script:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=mpi\n#SBATCH --output=logs/mpi_%j.out\n#SBATCH --time=01:00:00\n#SBATCH --partition=kicp\n#SBATCH --account=kicp\n#SBATCH --ntasks=100\n\nmodule load mpi4py/1.3-2014q3+intelmpi-4.0\n\nmpirun python mpi_pk.py\n</code></pre> <p>In this case we are only using MPI as a mechanism to remotely launch tasks on distributed nodes. All processes must start and end at the same time, which can lead to waste of resources if some job steps take longer than others.</p>"},{"location":"tutorials/kicp/#job-scheduler","title":"Job Scheduler","text":"<p>Most of this workshop will focus on using various features of Midway\u2019s batch scheduler, Slurm as its sole purpose is to help organize batch job submission.</p>"},{"location":"tutorials/kicp/#slurm-task-per-job","title":"Slurm task per job","text":"<p>In some cases it may be easiest to wrap the job submission in a script or bash command, taking advantage of the fact that Slurm will pass on environment variables defined at the time of job submission (this is also why you can load modules before submitting a job rather than inside the job script itself).</p> <pre><code>for i in {0..10}; do export i; sbatch job.sbatch; done\n</code></pre> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=job\n#SBATCH --output=logs/job_%j.out\n#SBATCH --time=01:00:00\n#SBATCH --partition=kicp\n#SBATCH --account=kicp\n#SBATCH --ntasks=1\n\npython pk.py $i 100\n</code></pre> <p>NOTE: It can be difficult to monitor and jobs submitted in this way. Be sure to use a unique job-name so you can identify a particular job group with commands like squeue and scancel, e.g. <code>scancel -n class</code></p>"},{"location":"tutorials/kicp/#gnu-parallel","title":"GNU Parallel","text":"<p>GNU Parallel is a tool for executing tasks in parallel, typically on a single machine. When coupled with the Slurm command srun, parallel becomes a powerful way of distributing a set of tasks amongst a number of workers. This is particularly useful when the number of tasks is significantly larger than the number of available workers (Slurm\u2019s <code>--ntasks</code>).</p> <pre><code>#!/bin/sh\n\n#SBATCH --time=01:00:00\n#SBATCH --output=logs/parallel.log\n#SBATCH --partition=kicp\n#SBATCH --account=kicp\n#SBATCH --ntasks=32\n#SBATCH --exclusive\n\nmodule load parallel\n\n# the --exclusive to srun makes srun use distinct CPUs for each job step\n# -N1 -n1 allocates a single core to each task\nsrun=\"srun --exclusive -N1 -n1\"\n\n# --delay .2 prevents overloading the controlling node\n# -j is the number of tasks parallel runs so we set it to $SLURM_NTASKS\n# --joblog makes parallel create a log of tasks that it has already run\n# --resume makes parallel use the joblog to resume from where it has left off\n# the combination of --joblog and --resume allow jobs to be resubmitted if\n# necessary and continue from where they left off\nparallel=\"parallel --delay .2 -j $SLURM_NTASKS --joblog logs/runtask.log --resume\"\n\n# this runs the parallel command we want\n# in this case, we are running a script named runtask\n# parallel uses ::: to separate options. Here {0..99} is a shell expansion\n# so parallel will run the command passing the numbers 0 through 99\n# via argument {1}\n$parallel \"$srun python pk.py {1} 100 &gt; logs/parallel_{1}.log\" ::: {0..99}\n</code></pre> <p>This job is submitted as with any Slurm batch job</p> <pre><code>$ sbatch parallel.sbatch\n</code></pre> <p>and will appear as a single job in the queue, assigned as many nodes/cores as was requested:</p> <pre><code>$ squeue -u $USER -p kicp\n   JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n11511073      kicp parallel    drudd  R       0:00      2 midway[203,390]\n</code></pre> <p>GNU Parallel maintains a log of the work that has already been done, along with the exit value of each step (useful for determining any failed steps).</p> <pre><code>$ head logs/runtask.log\nSeq Host    Starttime   Runtime Send    Receive Exitval Signal  Command\n1   :   1422211597.529  6.467   0   0   0   0   srun --exclusive -N1 -n1 python pk.py 0 100 &gt; logs/runtask.0\n2   :   1422211597.732  6.466   0   0   0   0   srun --exclusive -N1 -n1 python pk.py 1 100 &gt; logs/runtask.1\n3   :   1422211597.935  6.466   0   0   0   0   srun --exclusive -N1 -n1 python pk.py 2 100 &gt; logs/runtask.2\n4   :   1422211598.138  6.464   0   0   0   0   srun --exclusive -N1 -n1 python pk.py 3 100 &gt; logs/runtask.3\n</code></pre> <p>In our case we requested the output from each work step be directed to a file logs/runtask.{1}, allowing us to peform further diagnostics if necessary. The parallel option <code>--resume</code> creates a file parallel.log which allows GNU Parallel to resume a job that has been stopped due to failure or by hitting a walltime limit before all tasks have been completed. If you need to rerun a GNU Parallel job, be sure to delete parallel.log or it will think it has already finished!</p> <p>NOTE: More information may found in the RCC documentation section Parallel batch jobs.</p>"},{"location":"tutorials/kicp/#slurm-job-array","title":"Slurm Job Array","text":"<p>Most HPC job schedulers support a special class of batch job known as array jobs (or job arrays). Slurm support for job arrays is relatively new and is undergoing active development. The GNU Parallel solution in the previous section was developed at RCC because of the former lack of Slurm array jobs.</p> <p>An example Slurm array job submission script is as follows:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=array\n#SBATCH --output=logs/array_%A_%a.out\n#SBATCH --array=0-99\n#SBATCH --time=01:00:00\n#SBATCH --partition=kicp\n#SBATCH --account=kicp\n#SBATCH --ntasks=1\n\n# the environment variable SLURM_ARRAY_TASK_ID contains\n# the index corresponding to the current job step\npython pk.py $SLURM_ARRAY_TASK_ID 100\n</code></pre> <p>This looks very similar to our single-job batch submission script, but with the addition of the <code>--array</code> feature. In this case, the <code>--array=0-99</code> will cause 100 individual array-tasks to be created when this job script is submitted. Each array task is a copy of the master script, with an environment variable called <code>SLURM_ARRAY_TASK_ID</code> set to the index of the array task. As with the GNU Parallel example, we simply pass the value of that environment variable into our program to perform that piece of work.</p> <p>Each array job will enter the queue and run when resources are available for it, as if we had submitted each job manually (this is merely a highly-convenient shortcut).</p> <p>Array job indices do not need to be a linear range, and can be specified in a number of ways.  For example:</p> <pre><code>A job array with index values of 1, 2, 5, 19, 27:\n#SBATCH --array=1,2,5,19,27\n\nA job array with index values between 1 and 7 with a step size of 2 (i.e. 1, 3, 5, 7):\n#SBATCH --array=1-7:2\n</code></pre> <p>The <code>%A_%a</code> construct in the output and error file names is used to generate unique output and error files based on the master job ID (%A) and the array-tasks ID (%a).  In this fashion, each array-task will be able to write to its own output and error files.</p> <p>When we submit a job array, we will see the master process, as well as any submitted, running or otherwise not completed array tasks with the naming convention <code>%A_%a</code>.</p> <pre><code>$ squeue\n           JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n11510950_[10-99]      kicp    array    drudd PD       0:00      1 (None)\n11510950_0      kicp    array    drudd  R       0:00      1 midway185\n      11510950_1      kicp    array    drudd  R       0:00      1 midway185\n      11510950_2      kicp    array    drudd  R       0:00      1 midway185\n      11510950_3      kicp    array    drudd  R       0:00      1 midway185\n      11510950_4      kicp    array    drudd  R       0:00      1 midway185\n      11510950_5      kicp    array    drudd  R       0:00      1 midway185\n      11510950_6      kicp    array    drudd  R       0:00      1 midway185\n      11510950_7      kicp    array    drudd  R       0:00      1 midway185\n      11510950_8      kicp    array    drudd  R       0:00      1 midway185\n      11510950_9      kicp    array    drudd  R       0:00      1 midway185\n</code></pre> <p>We can cancel all array tasks associated with the master job ID as before, or cancel any subset of them using the naming convention <code>%A_%a</code></p> <pre><code># cancel job steps 10-100\n$ scancel 11510950_[10-100]\n\n# cancel all remaining job steps\n$ scancel 11510950\n</code></pre> <p>What happens if we try to submit a job with, say, <code>--array=0-1000</code>?</p> <pre><code>sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)\n</code></pre> <p>The number of jobs a user may have submitted (not running!) at any given time is limited, in order to avoid overloading the scheduler and to ensure users cannot accidentally swamp the machines with malformed job submissions. To see how many jobs can be run or submitted for a given partition+QOS, use the following command:</p> <pre><code>$ sacctmgr list qos kicp format=maxjobsperuser, maxsubmitjobsperuser\nMaxJobsPU MaxSubmitPU\n--------- -----------\n       64         128\n</code></pre> <p>The ability to submit array jobs which are larger than <code>MaxSubmitPU</code> is coming in a newer version of Slurm. Until then, each job should handle more than one piece of work, or the GNU Parallel solution should be used. For more information, see the RCC documentation section Job arrays.</p>"},{"location":"tutorials/kicp/#workflow-tools","title":"Workflow Tools","text":"<p>Other specialized tools have been created for handling parallel workflows, particularly in specific domains or for specific analysis or computational codes. Developing such tools is an open area of research.</p>"},{"location":"tutorials/msca/","title":"Introduction to RCC for MSc in Analytics","text":"<p>As a student in the Master of Science in Analytics (MScA) Program, you will be able to make use of The University of Chicago\u2019s Research Computing Center (RCC) resources in completing your capstone project.  Some courses in the program will also make use of RCC resources.</p> <p>RCC provides high-end research computing resources to researchers at the University of Chicago. These resources include centrally managed high-performance computing, storage, and visualization hardware, software, scientific and technical user support, as well as education and training opportunities to help researchers effectively make use of modern HPC technology.  To learn more about RCC, see https://rcc.uchicago.edu.</p> <p>Below are the basics you will need to know in order to get up and running at RCC.  For complete RCC technical documentation, see the main sections of this user guide. </p>"},{"location":"tutorials/msca/#getting-help","title":"Getting Help","text":"<p>RCC support staff is available to assist with technical issues (help logging in, questions about using the cluster, etc).  Please don\u2019t hesitate to ask questions if you encounter any technical issues.</p> <ul> <li> <p>The preferred way of requesting support is to contact our Help Desk.</p> </li> <li> <p>RCC\u2019s walk-in lab is open during business hours and is located in Regenstein Library room 216. Feel free to drop by to chat with one of our staff members if you get stuck.</p> </li> </ul>"},{"location":"tutorials/msca/#logging-into-midway","title":"Logging into Midway","text":"<p>For the most complete documentation regarding connecting to RCC resources see: Connecting to Midway.</p>"},{"location":"tutorials/msca/#using-midway","title":"Using Midway","text":"<p>See Running Jobs on Midway for detailed documentation on how to run your own programs on the cluster once you've connected. </p>"},{"location":"tutorials/msca/#software","title":"Software","text":"<p>Many commonly used software packages and libraries have been installed on Midway for your use.  For an overview of how to use Software Modules on Midway, consult the RCC Software documentation page.</p>"},{"location":"tutorials/msca/#sas","title":"SAS","text":"<p>SAS Studio is available to MScA students. SAS Studio is a web application frontend to SAS. To access SAS Studio, visit this link and log in with your CNetID and password:</p> <p>https://sas-studio.rcc.uchicago.edu</p> <p>Also, an instance of SAS Enterprise Miner is available to MScA students.  To access SAS Enterprise Miner, you can visit this link:</p> <p>https://sas-miner.rcc.uchicago.edu:8343/SASEnterpriseMinerJWS/Status</p> <p>SAS software is also available on Midway.  To load the SAS software module, use the command <code>module load sas</code>. It is recommended to use ThinLinc as described above to login to Midway if you want to use SAS in this manner.</p>"},{"location":"tutorials/msca/#nielsen-data","title":"Nielsen Data","text":"<p>The MScA program has obtained a subset of the Nielsen Homescan data for use in teaching and research projects.  Access to this data is controlled by MScA administration.  If you require access to this data, please consult your instructor or the MScA director and request that you be approved for access to the data.</p> <p>Once your user account has been approved for access to the Nielsen data, you will be able to access the data in the directory <code>/project/msca/data/nielsen/</code> on Midway.</p>"}]}